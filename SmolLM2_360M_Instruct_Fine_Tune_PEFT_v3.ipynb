{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/SmolLM2_360M_Instruct_Fine_Tune_PEFT_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "outputId": "69d52dc0-ca27-4fd1-81c4-bc2f70300670",
        "execution": {
          "iopub.status.busy": "2024-12-08T12:33:40.504321Z",
          "iopub.execute_input": "2024-12-08T12:33:40.504690Z",
          "iopub.status.idle": "2024-12-08T12:34:36.318905Z",
          "shell.execute_reply.started": "2024-12-08T12:33:40.504646Z",
          "shell.execute_reply": "2024-12-08T12:34:36.317576Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.12.2 requires transformers<4.47.0, but you have transformers 4.47.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-12-08T12:34:36.321039Z",
          "iopub.execute_input": "2024-12-08T12:34:36.321352Z",
          "iopub.status.idle": "2024-12-08T12:34:43.496811Z",
          "shell.execute_reply.started": "2024-12-08T12:34:36.321324Z",
          "shell.execute_reply": "2024-12-08T12:34:43.495918Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-12-08T12:34:43.497947Z",
          "iopub.execute_input": "2024-12-08T12:34:43.498215Z",
          "iopub.status.idle": "2024-12-08T12:34:43.795216Z",
          "shell.execute_reply.started": "2024-12-08T12:34:43.498188Z",
          "shell.execute_reply": "2024-12-08T12:34:43.792570Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'HuggingFaceTB/SmolLM2-360M-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:34:43.797757Z",
          "iopub.execute_input": "2024-12-08T12:34:43.798598Z",
          "iopub.status.idle": "2024-12-08T12:34:43.810371Z",
          "shell.execute_reply.started": "2024-12-08T12:34:43.798554Z",
          "shell.execute_reply": "2024-12-08T12:34:43.809580Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:34:43.811271Z",
          "iopub.execute_input": "2024-12-08T12:34:43.811544Z",
          "iopub.status.idle": "2024-12-08T12:34:43.821883Z",
          "shell.execute_reply.started": "2024-12-08T12:34:43.811500Z",
          "shell.execute_reply": "2024-12-08T12:34:43.821115Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:34:43.822782Z",
          "iopub.execute_input": "2024-12-08T12:34:43.823072Z",
          "iopub.status.idle": "2024-12-08T12:35:03.325083Z",
          "shell.execute_reply.started": "2024-12-08T12:34:43.823046Z",
          "shell.execute_reply": "2024-12-08T12:35:03.324188Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:03.326476Z",
          "iopub.execute_input": "2024-12-08T12:35:03.326756Z",
          "iopub.status.idle": "2024-12-08T12:35:03.334848Z",
          "shell.execute_reply.started": "2024-12-08T12:35:03.326730Z",
          "shell.execute_reply": "2024-12-08T12:35:03.333797Z"
        },
        "outputId": "280f8453-df06-430f-b2a9-d3bdcfc3b9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 204534720\nTrainable parameters : 47248320\nTrainable percentage: 23.10%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:03.336259Z",
          "iopub.execute_input": "2024-12-08T12:35:03.336518Z",
          "iopub.status.idle": "2024-12-08T12:35:05.833476Z",
          "shell.execute_reply.started": "2024-12-08T12:35:03.336493Z",
          "shell.execute_reply": "2024-12-08T12:35:05.832553Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'microsoft/orca-math-word-problems-200k'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:05.834590Z",
          "iopub.execute_input": "2024-12-08T12:35:05.834894Z",
          "iopub.status.idle": "2024-12-08T12:35:05.841598Z",
          "shell.execute_reply.started": "2024-12-08T12:35:05.834843Z",
          "shell.execute_reply": "2024-12-08T12:35:05.840775Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:05.845325Z",
          "iopub.execute_input": "2024-12-08T12:35:05.845565Z",
          "iopub.status.idle": "2024-12-08T12:35:05.852124Z",
          "shell.execute_reply.started": "2024-12-08T12:35:05.845542Z",
          "shell.execute_reply": "2024-12-08T12:35:05.851312Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:05.852994Z",
          "iopub.execute_input": "2024-12-08T12:35:05.853272Z",
          "iopub.status.idle": "2024-12-08T12:35:08.038515Z",
          "shell.execute_reply.started": "2024-12-08T12:35:05.853247Z",
          "shell.execute_reply": "2024-12-08T12:35:08.037630Z"
        },
        "outputId": "ef6c8a93-f507-4d44-cf64-0841db11f427"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['question', 'answer'],\n    num_rows: 200035\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.039469Z",
          "iopub.execute_input": "2024-12-08T12:35:08.039702Z",
          "iopub.status.idle": "2024-12-08T12:35:08.046514Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.039679Z",
          "shell.execute_reply": "2024-12-08T12:35:08.045588Z"
        },
        "id": "ybmPupfCxlOO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.047537Z",
          "iopub.execute_input": "2024-12-08T12:35:08.047797Z",
          "iopub.status.idle": "2024-12-08T12:35:08.116845Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.047771Z",
          "shell.execute_reply": "2024-12-08T12:35:08.116108Z"
        },
        "outputId": "314d7a21-25b9-4778-cb1c-d1a412578038"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.117741Z",
          "iopub.execute_input": "2024-12-08T12:35:08.117999Z",
          "iopub.status.idle": "2024-12-08T12:35:08.123492Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.117974Z",
          "shell.execute_reply": "2024-12-08T12:35:08.122590Z"
        },
        "outputId": "b3db7c90-68f5-4a48-859e-36bc586e6c7e"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.124605Z",
          "iopub.execute_input": "2024-12-08T12:35:08.124957Z",
          "iopub.status.idle": "2024-12-08T12:35:08.132781Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.124920Z",
          "shell.execute_reply": "2024-12-08T12:35:08.132035Z"
        },
        "outputId": "242c9fc9-5754-4987-b149-ab1efdba67a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['question', 'answer']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.133613Z",
          "iopub.execute_input": "2024-12-08T12:35:08.133844Z",
          "iopub.status.idle": "2024-12-08T12:35:08.142373Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.133823Z",
          "shell.execute_reply": "2024-12-08T12:35:08.141725Z"
        },
        "id": "H6WIPeGrxlOP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  input = examples['question']\n",
        "  output = examples['answer']\n",
        "\n",
        "  text = prompt_format.format(input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.143373Z",
          "iopub.execute_input": "2024-12-08T12:35:08.143664Z",
          "iopub.status.idle": "2024-12-08T12:35:08.153424Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.143623Z",
          "shell.execute_reply": "2024-12-08T12:35:08.152620Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.154414Z",
          "iopub.execute_input": "2024-12-08T12:35:08.154678Z",
          "iopub.status.idle": "2024-12-08T12:35:08.167068Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.154634Z",
          "shell.execute_reply": "2024-12-08T12:35:08.166373Z"
        },
        "outputId": "22d7a274-1c6f-4b13-c0d9-9382d0dee069"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.168053Z",
          "iopub.execute_input": "2024-12-08T12:35:08.168304Z",
          "iopub.status.idle": "2024-12-08T12:35:08.173757Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.168281Z",
          "shell.execute_reply": "2024-12-08T12:35:08.172907Z"
        },
        "outputId": "e09cc147-dce8-4310-ad1e-e4b4f84e30fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.174703Z",
          "iopub.execute_input": "2024-12-08T12:35:08.174979Z",
          "iopub.status.idle": "2024-12-08T12:35:08.182588Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.174954Z",
          "shell.execute_reply": "2024-12-08T12:35:08.181715Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:08.183561Z",
          "iopub.execute_input": "2024-12-08T12:35:08.183942Z",
          "iopub.status.idle": "2024-12-08T12:35:17.123716Z",
          "shell.execute_reply.started": "2024-12-08T12:35:08.183904Z",
          "shell.execute_reply": "2024-12-08T12:35:17.122783Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.124808Z",
          "iopub.execute_input": "2024-12-08T12:35:17.125123Z",
          "iopub.status.idle": "2024-12-08T12:35:17.130387Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.125089Z",
          "shell.execute_reply": "2024-12-08T12:35:17.129428Z"
        },
        "outputId": "d47cb6e4-713c-4571-bcfa-732ccf5beb42"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.131600Z",
          "iopub.execute_input": "2024-12-08T12:35:17.131854Z",
          "iopub.status.idle": "2024-12-08T12:35:17.189393Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.131830Z",
          "shell.execute_reply": "2024-12-08T12:35:17.188605Z"
        },
        "outputId": "19a9655a-2b2c-4fb4-f17b-7edaff40e9ad"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.190403Z",
          "iopub.execute_input": "2024-12-08T12:35:17.190704Z",
          "iopub.status.idle": "2024-12-08T12:35:17.198768Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.190670Z",
          "shell.execute_reply": "2024-12-08T12:35:17.197815Z"
        },
        "outputId": "b534ac7e-3a2f-4669-b19d-2756747f0890"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.199962Z",
          "iopub.execute_input": "2024-12-08T12:35:17.200288Z",
          "iopub.status.idle": "2024-12-08T12:35:17.221614Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.200248Z",
          "shell.execute_reply": "2024-12-08T12:35:17.220817Z"
        },
        "outputId": "40899d9f-1b04-4632-9d46-a28e6b34fd50"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [3757, 15232, 42, 198, 2122, 314, 253, 827, 29...   \n1  [3757, 15232, 42, 198, 788, 253, 2066, 3985, 2...   \n2  [3757, 15232, 42, 198, 31019, 3935, 288, 253, ...   \n3  [3757, 15232, 42, 198, 60, 14765, 314, 3012, 2...   \n4  [3757, 15232, 42, 198, 2122, 314, 253, 18896, ...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[3757, 15232, 42, 198, 2122, 314, 253, 827, 29...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[3757, 15232, 42, 198, 788, 253, 2066, 3985, 2...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[3757, 15232, 42, 198, 31019, 3935, 288, 253, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[3757, 15232, 42, 198, 60, 14765, 314, 3012, 2...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[3757, 15232, 42, 198, 2122, 314, 253, 18896, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.222546Z",
          "iopub.execute_input": "2024-12-08T12:35:17.222890Z",
          "iopub.status.idle": "2024-12-08T12:35:17.227599Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.222836Z",
          "shell.execute_reply": "2024-12-08T12:35:17.226763Z"
        },
        "outputId": "e9ac2e6b-dbb7-44b4-d306-621c54842ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.228594Z",
          "iopub.execute_input": "2024-12-08T12:35:17.228897Z",
          "iopub.status.idle": "2024-12-08T12:35:17.238269Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.228847Z",
          "shell.execute_reply": "2024-12-08T12:35:17.237590Z"
        },
        "outputId": "a0883bc4-c6a9-41f5-be27-a3a94b3e7037"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[3757, 15232, 42, 198, 2122, 314, 253, 827, 29, 23141, 1782, 1230, 3449, 12281, 1379, 314, 216, 35, 30, 2959, 330, 284, 389, 325, 260, 14498, 1010, 282, 451, 1230, 411, 216, 33, 32, 284, 260, 17867, 282, 7573, 411, 216, 33, 32, 28, 7827, 30, 1094, 389, 25319, 411, 216, 33, 32, 8055, 330, 314, 216, 41, 1181, 670, 330, 25319, 411, 216, 33, 32, 8055, 389, 28, 732, 314, 260, 808, 1230, 47, 198, 3757, 19842, 42, 198, 4239, 506, 25832, 260, 827, 29, 23141, 1230, 347, 3814, 24, 33739, 3814, 643, 837, 3814, 24, 2273, 3814, 25, 314, 260, 11403, 281, 260, 12281, 1379, 284, 3814, 24, 718, 3814, 25, 314, 260, 11403, 281, 260, 2911, 1379, 30, 4311, 260, 12281, 1379, 314, 216, 35, 28, 392, 457, 3814, 24, 2273, 446, 216, 35, 3814, 595, 198, 198, 5449, 288, 260, 1732, 28, 3814, 24, 330, 3814, 25, 314, 260, 14498, 1010, 282, 260, 1230, 411, 216, 33, 32, 28, 284, 3814, 24, 389, 3814, 25, 314, 260, 17867, 282, 260, 7573, 411, 216, 33, 32, 30, 4882, 28, 3814, 24, 330, 446, 2273, 446, 216, 35, 3814, 25, 284, 3814, 24, 389, 446, 718, 3814, 595, 198, 198, 504, 1732, 2496, 338, 3814, 24, 389, 3814, 14602, 216, 33, 32, 1232, 330, 3814, 25, 314, 216, 41, 1181, 670, 3814, 24, 330, 3814, 14602, 216, 33, 32, 1232, 389, 3814, 595, 669, 416, 325, 2855, 347, 354, 8345, 42, 198, 198, 76, 75, 389, 3814, 14602, 216, 33, 32, 1232, 330, 446, 330, 3814, 14602, 216, 33, 32, 1232, 389, 731, 216, 41, 3814, 77, 198, 198, 40810, 30053, 3814, 24, 330, 3814, 25, 284, 3814, 24, 389, 3814, 25, 351, 3814, 24, 216, 35, 3814, 25, 284, 3814, 24, 718, 3814, 643, 7827, 28, 392, 820, 42, 198, 198, 76, 75, 718, 3814, 14602, 216, 33, 32, 1232, 216, 35, 446, 216, 35, 3814, 14602, 216, 33, 32, 1232, 718, 731, 216, 41, 3814, 77, 198, 198, 8152, 439, 4318, 260, 8345, 42, 198, 198, 76, 75, 216, 33, 32, 73, 1232, 216, 35, 446, 216, 35, 32, 1232, 718, 731, 216, 41, 3814, 77, 198, 198, 76, 75, 216, 33, 32, 73, 1232, 216, 35, 446, 718, 1232, 216, 34, 33, 3814, 77, 198, 198, 7871, 38519, 3814]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.245353Z",
          "iopub.execute_input": "2024-12-08T12:35:17.245617Z",
          "iopub.status.idle": "2024-12-08T12:35:17.251054Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.245585Z",
          "shell.execute_reply": "2024-12-08T12:35:17.250168Z"
        },
        "outputId": "fe57ac0f-415d-40ae-f95d-fd9b6a60cff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.252107Z",
          "iopub.execute_input": "2024-12-08T12:35:17.252385Z",
          "iopub.status.idle": "2024-12-08T12:35:17.261241Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.252359Z",
          "shell.execute_reply": "2024-12-08T12:35:17.260448Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.262291Z",
          "iopub.execute_input": "2024-12-08T12:35:17.262568Z",
          "iopub.status.idle": "2024-12-08T12:35:17.272655Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.262543Z",
          "shell.execute_reply": "2024-12-08T12:35:17.271919Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.273486Z",
          "iopub.execute_input": "2024-12-08T12:35:17.273736Z",
          "iopub.status.idle": "2024-12-08T12:35:17.281832Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.273692Z",
          "shell.execute_reply": "2024-12-08T12:35:17.281124Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "\n",
        "#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.282672Z",
          "iopub.execute_input": "2024-12-08T12:35:17.282979Z",
          "iopub.status.idle": "2024-12-08T12:35:17.292305Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.282953Z",
          "shell.execute_reply": "2024-12-08T12:35:17.291589Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:17.293298Z",
          "iopub.execute_input": "2024-12-08T12:35:17.293587Z",
          "iopub.status.idle": "2024-12-08T12:35:18.410547Z",
          "shell.execute_reply.started": "2024-12-08T12:35:17.293563Z",
          "shell.execute_reply": "2024-12-08T12:35:18.409625Z"
        },
        "outputId": "08d193b6-8ca5-48f5-edfb-00fa7f5b03fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 34,734,080 || all params: 396,555,200 || trainable%: 8.7590\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:18.411770Z",
          "iopub.execute_input": "2024-12-08T12:35:18.412158Z",
          "iopub.status.idle": "2024-12-08T12:35:18.427274Z",
          "shell.execute_reply.started": "2024-12-08T12:35:18.412117Z",
          "shell.execute_reply": "2024-12-08T12:35:18.426638Z"
        },
        "outputId": "354f6c91-7f63-4483-af1e-548c014c6b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 239268800\nTrainable parameters : 34734080\nTrainable percentage: 14.52%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:18.428030Z",
          "iopub.execute_input": "2024-12-08T12:35:18.428327Z",
          "iopub.status.idle": "2024-12-08T12:35:21.240163Z",
          "shell.execute_reply.started": "2024-12-08T12:35:18.428278Z",
          "shell.execute_reply": "2024-12-08T12:35:21.239247Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:21.241330Z",
          "iopub.execute_input": "2024-12-08T12:35:21.241674Z",
          "iopub.status.idle": "2024-12-08T12:35:21.279035Z",
          "shell.execute_reply.started": "2024-12-08T12:35:21.241642Z",
          "shell.execute_reply": "2024-12-08T12:35:21.278178Z"
        },
        "outputId": "8c3077b9-7b87-4a3c-ba38-9b98d6e7aa67"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec08_12-35-21_a2c7c129f410,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:21.280143Z",
          "iopub.execute_input": "2024-12-08T12:35:21.280393Z",
          "iopub.status.idle": "2024-12-08T12:35:22.427289Z",
          "shell.execute_reply.started": "2024-12-08T12:35:21.280362Z",
          "shell.execute_reply": "2024-12-08T12:35:22.426410Z"
        },
        "outputId": "a2e8c6dc-f1d8-4cd4-ef2c-1230fe05a9ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x79f5dd1a3670>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:35:22.428386Z",
          "iopub.execute_input": "2024-12-08T12:35:22.428653Z",
          "iopub.status.idle": "2024-12-08T12:43:46.693370Z",
          "shell.execute_reply.started": "2024-12-08T12:35:22.428625Z",
          "shell.execute_reply": "2024-12-08T12:43:46.692518Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:43:46.694631Z",
          "iopub.execute_input": "2024-12-08T12:43:46.694915Z",
          "iopub.status.idle": "2024-12-08T12:44:01.544111Z",
          "shell.execute_reply.started": "2024-12-08T12:43:46.694888Z",
          "shell.execute_reply": "2024-12-08T12:44:01.543184Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:01.545445Z",
          "iopub.execute_input": "2024-12-08T12:44:01.545816Z",
          "iopub.status.idle": "2024-12-08T12:44:03.069980Z",
          "shell.execute_reply.started": "2024-12-08T12:44:01.545776Z",
          "shell.execute_reply": "2024-12-08T12:44:03.068917Z"
        },
        "outputId": "b0b90b61-7bfa-46b4-90d5-0b0d6fe1d53d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/f794cd508df3bc77353d6cb4799e7bc42e5187ca/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 960,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2560,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 15,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 5,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/f794cd508df3bc77353d6cb4799e7bc42e5187ca/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 960,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2560,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 15,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 5,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:03.071243Z",
          "iopub.execute_input": "2024-12-08T12:44:03.071676Z",
          "iopub.status.idle": "2024-12-08T12:44:03.213543Z",
          "shell.execute_reply.started": "2024-12-08T12:44:03.071624Z",
          "shell.execute_reply": "2024-12-08T12:44:03.212543Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:03.214747Z",
          "iopub.execute_input": "2024-12-08T12:44:03.215121Z",
          "iopub.status.idle": "2024-12-08T12:44:03.225291Z",
          "shell.execute_reply.started": "2024-12-08T12:44:03.215084Z",
          "shell.execute_reply": "2024-12-08T12:44:03.224435Z"
        },
        "id": "8OmClinKxlOg",
        "outputId": "82d86b8e-7801-4800-8cf4-8085ff0715cc"
      },
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:03.226367Z",
          "iopub.execute_input": "2024-12-08T12:44:03.227202Z",
          "iopub.status.idle": "2024-12-08T12:44:04.022534Z",
          "shell.execute_reply.started": "2024-12-08T12:44:03.227156Z",
          "shell.execute_reply": "2024-12-08T12:44:04.021702Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "gxIcra1qxlOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:04.023731Z",
          "iopub.execute_input": "2024-12-08T12:44:04.024137Z",
          "iopub.status.idle": "2024-12-08T12:44:06.193783Z",
          "shell.execute_reply.started": "2024-12-08T12:44:04.024099Z",
          "shell.execute_reply": "2024-12-08T12:44:06.193016Z"
        },
        "id": "j1G2tdnWxlOg",
        "outputId": "4a6b4083-a750-4538-9d93-e66c6ece7315"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/f794cd508df3bc77353d6cb4799e7bc42e5187ca/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-360M-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 960,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 2560,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 15,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 5,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/f794cd508df3bc77353d6cb4799e7bc42e5187ca/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at HuggingFaceTB/SmolLM2-360M-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-360M-Instruct/snapshots/f794cd508df3bc77353d6cb4799e7bc42e5187ca/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 960, padding_idx=2)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=960, out_features=960, bias=False)\n          (k_proj): Linear4bit(in_features=960, out_features=320, bias=False)\n          (v_proj): Linear4bit(in_features=960, out_features=320, bias=False)\n          (o_proj): Linear4bit(in_features=960, out_features=960, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=960, out_features=2560, bias=False)\n          (up_proj): Linear4bit(in_features=960, out_features=2560, bias=False)\n          (down_proj): Linear4bit(in_features=2560, out_features=960, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((960,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.194898Z",
          "iopub.execute_input": "2024-12-08T12:44:06.195241Z",
          "iopub.status.idle": "2024-12-08T12:44:06.205588Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.195202Z",
          "shell.execute_reply": "2024-12-08T12:44:06.204838Z"
        },
        "id": "XXjot7aMxlOg",
        "outputId": "ab49609b-b4b9-4737-d531-6ce7ccd0e9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 204534720\nTrainable parameters : 47248320\nTrainable percentage: 23.10%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.206691Z",
          "iopub.execute_input": "2024-12-08T12:44:06.207012Z",
          "iopub.status.idle": "2024-12-08T12:44:06.234380Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.206987Z",
          "shell.execute_reply": "2024-12-08T12:44:06.233569Z"
        },
        "id": "h8dLaHzpxlOh",
        "outputId": "7e1e053f-200a-4b38-ae19-732537244ea5"
      },
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(49152, 960, padding_idx=2)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=960, bias=False)\n                  (default): Linear(in_features=64, out_features=960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=320, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=320, bias=False)\n                  (default): Linear(in_features=64, out_features=320, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=320, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=320, bias=False)\n                  (default): Linear(in_features=64, out_features=320, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=960, bias=False)\n                  (default): Linear(in_features=64, out_features=960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=2560, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2560, bias=False)\n                  (default): Linear(in_features=64, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=960, out_features=2560, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=960, out_features=64, bias=False)\n                  (default): Linear(in_features=960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2560, bias=False)\n                  (default): Linear(in_features=64, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2560, out_features=64, bias=False)\n                  (default): Linear(in_features=2560, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=960, bias=False)\n                  (default): Linear(in_features=64, out_features=960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((960,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.235434Z",
          "iopub.execute_input": "2024-12-08T12:44:06.235703Z",
          "iopub.status.idle": "2024-12-08T12:44:06.261005Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.235680Z",
          "shell.execute_reply": "2024-12-08T12:44:06.260169Z"
        },
        "id": "kgJu2ncFxlOh",
        "outputId": "53af64f2-b0d2-4ffd-8120-207a147535bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 274002880\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.261955Z",
          "iopub.execute_input": "2024-12-08T12:44:06.262262Z",
          "iopub.status.idle": "2024-12-08T12:44:06.270213Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.262237Z",
          "shell.execute_reply": "2024-12-08T12:44:06.269475Z"
        },
        "id": "hpAD-RlZxlOi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.271106Z",
          "iopub.execute_input": "2024-12-08T12:44:06.271380Z",
          "iopub.status.idle": "2024-12-08T12:44:06.279294Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.271355Z",
          "shell.execute_reply": "2024-12-08T12:44:06.278481Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:44:06.280489Z",
          "iopub.execute_input": "2024-12-08T12:44:06.280754Z",
          "iopub.status.idle": "2024-12-08T12:44:06.289639Z",
          "shell.execute_reply.started": "2024-12-08T12:44:06.280730Z",
          "shell.execute_reply": "2024-12-08T12:44:06.288918Z"
        },
        "id": "dcylHqnSxlOi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T13:00:15.926466Z",
          "iopub.execute_input": "2024-12-08T13:00:15.926734Z",
          "iopub.status.idle": "2024-12-08T13:00:30.498820Z",
          "shell.execute_reply.started": "2024-12-08T13:00:15.926708Z",
          "shell.execute_reply": "2024-12-08T13:00:30.497910Z"
        },
        "outputId": "6fbf2a89-ea2f-46e4-826f-e30ab8a4f803"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    204534720                      |                     274002880                     \n================================================== | ==================================================\n### Question: A rectangle has a perimeter of 28     |  ### Question: A rectangle has a perimeter of 28   \ncentimeters (cm) and a width of 6 centimeters       |  centimeters (cm) and a width of 6 centimeters     \n(cm). Find the area of this rectangle. ### Answer:  |  (cm). Find the area of this rectangle. ### Answer:\nThe area of a rectangle is given by the formula:    |  The area of a rectangle is given by the formula:  \nArea = Length × Width  In this case, the length is  |  Area = Length × Width  In this case, the length is\n6 centimeters (cm) and the width is 6 centimeters   |  6 cm and the width is 6 cm. Plugging these values \n(cm).  Area = 6 cm × 6 cm  Area = 36 square         |  into the formula, we get:  Area = 6 cm × 6 cm     \ncentimeters (cm²)  So, the area of the rectangle    |  Area = 36 square centimeters  So, the area of the \nis 36 square centimeters (cm²).                     |  rectangle is 36 square centimeters.               \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:54:42.077106Z",
          "iopub.execute_input": "2024-12-08T12:54:42.077378Z",
          "iopub.status.idle": "2024-12-08T12:57:27.271696Z",
          "shell.execute_reply.started": "2024-12-08T12:54:42.077352Z",
          "shell.execute_reply": "2024-12-08T12:57:27.270672Z"
        },
        "outputId": "9427c42a-5eb1-4218-ac38-7d1e99c66a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    204534720                      |                     274002880                     \n================================================== | ==================================================\n### Question: A cleaning company produces two       |  ### Question: A cleaning company produces two     \nsanitizer sprays. One spray kills 50% of germs,     |  sanitizer sprays. One spray kills 50% of germs,   \nand another spray kills 25% of germs. However, a    |  and another spray kills 25% of germs. However, a  \ncertain percentage of the germs they kill are the   |  certain percentage of the germs they kill are the \nsame ones. After using both sanitizer sprays        |  same ones. After using both sanitizer sprays      \ntogether, 30% of germs would be left. What          |  together, 30% of germs would be left. What        \npercentage of germs do both sprays kill in common?  |  percentage of germs do both sprays kill in common?\n### Answer:  The answer is: 100%  Step-by-step      |  ### Answer:  The answer is: 100%  Step-by-step    \nreasoning process: 1. Identify the total            |  reasoning process: 1. Identify the total          \npercentage of germs killed by the sanitizer         |  percentage of germs killed by the sanitizer       \nsprays: 50% + 25% = 75% 2. Calculate the            |  sprays: 50% + 25% = 75% 2. Calculate the          \npercentage of germs killed by the sanitizer sprays  |  percentage of germs killed by the sanitizer sprays\nthat are common to both sprays: 30% of 75% = 22.5%  |  that are common to both sprays: 30% of 75% = 22.5%\n3. Add the percentage of germs killed by the        |  3. Add the percentage of germs killed by the      \nsanitizer sprays that are common to both sprays to  |  sanitizer sprays that are common to both sprays to\nthe total percentage of germs killed by the         |  the total percentage of germs killed by the       \nsanitizer sprays: 75% + 22.5% = 100%  Answer: 100%  |  sanitizer sprays: 75% + 22.5% = 100%  Answer: 100%\nQuestion: A bat and a ball together cost $1.10.     |  Question: A bat and a ball together cost $1.10.   \nThe bat costs $1.00 more than the ball. How much    |  The bat costs $1.00 more than the ball. How much  \ndoes the ball cost?  Answer:  The answer is: 5      |  does the ball cost?  Answer:  The answer is: 5    \ncents  Step-by-step reasoning process: 1. Identify  |  cents  Step-by-step reasoning process: 1. Identify\nthe information given: The bat costs $1.00 more     |  the information given: The bat costs $1.00 more   \nthan the ball. 2. Identify the unknown: The cost    |  than the ball. 2. Identify the unknown: The cost  \nof the ball. 3. Use the information to set up an    |  of the ball. 3. Use the information to set up an  \nequation: Let x be the cost of the ball. Then the   |  equation: Let x be the cost of the ball. Then the \nbat costs x + $1.00. 4. Solve the equation: x + (x  |  bat costs x + $1.00. 4. Solve the equation: x + (x\n+ $1.00) = $1.10 5. Simplify the equation: 2x +     |  + $1.00) = $1.10 5. Simplify the equation: 2x +   \n$1.00 = $1.10 6. Subtract $1.00 from both sides:    |  $1.00 = $1.10 6. Subtract $1.00 from both sides:  \n2x = $0.10 7. Divide both sides by 2: x = $0.05     |  2x = $0.10 7. Divide both sides by 2: x = $0.05   \nAnswer: 5 cents  Question: A snail is at the        |  Answer: 5 cents  Question: A snail is at the      \nbottom of a 20-foot well. Each day, it climbs up 3  |  bottom of a 20-foot well. Each day, it climbs up 3\nfeet, but at night, it slips back 2 feet. How many  |  feet, but at night, it slips back 2 feet. How many\ndays will it take for the snail to reach the top    |  days will it take for the snail to reach the top  \nof the well?  Answer:  The answer is: 18 days       |  of the well?  Answer:  The answer is: 18 days     \nStep-by-step reasoning process: 1. Identify the     |  Step-by-step reasoning process: 1. Identify the   \npattern: The snail climbs 3 feet during the day     |  pattern: The snail climbs 3 feet during the day   \nand slips back 2 feet at night. 2. Calculate the    |  and slips back 2 feet at night. 2. Calculate the  \nprogress: The snail climbs 3 feet in 18 days,       |  progress: The snail climbs 3 feet in 18 days,     \nsince it slips back 2 feet each night. 3.           |  since it slips back 2 feet each night. 3.         \nDetermine the total distance: The snail climbs 3    |  Determine the total distance: The snail climbs 3  \nfeet in 18 days, so it climbs 20 feet in total. 4.  |  feet in 18 days, so it climbs 20 feet in total. 4.\nCalculate the total progress: The snail climbs 20   |  Calculate the total progress: The snail climbs 20 \nfeet in 18 days, so it climbs 1 foot per day. 5.    |  feet in 18 days, so it climbs 1 foot per day. 5.  \nDetermine the number of days: Since the snail       |  Determine the number of days: Since the snail     \nclimbs 3 feet in 18 days, it takes 18 days to       |  climbs 3 feet in 18 days, it takes 18 days to     \nclimb 18 feet. 6. Calculate the total progress:     |  climb 18 feet. 6. Calculate the total progress:   \nThe snail climbs 1 foot per day. 7. Determine the   |  The snail climbs 20 feet in 18 days, so it climbs \nnumber of days: Since the snail climbs 3 feet in    |  1 foot per day. 7. Determine the number of days:  \n18 days, it takes 18 days to climb 20 feet. 8.      |  Since the snail climbs 3 feet in 18 days, it takes\nCalculate the total progress: The snail climbs 1    |  18 days to climb 18 feet. 8. Calculate the total  \nfoot per day. 9. Determine the number of days:      |  progress: The snail climbs 20 feet in 18 days, so \nSince the snail climbs 3 feet in 18 days, it takes  |  it climbs 1 foot per day. 9. Determine the number \n18 days to climb 20 feet. 10. Calculate the total   |  of days: Since the snail climbs 3 feet in 18 days,\nprogress: The snail climbs 1 foot per day. 11.      |  it takes 18 days to climb 18 feet. 10. Calculate  \nDetermine the number of days: Since the snail       |  the total progress: The snail climbs 20 feet in 18\nclimbs 3 feet in 18 days, it takes 18 days to       |  days, so it climbs 1 foot per day. 11. Determine  \nclimb 20 feet. 12. Calculate the total progress:    |  the number of days: Since the snail climbs 3 feet \nThe snail climbs 1 foot per day. 13. Determine the  |  in 18 days, it takes 18 days to climb 18 feet. 12.\nnumber of days: Since the snail climbs 3 feet in    |  Calculate the total progress: The snail climbs 20 \n18 days, it takes 18 days to climb 20 feet. 14.     |  feet in 18 days, so it climbs 1 foot per day. 13. \nCalculate the total progress: The snail climbs 1    |  Determine the number of days: Since the snail     \nfoot per day. 15. Determine the number of days:     |  climbs 3 feet in 18 days, it takes 18 days to     \nSince the snail climbs 3 feet in 18 days, it takes  |  climb 18 feet. 14. Calculate the total progress:  \n18 days to climb 20 feet. 16. Calculate the total   |  The snail climbs 20 feet in 18 days, so it climbs \nprogress: The snail climbs 1 foot per day. 17.      |  1 foot per day. 15. Determine the number of days: \nDetermine the number of days: Since the snail       |  Since the snail climbs 3 feet in 18 days, it takes\nclimbs 3 feet in 18 days, it takes 18 days to       |  18 days to climb 18 feet. 16. Calculate the total \nclimb 20 feet. 18. Calculate the total progress:    |  progress: The snail climbs 20 feet in 18 days, so \nThe snail climbs 1 foot per day. 19. Determine the  |  it climbs 1 foot per day. 17. Determine the number\nnumber of days: Since the snail climbs 3 feet in    |  of days: Since the snail climbs 3 feet in 18 days,\n18 days, it takes 18 days to climb 20 feet. 20.     |  it takes 18 days to climb 18 feet. 18. Calculate  \nCalculate the total progress: The snail climbs 1    |                                                    \nfoot per day. 21. Determine the number of days:     |                                                    \nSince the snail clim                                |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T13:56:16.667841Z",
          "iopub.execute_input": "2024-12-08T13:56:16.668670Z",
          "iopub.status.idle": "2024-12-08T13:59:00.484319Z",
          "shell.execute_reply.started": "2024-12-08T13:56:16.668636Z",
          "shell.execute_reply": "2024-12-08T13:59:00.483511Z"
        },
        "outputId": "124140cf-78e1-414c-8168-cea650d4cd14"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    204534720                      |                     274002880                     \n================================================== | ==================================================\n### Question: How many three-digit numbers are      |  ### Question: How many three-digit numbers are    \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  divisible by 6, 5, 8, and 9? ### Answer:  The     \nanswer is 12.  Question: How many three-digit       |  answer is 12.  Question: What is the remainder    \nnumbers are divisible by 6, 5, 8, and 9? ###        |  when 2^100 is divided by 7? ### Answer:  The      \nAnswer:  The answer is 12.  Question: How many      |  answer is 1.  Question: What is the remainder when\nthree-digit numbers are divisible by 6, 5, 8, and   |  2^100 is divided by 7? ### Answer:  The answer is \n9? ### Answer:  The answer is 12.  Question: How    |  1.  Question: What is the remainder when 2^100 is \nmany three-digit numbers are divisible by 6, 5, 8,  |  divided by 7? ### Answer:  The answer is 1.       \nand 9? ### Answer:  The answer is 12.  Question:    |  Question: What is the remainder when 2^100 is     \nHow many three-digit numbers are divisible by 6,    |  divided by 7? ### Answer:  The answer is 1.       \n5, 8, and 9? ### Answer:  The answer is 12.         |  Question: What is the remainder when 2^100 is     \nQuestion: How many three-digit numbers are          |  divided by 7? ### Answer:  The answer is 1.       \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  Question: What is the remainder when 2^100 is     \nanswer is 12.  Question: How many three-digit       |  divided by 7? ### Answer:  The answer is 1.       \nnumbers are divisible by 6, 5, 8, and 9? ###        |  Question: What is the remainder when 2^100 is     \nAnswer:  The answer is 12.  Question: How many      |  divided by 7? ### Answer:  The answer is 1.       \nthree-digit numbers are divisible by 6, 5, 8, and   |  Question: What is the remainder when 2^100 is     \n9? ### Answer:  The answer is 12.  Question: How    |  divided by 7? ### Answer:  The answer is 1.       \nmany three-digit numbers are divisible by 6, 5, 8,  |  Question: What is the remainder when 2^100 is     \nand 9? ### Answer:  The answer is 12.  Question:    |  divided by 7? ### Answer:  The answer is 1.       \nHow many three-digit numbers are divisible by 6,    |  Question: What is the remainder when 2^100 is     \n5, 8, and 9? ### Answer:  The answer is 12.         |  divided by 7? ### Answer:  The answer is 1.       \nQuestion: How many three-digit numbers are          |  Question: What is the remainder when 2^100 is     \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  divided by 7? ### Answer:  The answer is 1.       \nanswer is 12.  Question: How many three-digit       |  Question: What is the remainder when 2^100 is     \nnumbers are divisible by 6, 5, 8, and 9? ###        |  divided by 7? ### Answer:  The answer is 1.       \nAnswer:  The answer is 12.  Question: How many      |  Question: What is the remainder when 2^100 is     \nthree-digit numbers are divisible by 6, 5, 8, and   |  divided by 7? ### Answer:  The answer is 1.       \n9? ### Answer:  The answer is 12.  Question: How    |  Question: What is the remainder when 2^100 is     \nmany three-digit numbers are divisible by 6, 5, 8,  |  divided by 7? ### Answer:  The answer is 1.       \nand 9? ### Answer:  The answer is 12.  Question:    |  Question: What is the remainder when 2^100 is     \nHow many three-digit numbers are divisible by 6,    |  divided by 7? ### Answer:  The answer is 1.       \n5, 8, and 9? ### Answer:  The answer is 12.         |  Question: What is the remainder when 2^100 is     \nQuestion: How many three-digit numbers are          |  divided by 7? ### Answer:  The answer is 1.       \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  Question: What is the remainder when 2^100 is     \nanswer is 12.  Question: How many three-digit       |  divided by 7? ### Answer:  The answer is 1.       \nnumbers are divisible by 6, 5, 8, and 9? ###        |  Question: What is the remainder when 2^100 is     \nAnswer:  The answer is 12.  Question: How many      |  divided by 7? ### Answer:  The answer is 1.       \nthree-digit numbers are divisible by 6, 5, 8, and   |  Question: What is the remainder when 2^100 is     \n9? ### Answer:  The answer is 12.  Question: How    |  divided by 7? ### Answer:  The answer is 1.       \nmany three-digit numbers are divisible by 6, 5, 8,  |  Question: What is the remainder when 2^100 is     \nand 9? ### Answer:  The answer is 12.  Question:    |  divided by 7? ### Answer:  The answer is 1.       \nHow many three-digit numbers are divisible by 6,    |  Question: What is the remainder when 2^100 is     \n5, 8, and 9? ### Answer:  The answer is 12.         |  divided by 7? ### Answer:  The answer is 1.       \nQuestion: How many three-digit numbers are          |  Question: What is the remainder when 2^100 is     \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  divided by 7? ### Answer:  The answer is 1.       \nanswer is 12.  Question: How many three-digit       |  Question: What is the remainder when 2^100 is     \nnumbers are divisible by 6, 5, 8, and 9? ###        |  divided by 7? ### Answer:  The answer is 1.       \nAnswer:  The answer is 12.  Question: How many      |  Question: What is the remainder when 2^100 is     \nthree-digit numbers are divisible by 6, 5, 8, and   |  divided by 7? ### Answer:  The answer is 1.       \n9? ### Answer:  The answer is 12.  Question: How    |  Question: What is the remainder when 2^100 is     \nmany three-digit numbers are divisible by 6, 5, 8,  |  divided by 7? ### Answer:  The answer is 1.       \nand 9? ### Answer:  The answer is 12.  Question:    |  Question: What is the remainder when 2^100 is     \nHow many three-digit numbers are divisible by 6,    |  divided by 7? ### Answer:  The answer is 1.       \n5, 8, and 9? ### Answer:  The answer is 12.         |  Question: What is the remainder when 2^100 is     \nQuestion: How many three-digit numbers are          |  divided by 7? ### Answer:  The answer is 1.       \ndivisible by 6, 5, 8, and 9? ### Answer:  The       |  Question: What is the remainder when 2^100 is     \nanswer is 12.  Question: How many three-digit       |  divided by 7? ### Answer:  The answer is 1.       \nnumbers are divisible by 6                          |  Question: What is the remainder when 2^100 is     \n                                                    |  divided by 7? ### Answer:  The answer is 1.       \n                                                    |  Question: What is the remainder when 2^100 is     \n                                                    |  divided by 7? ### Answer:  The answer             \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:49:34.526529Z",
          "iopub.execute_input": "2024-12-08T12:49:34.527198Z",
          "iopub.status.idle": "2024-12-08T12:51:21.070472Z",
          "shell.execute_reply.started": "2024-12-08T12:49:34.527147Z",
          "shell.execute_reply": "2024-12-08T12:51:21.069585Z"
        },
        "outputId": "da0d3992-72c9-4e99-86a7-9982c82d137e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    204534720                      |                     274002880                     \n================================================== | ==================================================\n### Question: How many numbers greater than 1.1     |  ### Question: How many numbers greater than 1.1   \nare there in 1.4, 9/10, 1.2, 0.5, and 13/10? ###    |  are there in 1.4, 9/10, 1.2, 0.5, and 13/10? ###  \nAnswer:  Question: How many numbers greater than    |  Answer:  The numbers greater than 1.1 are 2, 3, 4,\n1.1 are there in 1.4, 9/10, 1.2, 0.5, and 13/10?    |  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\nAnswer:                                             |  19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,   \n                                                    |  31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,   \n                                                    |  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,   \n                                                    |  55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,   \n                                                    |  67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78,   \n                                                    |  79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,   \n                                                    |  91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102,\n                                                    |  103, 104, 105, 106, 107, 108, 109, 110, 111, 112, \n                                                    |  113, 114, 115, 116, 117, 118, 119, 120, 121, 122, \n                                                    |  123, 124, 125, 126, 127, 128, 129, 130, 131, 132, \n                                                    |  133, 134, 135, 136, 137, 138, 139, 140, 141, 142, \n                                                    |  143, 144, 145, 146, 147, 148, 149, 150, 151, 152, \n                                                    |  153, 154, 155, 156, 157, 158, 159, 160, 161, 162, \n                                                    |  163, 164, 165, 166, 167, 168, 169, 170, 171, 172, \n                                                    |  173, 174, 175, 176, 177, 178, 179, 180, 181, 182, \n                                                    |  183, 184, 185, 186, 187, 188, 189, 190, 191, 192, \n                                                    |  193, 194, 195, 196, 197, 198, 199, 200, 201, 202, \n                                                    |  203, 204, 205, 206, 207, 208, 209, 210, 211, 212, \n                                                    |  213, 214, 215, 216, 217, 218, 219, 220, 221, 222, \n                                                    |  223, 224, 225,                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T13:27:15.321997Z",
          "iopub.execute_input": "2024-12-08T13:27:15.322383Z",
          "iopub.status.idle": "2024-12-08T13:28:47.350594Z",
          "shell.execute_reply.started": "2024-12-08T13:27:15.322350Z",
          "shell.execute_reply": "2024-12-08T13:28:47.349733Z"
        },
        "outputId": "b221e4c7-49c5-4f6e-bd96-09cd326b3437"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    204534720                      |                     274002880                     \n================================================== | ==================================================\n### Question: Two tapes of the same length are      |  ### Question: Two tapes of the same length are    \nstacked together and overlapped resulting in a      |  stacked together and overlapped resulting in a    \ntotal length of 512 centimeters (cm). If the        |  total length of 512 centimeters (cm). If the      \nlength of one piece of tape is 275 centimeters      |  length of one piece of tape is 275 centimeters    \n(cm), how many centimeters (cm) is the overlap?     |  (cm), how many centimeters (cm) is the overlap?   \n### Answer:  The answer is: 275  Question: A snail  |  ### Answer:  The answer is: 275  Question: A snail\nis at the bottom of a 20-foot well. Each day, it    |  is at the bottom of a 20-foot well. Each day, it  \nclimbs up 3 feet, but at night, it slips back 2     |  climbs up 3 feet, but at night, it slips back 2   \nfeet. How many days will it take for the snail to   |  feet. How many days will it take for the snail to \nreach the top of the well?  Answer:  The answer     |  reach the top of the well?  Answer:  The answer   \nis: 18  Question: A bat and a ball together cost    |  is: 18  Question: A bat and a ball together cost  \n$1.10. The bat costs $1.00 more than the ball. How  |  $1.10. The bat costs $1.00 more than the ball. How\nmuch does the ball cost?  Answer:  The answer is:   |  much does the ball cost?  Answer:  The answer is: \n10 cents  Question: A snail is at the bottom of a   |  10 cents  Question: A snail is at the bottom of a \n20-foot well. Each day, it climbs up 3 feet, but    |  20-foot well. Each day, it climbs up 3 feet, but  \nat night, it slips back 2 feet. How many days will  |  at night, it slips back 2 feet. How many days will\nit take for the snail to reach the top of the       |  it take for the snail to reach the top of the     \nwell?  Answer:  The answer is: 20  Question: A      |  well?  Answer:  The answer is: 20  Question: A    \nsnail is at the bottom of a 20-foot well. Each      |  snail is at the bottom of a 20-foot well. Each    \nday, it climbs up 3 feet, but at night, it slips    |  day, it climbs up 3 feet, but at night, it slips  \nback 2 feet. How many days will it take for the     |  back 2 feet. How many days will it take for the   \nsnail to reach the top of the well?  Answer:  The   |  snail to reach the top of the well?  Answer:  The \nanswer is: 20  Question: A bat and a ball together  |  answer is: 20  What is the answer to this         \ncost $1.10. The bat costs $1.00 more than the       |  question? A bat and a ball together cost $1.10.   \nball. How much does the ball cost?  Answer:  The    |  The bat costs $1.00 more than the ball. How much  \nanswer is: 10 cents  Question: A bat and a ball     |  does the ball cost?                               \ntogether cost $1.10. The bat costs $1.00 more than  |                                                    \nthe ball. How much does the ball cost?  Answer:     |                                                    \nThe answer is: 10 cents  Question: A bat and a      |                                                    \nball together cost $1.10. The bat costs $1.00 more  |                                                    \nthan the ball. How much does the ball cost?         |                                                    \nAnswer:  The answer is: 10 cents  Question: A bat   |                                                    \nand a ball together cost $1.10. The bat costs       |                                                    \n$1.00 more than the ball. How much does the ball    |                                                    \ncost?  Answer:  The answer is: 10 cents  Question:  |                                                    \nA bat and a ball together cost $1.10. The bat       |                                                    \ncosts $1.00 more than the ball. How much does the   |                                                    \nball cost?  Answer:  The answer is: 10 cents        |                                                    \nQuestion: A bat and a ball together cost $1.10.     |                                                    \nThe bat costs $1.00 more than the ball. How much    |                                                    \ndoes the ball cost?  Answer:  The answer is: 10     |                                                    \ncents  Question: A bat and a ball together cost     |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The bat costs $1.00 more than the ball. How  |                                                    \nmuch does the ball cost?  Answer:  The answer is:   |                                                    \n10 cents  Question: A bat and a ball together cost  |                                                    \n$1.10. The                                          |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}