{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Llama3.1_8B_Storm_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:26:17.388147Z",
          "iopub.execute_input": "2024-11-25T11:26:17.390746Z",
          "iopub.status.idle": "2024-11-25T11:27:06.336815Z",
          "shell.execute_reply.started": "2024-11-25T11:26:17.390684Z",
          "shell.execute_reply": "2024-11-25T11:27:06.335809Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-25T11:27:06.338534Z",
          "iopub.execute_input": "2024-11-25T11:27:06.338845Z",
          "iopub.status.idle": "2024-11-25T11:27:24.961412Z",
          "shell.execute_reply.started": "2024-11-25T11:27:06.338817Z",
          "shell.execute_reply": "2024-11-25T11:27:24.960295Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-25T11:27:24.962940Z",
          "iopub.execute_input": "2024-11-25T11:27:24.963258Z",
          "iopub.status.idle": "2024-11-25T11:27:24.972246Z",
          "shell.execute_reply.started": "2024-11-25T11:27:24.963233Z",
          "shell.execute_reply": "2024-11-25T11:27:24.970537Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'unsloth/Llama-3.1-Storm-8B'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:27:24.974579Z",
          "iopub.execute_input": "2024-11-25T11:27:24.974850Z",
          "iopub.status.idle": "2024-11-25T11:27:25.005192Z",
          "shell.execute_reply.started": "2024-11-25T11:27:24.974816Z",
          "shell.execute_reply": "2024-11-25T11:27:25.004126Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:27:25.006185Z",
          "iopub.execute_input": "2024-11-25T11:27:25.006445Z",
          "iopub.status.idle": "2024-11-25T11:27:25.016335Z",
          "shell.execute_reply.started": "2024-11-25T11:27:25.006420Z",
          "shell.execute_reply": "2024-11-25T11:27:25.015561Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:27:25.017303Z",
          "iopub.execute_input": "2024-11-25T11:27:25.017576Z",
          "iopub.status.idle": "2024-11-25T11:34:43.478861Z",
          "shell.execute_reply.started": "2024-11-25T11:27:25.017549Z",
          "shell.execute_reply": "2024-11-25T11:34:43.478002Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:43.480007Z",
          "iopub.execute_input": "2024-11-25T11:34:43.480235Z",
          "iopub.status.idle": "2024-11-25T11:34:43.488059Z",
          "shell.execute_reply.started": "2024-11-25T11:34:43.480211Z",
          "shell.execute_reply": "2024-11-25T11:34:43.487130Z"
        },
        "outputId": "2341f2f4-f721-462f-d986-b7a5e2f09466"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540600320\nTrainable parameters : 1050939392\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:43.489416Z",
          "iopub.execute_input": "2024-11-25T11:34:43.489683Z",
          "iopub.status.idle": "2024-11-25T11:34:45.275547Z",
          "shell.execute_reply.started": "2024-11-25T11:34:43.489657Z",
          "shell.execute_reply": "2024-11-25T11:34:45.274857Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:45.276645Z",
          "iopub.execute_input": "2024-11-25T11:34:45.276928Z",
          "iopub.status.idle": "2024-11-25T11:34:45.280772Z",
          "shell.execute_reply.started": "2024-11-25T11:34:45.276902Z",
          "shell.execute_reply": "2024-11-25T11:34:45.279851Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:45.284054Z",
          "iopub.execute_input": "2024-11-25T11:34:45.284276Z",
          "iopub.status.idle": "2024-11-25T11:34:45.306552Z",
          "shell.execute_reply.started": "2024-11-25T11:34:45.284254Z",
          "shell.execute_reply": "2024-11-25T11:34:45.305745Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:45.307550Z",
          "iopub.execute_input": "2024-11-25T11:34:45.307896Z",
          "iopub.status.idle": "2024-11-25T11:34:48.118154Z",
          "shell.execute_reply.started": "2024-11-25T11:34:45.307870Z",
          "shell.execute_reply": "2024-11-25T11:34:48.117408Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.119078Z",
          "iopub.execute_input": "2024-11-25T11:34:48.119306Z",
          "iopub.status.idle": "2024-11-25T11:34:48.125589Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.119283Z",
          "shell.execute_reply": "2024-11-25T11:34:48.124740Z"
        },
        "id": "YUjljx-dXN_U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.126650Z",
          "iopub.execute_input": "2024-11-25T11:34:48.126936Z",
          "iopub.status.idle": "2024-11-25T11:34:48.148171Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.126911Z",
          "shell.execute_reply": "2024-11-25T11:34:48.147352Z"
        },
        "outputId": "615acbcd-88af-4b33-cfe6-79ed6bd550b0"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.149194Z",
          "iopub.execute_input": "2024-11-25T11:34:48.149551Z",
          "iopub.status.idle": "2024-11-25T11:34:48.156973Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.149505Z",
          "shell.execute_reply": "2024-11-25T11:34:48.156085Z"
        },
        "outputId": "cef66179-320a-4971-d636-4576380ed1a6"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.157935Z",
          "iopub.execute_input": "2024-11-25T11:34:48.158187Z",
          "iopub.status.idle": "2024-11-25T11:34:48.167823Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.158159Z",
          "shell.execute_reply": "2024-11-25T11:34:48.167056Z"
        },
        "outputId": "b1efa3f2-484b-4ae6-b6ea-397f09091e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.169006Z",
          "iopub.execute_input": "2024-11-25T11:34:48.169349Z",
          "iopub.status.idle": "2024-11-25T11:34:48.179480Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.169313Z",
          "shell.execute_reply": "2024-11-25T11:34:48.178723Z"
        },
        "id": "sgqAc-RnXN_V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.180422Z",
          "iopub.execute_input": "2024-11-25T11:34:48.180754Z",
          "iopub.status.idle": "2024-11-25T11:34:48.189952Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.180718Z",
          "shell.execute_reply": "2024-11-25T11:34:48.189214Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.190887Z",
          "iopub.execute_input": "2024-11-25T11:34:48.191207Z",
          "iopub.status.idle": "2024-11-25T11:34:48.739808Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.191171Z",
          "shell.execute_reply": "2024-11-25T11:34:48.738925Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.740938Z",
          "iopub.execute_input": "2024-11-25T11:34:48.741207Z",
          "iopub.status.idle": "2024-11-25T11:34:48.746161Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.741182Z",
          "shell.execute_reply": "2024-11-25T11:34:48.745305Z"
        },
        "outputId": "37c416d0-19b6-4591-feda-bc64088ddb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.747417Z",
          "iopub.execute_input": "2024-11-25T11:34:48.747768Z",
          "iopub.status.idle": "2024-11-25T11:34:48.769399Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.747731Z",
          "shell.execute_reply": "2024-11-25T11:34:48.768767Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:48.770388Z",
          "iopub.execute_input": "2024-11-25T11:34:48.770615Z",
          "iopub.status.idle": "2024-11-25T11:34:56.772536Z",
          "shell.execute_reply.started": "2024-11-25T11:34:48.770592Z",
          "shell.execute_reply": "2024-11-25T11:34:56.771613Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.773656Z",
          "iopub.execute_input": "2024-11-25T11:34:56.773946Z",
          "iopub.status.idle": "2024-11-25T11:34:56.780666Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.773919Z",
          "shell.execute_reply": "2024-11-25T11:34:56.779714Z"
        },
        "outputId": "7e7afe88-290e-4e4a-da87-6f2bbe0fbd94"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.781677Z",
          "iopub.execute_input": "2024-11-25T11:34:56.781944Z",
          "iopub.status.idle": "2024-11-25T11:34:56.853878Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.781918Z",
          "shell.execute_reply": "2024-11-25T11:34:56.853039Z"
        },
        "outputId": "d164c92a-a533-4be0-da81-4b60b03b4c3c"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.854901Z",
          "iopub.execute_input": "2024-11-25T11:34:56.855163Z",
          "iopub.status.idle": "2024-11-25T11:34:56.865976Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.855138Z",
          "shell.execute_reply": "2024-11-25T11:34:56.865132Z"
        },
        "outputId": "8d7c991d-9fe8-4e77-ccf6-cd7dfe6c8313"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.867091Z",
          "iopub.execute_input": "2024-11-25T11:34:56.867674Z",
          "iopub.status.idle": "2024-11-25T11:34:56.892126Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.867637Z",
          "shell.execute_reply": "2024-11-25T11:34:56.891303Z"
        },
        "outputId": "9b19f1d5-44d8-47f0-85f4-59d1c690c8cd"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [128004, 128004, 128004, 128004, 128004, 12800...   \n1  [128004, 128004, 128004, 128004, 128004, 12800...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128004, 128004, 128004, 128004, 128004, 12800...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.893211Z",
          "iopub.execute_input": "2024-11-25T11:34:56.893827Z",
          "iopub.status.idle": "2024-11-25T11:34:56.898312Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.893774Z",
          "shell.execute_reply": "2024-11-25T11:34:56.897405Z"
        },
        "outputId": "8e88d9db-a157-4fb8-b460-1c5ec92ba84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and Iâ€”\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.899515Z",
          "iopub.execute_input": "2024-11-25T11:34:56.899853Z",
          "iopub.status.idle": "2024-11-25T11:34:56.909777Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.899818Z",
          "shell.execute_reply": "2024-11-25T11:34:56.908994Z"
        },
        "outputId": "cf5af706-9788-4f44-dff8-38ac836d87c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 11, 35526, 449, 459, 1988, 430, 5825, 4726, 2317, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 2127, 56956, 279, 2728, 33894, 323, 10765, 1202, 1925, 7057, 382, 14711, 5688, 512, 11874, 19795, 37441, 3640, 304, 264, 14071, 7732, 27362, 77, 3112, 14931, 358, 1436, 539, 5944, 2225, 1734, 3112, 387, 832, 63865, 11, 1317, 358, 14980, 1734, 3112, 7111, 1523, 832, 439, 3117, 439, 358, 1436, 1734, 1271, 1405, 433, 30280, 304, 279, 1234, 74189, 18364, 77, 1734, 12487, 3952, 279, 1023, 11, 439, 1120, 439, 6762, 27362, 77, 3112, 3515, 8530, 279, 2731, 3802, 27362, 77, 18433, 433, 574, 16763, 88, 323, 4934, 10051, 18364, 77, 27831, 439, 369, 430, 279, 12579, 1070, 1734, 56568, 24634, 1124, 2216, 922, 279, 1890, 27362, 89330, 19795, 430, 6693, 18813, 11203, 1734, 644, 11141, 912, 3094, 1047, 8348, 11025, 3776, 7255, 77, 12174, 11, 358, 2163, 279, 1176, 369, 2500, 1938, 15114, 77, 29174, 14392, 1268, 1648, 11767, 389, 311, 1648, 27362, 77, 40, 93762, 422, 358, 1288, 3596, 2586, 1203, 7255, 77, 1734, 40, 4985, 387, 11890, 420, 449, 264, 31238, 1734, 50982, 61752, 17051, 323, 17051, 16472, 7338, 77, 11874, 19795, 37441, 3640, 304, 264, 7732, 11, 323, 358, 2345, 59, 77, 40, 3952, 279, 832, 2753, 31796, 555, 27362, 77, 3112, 430, 706, 1903, 682, 279, 6811, 382, 14711, 6075, 512, 791, 1925, 7057, 315, 279, 33894, 374, 279, 12939, 315, 3339, 11709, 323, 279, 5536, 315, 1884, 11709, 389, 832, 596, 2324, 13, 578, 19114, 374, 17011, 449, 264, 5597, 1990, 1403, 13006, 323, 13967, 41011, 279, 832, 2753, 31796, 11, 902, 13967, 21483, 872, 2324, 3217, 13, 128009]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.915479Z",
          "iopub.execute_input": "2024-11-25T11:34:56.915787Z",
          "iopub.status.idle": "2024-11-25T11:34:56.921510Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.915762Z",
          "shell.execute_reply": "2024-11-25T11:34:56.920687Z"
        },
        "outputId": "400fc22d-c05f-45dd-8988-8ebb584a4f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.922392Z",
          "iopub.execute_input": "2024-11-25T11:34:56.922635Z",
          "iopub.status.idle": "2024-11-25T11:34:56.931426Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.922612Z",
          "shell.execute_reply": "2024-11-25T11:34:56.930546Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.932369Z",
          "iopub.execute_input": "2024-11-25T11:34:56.932586Z",
          "iopub.status.idle": "2024-11-25T11:34:56.942745Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.932564Z",
          "shell.execute_reply": "2024-11-25T11:34:56.942098Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.943785Z",
          "iopub.execute_input": "2024-11-25T11:34:56.944564Z",
          "iopub.status.idle": "2024-11-25T11:34:56.955751Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.944526Z",
          "shell.execute_reply": "2024-11-25T11:34:56.955025Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 32\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.956650Z",
          "iopub.execute_input": "2024-11-25T11:34:56.956925Z",
          "iopub.status.idle": "2024-11-25T11:34:56.967515Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.956883Z",
          "shell.execute_reply": "2024-11-25T11:34:56.966818Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:56.968349Z",
          "iopub.execute_input": "2024-11-25T11:34:56.968637Z",
          "iopub.status.idle": "2024-11-25T11:34:58.094506Z",
          "shell.execute_reply.started": "2024-11-25T11:34:56.968614Z",
          "shell.execute_reply": "2024-11-25T11:34:58.093588Z"
        },
        "outputId": "4a8d3d31-3eb0-4b79-9be4-05ecd6891eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 83,886,080 || all params: 8,114,147,328 || trainable%: 1.0338\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:58.095623Z",
          "iopub.execute_input": "2024-11-25T11:34:58.095940Z",
          "iopub.status.idle": "2024-11-25T11:34:58.114632Z",
          "shell.execute_reply.started": "2024-11-25T11:34:58.095909Z",
          "shell.execute_reply": "2024-11-25T11:34:58.113782Z"
        },
        "outputId": "5a539941-38b4-4401-a2c2-904eaffb1185"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:58.115785Z",
          "iopub.execute_input": "2024-11-25T11:34:58.116122Z",
          "iopub.status.idle": "2024-11-25T11:34:58.133035Z",
          "shell.execute_reply.started": "2024-11-25T11:34:58.116086Z",
          "shell.execute_reply": "2024-11-25T11:34:58.132248Z"
        },
        "outputId": "d3623f73-d42d-420c-b192-4e9df2207d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4624486400\nTrainable parameters : 83886080\nTrainable percentage: 1.81%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:58.134062Z",
          "iopub.execute_input": "2024-11-25T11:34:58.134354Z",
          "iopub.status.idle": "2024-11-25T11:34:58.146039Z",
          "shell.execute_reply.started": "2024-11-25T11:34:58.134326Z",
          "shell.execute_reply": "2024-11-25T11:34:58.145286Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 1\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 2,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 2,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:58.147128Z",
          "iopub.execute_input": "2024-11-25T11:34:58.147760Z",
          "iopub.status.idle": "2024-11-25T11:34:58.192386Z",
          "shell.execute_reply.started": "2024-11-25T11:34:58.147722Z",
          "shell.execute_reply": "2024-11-25T11:34:58.191559Z"
        },
        "outputId": "2e28521f-3aee-41f5-d99a-385767d1f766"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=2,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov25_11-34-58_1d63553094ae,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:34:58.193547Z",
          "iopub.execute_input": "2024-11-25T11:34:58.193909Z",
          "iopub.status.idle": "2024-11-25T11:35:00.027357Z",
          "shell.execute_reply.started": "2024-11-25T11:34:58.193871Z",
          "shell.execute_reply": "2024-11-25T11:35:00.026650Z"
        },
        "outputId": "4b68e07e-8c3f-44c3-ba16-630e22c5dee5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7f5b843d5c30>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T11:35:00.028543Z",
          "iopub.execute_input": "2024-11-25T11:35:00.028908Z",
          "iopub.status.idle": "2024-11-25T12:28:56.524165Z",
          "shell.execute_reply.started": "2024-11-25T11:35:00.028868Z",
          "shell.execute_reply": "2024-11-25T12:28:56.523311Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:28:56.525236Z",
          "iopub.execute_input": "2024-11-25T12:28:56.525520Z",
          "iopub.status.idle": "2024-11-25T12:32:37.496157Z",
          "shell.execute_reply.started": "2024-11-25T12:28:56.525493Z",
          "shell.execute_reply": "2024-11-25T12:32:37.495190Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:32:37.497428Z",
          "iopub.execute_input": "2024-11-25T12:32:37.498085Z",
          "iopub.status.idle": "2024-11-25T12:32:39.392983Z",
          "shell.execute_reply.started": "2024-11-25T12:32:37.498041Z",
          "shell.execute_reply": "2024-11-25T12:32:39.392315Z"
        },
        "outputId": "7f97eb37-4948-4fd1-af9e-f1d7ec6cef0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"akjindal53244/Llama-3.1-Storm-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"akjindal53244/Llama-3.1-Storm-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:32:39.393979Z",
          "iopub.execute_input": "2024-11-25T12:32:39.394237Z",
          "iopub.status.idle": "2024-11-25T12:32:39.545288Z",
          "shell.execute_reply.started": "2024-11-25T12:32:39.394211Z",
          "shell.execute_reply": "2024-11-25T12:32:39.544307Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:32:39.546424Z",
          "iopub.execute_input": "2024-11-25T12:32:39.546684Z",
          "iopub.status.idle": "2024-11-25T12:32:39.557996Z",
          "shell.execute_reply.started": "2024-11-25T12:32:39.546658Z",
          "shell.execute_reply": "2024-11-25T12:32:39.557149Z"
        },
        "id": "-LMTHSIPXN_Z",
        "outputId": "8be4e897-8aef-4ff1-a329-3d883bc2d978"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:32:39.558996Z",
          "iopub.execute_input": "2024-11-25T12:32:39.559268Z",
          "iopub.status.idle": "2024-11-25T12:32:40.901899Z",
          "shell.execute_reply.started": "2024-11-25T12:32:39.559244Z",
          "shell.execute_reply": "2024-11-25T12:32:40.901208Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "0GiCN4oxXN_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:32:40.902902Z",
          "iopub.execute_input": "2024-11-25T12:32:40.903158Z",
          "iopub.status.idle": "2024-11-25T12:34:08.700623Z",
          "shell.execute_reply.started": "2024-11-25T12:32:40.903133Z",
          "shell.execute_reply": "2024-11-25T12:34:08.699985Z"
        },
        "id": "Doi18PiCXN_Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.701682Z",
          "iopub.execute_input": "2024-11-25T12:34:08.701965Z",
          "iopub.status.idle": "2024-11-25T12:34:08.711426Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.701939Z",
          "shell.execute_reply": "2024-11-25T12:34:08.710653Z"
        },
        "id": "dkr8Sun-XN_Z",
        "outputId": "ebda0980-0b57-413a-ad94-67caa9ed1c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540600320\nTrainable parameters : 1050939392\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.712311Z",
          "iopub.execute_input": "2024-11-25T12:34:08.712564Z",
          "iopub.status.idle": "2024-11-25T12:34:08.742603Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.712539Z",
          "shell.execute_reply": "2024-11-25T12:34:08.741818Z"
        },
        "id": "7Csy-uBQXN_Z",
        "outputId": "70740ae1-ad1f-4362-9eb6-4512eafa4553"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.743698Z",
          "iopub.execute_input": "2024-11-25T12:34:08.743999Z",
          "iopub.status.idle": "2024-11-25T12:34:08.773324Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.743973Z",
          "shell.execute_reply": "2024-11-25T12:34:08.772597Z"
        },
        "id": "IZI5baZEXN_Z",
        "outputId": "f1056f60-f19a-4dfa-da23-6d739ec66496"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4708372480\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.774189Z",
          "iopub.execute_input": "2024-11-25T12:34:08.774428Z",
          "iopub.status.idle": "2024-11-25T12:34:08.782620Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.774405Z",
          "shell.execute_reply": "2024-11-25T12:34:08.781832Z"
        },
        "id": "yJAZUaTBXN_Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.783684Z",
          "iopub.execute_input": "2024-11-25T12:34:08.783990Z",
          "iopub.status.idle": "2024-11-25T12:34:08.793178Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.783964Z",
          "shell.execute_reply": "2024-11-25T12:34:08.792424Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:34:08.794110Z",
          "iopub.execute_input": "2024-11-25T12:34:08.794389Z",
          "iopub.status.idle": "2024-11-25T12:34:08.806374Z",
          "shell.execute_reply.started": "2024-11-25T12:34:08.794329Z",
          "shell.execute_reply": "2024-11-25T12:34:08.805690Z"
        },
        "id": "jzfIBMoNXN_Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:46:57.365141Z",
          "iopub.execute_input": "2024-11-25T12:46:57.365476Z",
          "iopub.status.idle": "2024-11-25T12:48:59.068845Z",
          "shell.execute_reply.started": "2024-11-25T12:46:57.365444Z",
          "shell.execute_reply": "2024-11-25T12:48:59.067847Z"
        },
        "outputId": "3ab2647d-e03e-40ed-c5ef-b090e2965056"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe implications of Artificial Intelligence  ###    |  the implications of Artificial Intelligence  ###  \nInput:   ### Response: Artificial Intelligence      |  Input:   ### Response: Artificial Intelligence    \n(AI) has far-reaching implications that affect      |  (AI) has far-reaching implications that affect    \nvarious aspects of our lives, from the way we work  |  various aspects of our lives, from the way we work\nand interact with each other to the way we          |  and interact with each other to the way we        \napproach complex problems and make decisions. Here  |  approach complex problems and make decisions. Here\nare some of the key implications of AI:  1. **Job   |  are some of the key implications of AI:  1. **Job \nMarket Disruption:** AI has the potential to        |  Market Disruption:** AI has the potential to      \nautomate many jobs, especially those that involve   |  automate many jobs, especially those that involve \nrepetitive tasks or can be easily codified. This    |  repetitive tasks or can be easily codified. This  \ncould lead to significant job displacement,         |  could lead to significant job displacement,       \nparticularly in sectors where AI can perform tasks  |  particularly in sectors where AI can perform tasks\nmore efficiently and accurately than humans. On     |  more efficiently and accurately than humans. On   \nthe other hand, AI could also create new job        |  the other hand, AI could also create new job      \nopportunities in fields related to AI development,  |  opportunities in fields related to AI development,\ndeployment, and maintenance.  2. **Enhanced         |  deployment, and maintenance.  2. **Enhanced       \nProductivity:** AI can significantly enhance        |  Productivity:** AI can significantly enhance      \nproductivity by automating routine tasks,           |  productivity by automating routine tasks,         \nimproving decision-making processes, and providing  |  improving decision-making processes, and providing\ninsights that humans might miss. This can lead to   |  insights that humans might miss. This can lead to \nincreased efficiency in various industries, from    |  increased efficiency in various industries, from  \nmanufacturing to healthcare, and can contribute to  |  manufacturing to healthcare, and can contribute to\neconomic growth.  3. **Personalization and          |  economic growth.  3. **Personalization and        \nCustomization:** AI can analyze vast amounts of     |  Customization:** AI can analyze vast amounts of   \ndata to provide personalized recommendations and    |  data to provide personalized recommendations and  \nexperiences. This is already seen in the            |  experiences. This is already seen in the          \nentertainment industry, where AI-driven algorithms  |  entertainment industry, where AI-driven algorithms\nsuggest movies and music based on user              |  suggest movies and music based on user            \npreferences. In education, AI can create            |  preferences. In education, AI can create          \ncustomized learning paths for students, enhancing   |  customized learning paths for students, enhancing \ntheir learning experience.  4. **Healthcare         |  their learning experience.  4. **Healthcare       \nAdvancements:** AI has the potential to             |  Advancements:** AI has the potential to           \nrevolutionize healthcare by improving diagnosis     |  revolutionize healthcare by improving diagnosis   \naccuracy, streamlining clinical workflows, and      |  accuracy, streamlining clinical workflows, and    \nenabling personalized medicine. AI-assisted         |  enabling personalized medicine. AI-assisted       \nsystems can analyze medical images, identify        |  systems can analyze medical images, identify      \npatterns, and predict patient outcomes, leading to  |  patterns, and predict patient outcomes, leading to\nbetter patient care.  5. **Cybersecurity            |  better patient care.  5. **Cybersecurity          \nChallenges:** As AI becomes more pervasive, it      |  Challenges:** As AI becomes more pervasive, it    \nalso introduces new cybersecurity risks. AI         |  also introduces new cybersecurity risks. AI       \nsystems can be vulnerable to attacks, and their     |  systems can be vulnerable to attacks, and their   \nability to learn and adapt can make them difficult  |  ability to learn and adapt can make them difficult\nto defend. Moreover, AI can also be used to launch  |  to defend. Moreover, AI can also be used to launch\nmore sophisticated cyberattacks, making             |  more sophisticated cyberattacks, making           \ncybersecurity a significant concern.  6. **Ethical  |  cybersecurity a significant concern.  6. **Ethical\nConsiderations:** AI raises ethical questions       |  Considerations:** AI raises ethical questions     \nabout privacy, bias, and accountability. AI         |  about privacy, bias, and accountability. AI       \nsystems can perpetuate biases present in the data   |  systems can perpetuate biases present in the data \nused to train them, leading to unfair outcomes.     |  used to train them, leading to unfair outcomes.   \nThere are also concerns about the use of AI in      |  There are also concerns about the use of AI in    \nsurveillance and the potential for AI to be used    |  surveillance and the potential for AI to be used  \nas a tool for social control.  7. **Social          |  as a tool for social control.  7. **Social        \nInteractions:** AI-powered chatbots and virtual     |  Interactions:** AI-powered chatbots and virtual   \nassistants are changing the way we interact with    |  assistants are changing the way we interact with  \ntechnology and each other. They can provide         |  technology and each other. They can provide       \nimmediate responses, reducing the need for human    |  immediate responses, reducing the need for human  \nintervention in many contexts. However, there are   |  intervention in many contexts. However, there are \nconcerns about the impact of AI on human            |  concerns about the impact of AI on human          \nrelationships and the potential for social          |  relationships and the potential for social        \nisolation.  8. **Environmental Impact:** The        |  isolation.  8. **Environmental Impact:** The      \ndevelopment and deployment of AI systems require    |  development and deployment of AI systems require  \nsignificant computational resources, which can      |  significant computational resources, which can    \ncontribute to environmental issues such as energy   |  contribute to energy consumption and e-waste.     \nconsumption and e-waste. There is a growing need    |  There is a growing need to develop more           \nto develop more sustainable AI practices.  9.       |  sustainable AI practices that minimize            \n**Education and Skills:** The increasing use of AI  |  environmental impact.  In conclusion, the         \nin various sectors means that there is a growing    |  implications of AI are multifaceted and far-      \nneed for education and training programs that       |  reaching, affecting various aspects of our lives. \nfocus on AI literacy and skills. This includes      |  While AI presents opportunities for growth,       \nunderstanding AI algorithms, data analysis, and     |  efficiency, and innovation, it also poses         \nthe ethical considerations involved in AI           |  challenges related to job displacement,           \ndevelopment.  10. **Regulatory Frameworks:** The    |  cybersecurity, ethics, and environmental          \nimplications of AI are so profound that there is a  |  sustainability. Addressing these implications     \nneed for regulatory frameworks that address the     |  requires a thoughtful and multidisciplinary       \nethical, legal, and social implications of AI.      |  approach to ensure that AI benefits society as a  \nThis includes ensuring that AI systems are          |  whole.                                            \ntransparent, accountable, and fair.  In             |                                                    \nconclusion, the implications of AI are              |                                                    \nmultifaceted and far-reaching, affecting various    |                                                    \naspects of our lives. While AI presents numerous    |                                                    \nopportunities for growth and improvement, it also   |                                                    \nposes significant challenges that need to be        |                                                    \naddressed through careful consideration and         |                                                    \nresponsible development. By understanding these     |                                                    \nimplications, we can work towards harnessing the    |                                                    \nbenefits of AI while mitigating its negative        |                                                    \neffects.                                            |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:53:40.829458Z",
          "iopub.execute_input": "2024-11-25T12:53:40.829806Z",
          "iopub.status.idle": "2024-11-25T12:56:53.248268Z",
          "shell.execute_reply.started": "2024-11-25T12:53:40.829761Z",
          "shell.execute_reply": "2024-11-25T12:56:53.247252Z"
        },
        "outputId": "a693a00d-6560-4e86-a635-a77637fee590"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: List two   |  completes the request.  ### Instruction: List two \nproblems caused by climate change  ### Input:       |  problems caused by climate change  ### Input:     \n### Response: Two problems caused by climate        |  ### Response: Two problems caused by climate      \nchange are:  1. Rising sea levels: As the Earth's   |  change are:  1. Rising sea levels: As the Earth's \ntemperature increases, polar ice caps and glaciers  |  temperature increases, polar ice caps and glaciers\nmelt, causing sea levels to rise. This can lead to  |  melt, causing sea levels to rise. This can lead to\ncoastal flooding, erosion, and saltwater intrusion  |  coastal flooding, erosion, and saltwater intrusion\ninto freshwater sources, affecting the livelihoods  |  into freshwater sources, affecting the livelihoods\nof people living in low-lying areas and islands.    |  of people living in low-lying areas and islands.  \n2. Extreme weather events: Climate change is        |  2. Extreme weather events: Climate change is      \nlinked to an increase in extreme weather events     |  linked to an increase in extreme weather events   \nsuch as heatwaves, droughts, and intense storms.    |  such as heatwaves, droughts, and intense storms.  \nThese events can have devastating impacts on        |  These events can have devastating impacts on      \ncommunities, causing loss of life, property         |  communities, causing loss of life, property       \ndamage, and displacement of people. For example,    |  damage, and displacement of people. For example,  \nheatwaves can lead to heat-related illnesses and    |  heatwaves can lead to heat-related illnesses and  \nmortality, while intense storms can destroy         |  mortality, while intense storms can destroy       \ninfrastructure and disrupt essential services.      |  infrastructure and disrupt essential services.    \nThe frequency and severity of these events are      |  The frequency and severity of these events are    \nexpected to worsen as the planet continues to       |  expected to worsen as the planet continues to     \nwarm.  This can have long-term consequences for     |  warm.  This can have long-term consequences for   \nthe environment, economy, and human health.  It is  |  the environment, economy, and human health.  It is\ncrucial to address climate change through           |  crucial to address climate change through         \nmitigation and adaptation strategies to minimize    |  mitigation and adaptation strategies to minimize  \nits impacts.  This can involve reducing greenhouse  |  its impacts.  This can involve reducing greenhouse\ngas emissions, transitioning to renewable energy    |  gas emissions, transitioning to renewable energy  \nsources, and implementing sustainable land use      |  sources, and implementing sustainable land use    \npractices.  Additionally, investing in climate-     |  practices.  Additionally, investing in climate-   \nresilient infrastructure, early warning systems,    |  resilient infrastructure, early warning systems,  \nand climate education can help communities prepare  |  and climate education can help communities prepare\nfor and respond to climate-related disasters.  By   |  for and respond to climate-related disasters.  By \ntaking proactive steps, we can reduce the risks     |  taking proactive steps, we can reduce the risks   \nassociated with climate change and create a more    |  associated with climate change and create a more  \nsustainable future for all.  This requires a        |  sustainable future for all.  This requires a      \ncollective effort from governments, businesses,     |  collective effort from governments, businesses,   \nand individuals to work together towards a common   |  and individuals to work together towards a common \ngoal.  We must prioritize climate action to         |  goal.  We must prioritize climate action to       \nprotect our planet and ensure a livable future for  |  protect our planet and ensure a livable future for\ngenerations to come.  This involves making          |  generations to come.  This involves making        \ninformed choices in our daily lives, such as        |  informed choices in our daily lives, such as      \nreducing energy consumption, using public           |  reducing energy consumption, using public         \ntransport, and supporting organizations that        |  transport, and supporting organizations that      \nprioritize sustainability.  By making these         |  promote sustainability.  Every small action       \nchoices, we can contribute to a cleaner,            |  counts, and together, we can make a significant   \nhealthier, and more resilient world.  It is         |  difference in addressing climate change.  By      \nessential to recognize the urgency of the climate   |  working together, we can create a better world for\ncrisis and take immediate action to address it.     |  ourselves and future generations.  This requires a\nWe must work together to mitigate the impacts of    |  commitment to sustainability, equity, and justice.\nclimate change and create a better future for       |  We must recognize the disproportionate impacts of \nourselves and future generations.  This requires a  |  climate change on vulnerable populations and      \ncommitment to sustainability, equity, and justice.  |  prioritize their needs in our climate policies.   \nWe must prioritize the needs of the most            |  This involves ensuring that climate action is     \nvulnerable populations and ensure that climate      |  inclusive, equitable, and just.  We must also     \naction is inclusive and equitable.  By doing so,    |  recognize the importance of preserving            \nwe can build a more just and sustainable world      |  biodiversity and ecosystem services.  Climate     \nwhere everyone has access to the resources they     |  change is closely linked to the loss of natural   \nneed to thrive.  This involves addressing the root  |  habitats and the decline of species.  Preserving  \ncauses of climate change, such as poverty,          |  biodiversity is crucial for maintaining ecosystem \ninequality, and unsustainable consumption           |  resilience and providing essential services such  \npatterns.  We must recognize the                    |  as pollination, pest control, and nutrient        \ninterconnectedness of our planet and the impact of  |  cycling.  This requires protecting and restoring  \nour actions on the environment and human            |  natural habitats, promoting sustainable           \nsocieties.  By taking a holistic approach to        |  agriculture practices, and reducing pollution.  By\nclimate action, we can create a more resilient and  |  taking these steps, we can mitigate the impacts of\nsustainable future for all.  This requires a long-  |  climate change and promote a healthy and thriving \nterm perspective and a willingness to make          |  planet.  This involves making conscious choices in\ndifficult choices.  We must prioritize the health   |  our daily lives, such as reducing meat            \nof our planet and the well-being of our             |  consumption, using eco-friendly products, and     \ncommunities over short-term gains and economic      |  supporting organizations that promote             \ninterests.  By doing so, we can create a more       |  conservation.  Every small action counts, and     \nequitable and sustainable world where everyone has  |  together, we can make a significant difference in \naccess to the resources they need to thrive.  This  |  preserving biodiversity and addressing climate    \ninvolves investing in climate-resilient             |  change.  By working together, we can create a     \ninfrastructure, renewable energy, and sustainable   |  better world for ourselves and future generations.\nland use practices.  We must also prioritize        |  This requires a commitment to sustainability,     \nclimate education and awareness-raising to empower  |  equity, and justice.  We must recognize the       \nindividuals and communities to take action.  By     |  disproportionate impacts of climate change on     \nworking together, we can create a better future     |  vulnerable populations and prioritize their needs \nfor ourselves and future generations.  This         |  in our climate policies.  This involves ensuring  \nrequires a commitment to sustainability, equity,    |  that climate action is inclusive, equitable, and  \nand justice.  We must prioritize the needs of the   |  just.  We must also recognize the importance of   \nmost vulnerable populations and ensure that         |  preserving biodiversity and ecosystem services.   \nclimate action is inclusive and equitable.  By      |  Climate change is closely linked to the loss of   \ndoing so, we can build a more just and sustainable  |  natural habitats and the decline of species.      \nworld where everyone has access to the resources    |  Preserving biodiversity is crucial for maintaining\nthey need to thrive.  This involves addressing the  |  ecosystem resilience and providing essential      \nroot causes of climate change, such as poverty,     |  services such as pollination, pest control, and   \ninequality, and unsustainable consumption           |  nutrient cycling.  This requires protecting and   \npatterns.  We must recognize the                    |  restoring natural habitats, promoting sustainable \ninterconnectedness of our planet and the impact of  |  agriculture practices, and reducing pollution.  By\nour actions on the environment and human            |  taking these steps, we can mitigate the impacts of\nsocieties.  By taking a holistic approach to        |  climate change and promote a healthy and thriving \nclimate action, we can create a more resilient and  |  planet.  This involves making conscious choices in\nsustainable future for all.  This requires a long-  |  our daily lives, such as reducing meat            \nterm perspective and a willingness to make          |  consumption, using eco-friendly products, and     \ndifficult choices.  We must prioritize the health   |  supporting organizations that promote             \nof our planet and the well-being of our             |  conservation.  Every small action counts, and     \ncommunities over short-term gains and economic      |  together, we can make a significant difference in \ninterests.  By doing so, we can create a more       |  preserving biodiversity and addressing climate    \nequitable and sustainable world where everyone has  |  change.  By working together, we can create a     \naccess to the resources they need to thrive.  This  |  better world for ourselves and future generations.\ninvolves investing in climate-resilient             |  This requires a commitment to sustainability,     \ninfrastructure, renewable energy, and sustainable   |  equity, and justice.  We must recognize the       \nland use practices.  We must also prioritize        |  disproportionate impacts of climate change on     \nclimate education and awareness-raising to empower  |  vulnerable populations and prioritize their needs \nindividuals and communities to take action.  By     |  in our climate policies.  This involves ensuring  \nworking together, we can create a better future     |  that climate action is inclusive, equitable, and  \nfor ourselves and future generations.  This         |  just.  We must also recognize the importance of   \nrequires a commitment to sustainability, equity,    |  preserving biodiversity and ecosystem services.   \nand justice.  We must prioritize the needs of the   |  Climate change is closely linked to the loss of   \nmost vulnerable populations and ensure that         |  natural habitats and the decline of species.      \nclimate action is inclusive and equitable.  By      |  Preserving biodiversity is crucial for maintaining\ndoing so, we can build a more just and sustainable  |  ecosystem resilience and providing essential      \nworld where everyone has access to the resources    |  services such as pollination, pest control, and   \nthey need to thrive.  This involves addressing the  |  nutrient cycling.  This requires protecting and   \nroot causes of climate change, such as poverty,     |  restoring natural habitats, promoting sustainable \ninequality, and unsustainable consumption           |  agriculture practices, and reducing pollution.  By\npatterns.  We must recognize the                    |  taking these steps, we can mitigate the impacts of\ninterconnectedness of our planet and the impact of  |  climate change and promote a healthy and thriving \nour actions on the environment and human            |  planet.  This involves making conscious choices in\nsocieties.  By taking a holistic approach to        |  our daily lives, such as reducing meat            \nclimate action, we can create a more                |  consumption, using eco-friendly products, and     \n                                                    |  supporting organizations that promote             \n                                                    |  conservation.  Every small action counts, and     \n                                                    |  together, we can make a significant difference in \n                                                    |  preserving biodiversity and addressing climate    \n                                                    |  change.  By working together, we can create a     \n                                                    |  better                                            \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T12:37:31.347630Z",
          "iopub.execute_input": "2024-11-25T12:37:31.348279Z",
          "iopub.status.idle": "2024-11-25T12:40:14.589181Z",
          "shell.execute_reply.started": "2024-11-25T12:37:31.348249Z",
          "shell.execute_reply": "2024-11-25T12:40:14.588365Z"
        },
        "outputId": "e59b70ac-3cda-4fa5-8064-a33c5722aeea"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse: Once upon a time, in a quaint little      |  Response: Once upon a time, in a quaint little    \nvillage nestled between rolling hills and dense     |  village nestled between rolling hills and dense   \nforests, there lived a young couple named Sophia    |  forests, there lived a young couple named Sophia  \nand Alexander. Their love story was one for the     |  and Alexander. Their love story was one for the   \nages, filled with laughter, adventure, and a deep,  |  ages, filled with laughter, adventure, and a deep,\nunbreakable bond.  Sophia, with her fiery spirit    |  unbreakable bond.  Sophia, with her fiery spirit  \nand bright smile, was a painter, capturing the      |  and bright smile, was a painter, capturing the    \nbeauty of the world around her on canvas.           |  beauty of the world around her on canvas.         \nAlexander, a poet, was her muse, his words weaving  |  Alexander, a poet, was her muse, his words weaving\na tapestry of emotions that resonated deeply with   |  a tapestry of emotions that resonated deeply with \nSophia's art.  Their love blossomed under the warm  |  Sophia's art.  Their love blossomed under the warm\nsun of summer, with long walks through the fields,  |  sun of summer, with long walks through the fields,\npicnics by the river, and cozy nights spent         |  picnics by the river, and cozy nights spent       \nreading each other's work. It was as if their       |  reading each other's work. It was as if their     \nsouls were meant to be together, their love a       |  souls were meant to be together, their love a     \nsymphony that harmonized the discordant notes of    |  symphony that harmonized the discordant notes of  \nlife.  But fate, it seemed, had other plans.        |  life.  But fate, it seemed, had other plans.      \nAlexander, the free spirit that he was, decided to  |  Alexander, the free spirit that he was, decided to\nembark on a journey to explore the world, to find   |  embark on a journey to explore the world, to find \ninspiration in the farthest corners of the globe.   |  inspiration in the farthest corners of the globe. \nSophia, though heartbroken, understood his need     |  Sophia, though heartbroken, understood his need   \nfor adventure and promised to wait for him, their   |  for adventure and promised to wait for him, their \nlove strong enough to weather any storm.  Years     |  love strong enough to withstand the distance.     \npassed, and Sophia's art flourished, her paintings  |  Years passed, and Sophia's paintings became       \na testament to the love they shared. She would      |  renowned, her art a reflection of the love she    \noften look at the stars, hoping Alexander's         |  held in her heart. She would often look up at the \njourney was taking him closer to her, to the home   |  sky, hoping to catch a glimpse of Alexander's     \nthey had built together.  Then, one fateful day, a  |  star, a celestial guide that would lead him back  \nletter arrived, its arrival like a thunderclap on   |  to her.  Meanwhile, Alexander traveled the world, \na clear day. Alexander had fallen ill, his body     |  meeting people, experiencing cultures, and writing\nweakened by the harsh conditions of his travels.    |  about the beauty he encountered. His words, though\nSophia, her heart heavy with sorrow, set out to     |  filled with the wonder of the world, were always  \njoin him, to be by his side in his final days.  As  |  tinged with a longing for Sophia, the love that   \nshe reached his bedside, Alexander's eyes, once     |  had set his soul ablaze.  One day, Alexander      \nbright with love and laughter, now dimmed with the  |  received news that Sophia's health was failing. He\nweight of his mortality. He held her hand, his      |  dropped everything, sold his belongings, and set  \nvoice barely above a whisper, and spoke the words   |  sail across the seas to return to her. The journey\nthat would haunt Sophia for the rest of her days:   |  was long and arduous, but his heart, filled with  \n\"My love, I'm sorry. I never got to see the world,  |  love and determination, propelled him forward.    \nto paint it with the colors of our love. But I      |  When Alexander finally arrived at Sophia's        \nknow that you will, that you will bring our story   |  doorstep, he was met with a frail but radiant     \nto life, and that our love will live on through     |  woman, her eyes still shining with the love they  \nyour art.\"  And with those words, Alexander passed  |  had shared. They spent their days reminiscing     \naway, leaving Sophia alone, her heart shattered     |  about their past, their nights filled with the    \ninto a million pieces. Yet, even in her grief, she  |  soft glow of candles, and the gentle hum of       \nfound solace in her art, in the memories they had   |  Alexander's poetry.  As the days turned into      \ncreated together. She painted the world, not as it  |  weeks, Sophia's health began to decline further.  \nwas, but as it could have been, with Alexander by   |  Alexander held her hand, his words pouring out in \nher side, their love a beacon that illuminated the  |  a desperate attempt to keep her with him. He wrote\ndarkness.  Years later, Sophia's art had become     |  of their love, of the beauty they had shared, and \nlegendary, her paintings a testament to the         |  of the promise they had made to each other.  In   \nenduring power of love. And though she never        |  the end, it was not the distance that had tested  \nforgot Alexander, she learned to live with her      |  their love, but the cruel hand of fate. Sophia    \nloss, her heart still heavy, but her spirit         |  passed away, surrounded by Alexander's words, her \nunbroken. For in the end, it was not the length of  |  heart filled with the love they had shared.       \ntheir time together that mattered, but the depth    |  Alexander, though shattered by grief, found solace\nof their love, a love that had transcended time     |  in the memories they had created, the love they   \nand space, a love that would forever be etched in   |  had known, and the promise they had made to each  \nthe canvas of her soul.                             |  other.  Years later, Alexander returned to the    \n                                                    |  village, his heart heavy with the weight of his   \n                                                    |  loss. He walked to the spot where they had first  \n                                                    |  shared their love, and there, he planted a tree, a\n                                                    |  symbol of their enduring love. The villagers, who \n                                                    |  had known the couple, would often visit the tree, \n                                                    |  their hearts filled with the story of Sophia and  \n                                                    |  Alexander, a tale of love and loss that would be  \n                                                    |  remembered for generations to come.  And so, the  \n                                                    |  tree grew, its branches reaching towards the sky, \n                                                    |  a testament to the love that had once flourished  \n                                                    |  beneath its shade. It stood as a reminder that    \n                                                    |  even in the darkest of times, love can be a beacon\n                                                    |  of hope, a guiding light that leads us through the\n                                                    |  shadows, and a promise that our hearts will always\n                                                    |  remember the love we have shared. The story of    \n                                                    |  Sophia and Alexander became a legend, a tale of   \n                                                    |  two souls who had found each other in a world full\n                                                    |  of beauty and wonder, and who had loved each other\n                                                    |  until the very end. Their love, though tested by  \n                                                    |  loss, remained a powerful force, a reminder to all\n                                                    |  who knew them that true love can conquer even     \n                                                    |  death itself. The tree, a living monument to their\n                                                    |  love, stood as a testament to the enduring power  \n                                                    |  of the human heart, a symbol of the love that     \n                                                    |  would forever be etched in the hearts of those who\n                                                    |  knew Sophia and Alexander. And so, their story    \n                                                    |  lives on, a reminder to cherish every moment, to  \n                                                    |  hold dear the love we share, and to never let go  \n                                                    |  of the promise we make to each other. The tree, a \n                                                    |  living embodiment of their love, continues to     \n                                                    |  grow, its branches reaching towards the sky, a    \n                                                    |  symbol of the love that will forever be remembered\n                                                    |  as a beacon of hope, a guiding light that leads us\n                                                    |  through the shadows, and a promise that our hearts\n                                                    |  will always remember the love we have shared. The \n                                                    |  story of Sophia and Alexander became a legend, a  \n                                                    |  tale of two souls who had found each other in a   \n                                                    |  world full of beauty and wonder, and who had loved\n                                                    |  each other until the very end. Their love, though \n                                                    |  tested by loss, remained a powerful force, a      \n                                                    |  reminder to all who knew them that                \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T13:00:34.483829Z",
          "iopub.execute_input": "2024-11-25T13:00:34.484490Z",
          "iopub.status.idle": "2024-11-25T13:03:48.502020Z",
          "shell.execute_reply.started": "2024-11-25T13:00:34.484459Z",
          "shell.execute_reply": "2024-11-25T13:03:48.501155Z"
        },
        "outputId": "ff8f1899-2b13-46ee-be84-b749e7c58f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Rewrite    |  completes the request.  ### Instruction: Rewrite  \nthese sentences using different words  ### Input:   |  these sentences using different words  ### Input: \nThis tech device will make your life more           |  This tech device will make your life more         \nefficient and enjoyable.  ### Response: This        |  efficient and enjoyable.  ### Response: This      \ncutting-edge gadget will significantly enhance      |  cutting-edge gadget will significantly enhance    \nyour quality of life and make it more productive    |  your quality of life and make it more productive  \nand fulfilling.   ### Explanation: The task         |  and fulfilling.   ### Explanation: The task       \nrequires us to rewrite the given sentence using     |  requires us to rewrite the given sentence using   \ndifferent words while maintaining its original      |  different words while maintaining its original    \nmeaning. The original sentence uses the words       |  meaning. The original sentence uses the words     \n\"tech device,\" \"efficient,\" and \"enjoyable.\" In     |  \"tech device,\" \"efficient,\" and \"enjoyable.\" In   \nthe rewritten sentence, we use the words \"cutting-  |  the rewritten sentence, we use the words \"cutting-\nedge gadget,\" \"significantly enhance,\" \"quality of  |  edge gadget,\" \"significantly enhance,\" \"quality of\nlife,\" \"productive,\" and \"fulfilling.\" These words  |  life,\" \"productive,\" and \"fulfilling.\" These words\nconvey the same meaning as the original sentence    |  convey the same meaning as the original sentence  \nbut with a different tone and style. The use of     |  but with a different tone and style. The use of   \nsynonyms like \"cutting-edge\" instead of \"tech\" and  |  synonyms like \"cutting-edge\" instead of \"tech\" and\n\"gadget\" instead of \"device\" adds variety to the    |  \"gadget\" instead of \"device\" adds variety to the  \nsentence. Similarly, \"significantly enhance\"        |  sentence. Similarly, \"significantly enhance\"      \nreplaces \"make,\" and \"quality of life\" replaces     |  replaces \"make,\" and \"quality of life\" replaces   \n\"life.\" The words \"productive\" and \"fulfilling\"     |  \"life.\" The words \"productive\" and \"fulfilling\"   \nreplace \"efficient\" and \"enjoyable,\" respectively,  |  replace \"efficient\" and \"enjoyable,\" respectively,\nto maintain the original meaning. This approach     |  to maintain the original meaning. This approach   \nensures that the rewritten sentence conveys the     |  ensures that the rewritten sentence conveys the   \nsame message as the original but with a fresh       |  same message as the original but with a fresh     \nperspective.   ### Example Use Case: Rewrite the    |  perspective.   ### Example Use Case: Rewrite the  \nfollowing sentence using different words: \"The new  |  following sentence using different words: \"The new\npolicy will have a positive impact on the           |  policy will have a positive impact on the         \ncommunity.\"  Rewritten sentence: \"The recently      |  community.\"  Rewritten sentence: \"The recently    \nintroduced initiative will undoubtedly bring about  |  introduced initiative will undoubtedly bring about\na beneficial effect on the local population.\"   In  |  a beneficial effect on the local population.\"   In\nthis example, the original sentence uses the words  |  this example, the original sentence uses the words\n\"new policy,\" \"positive impact,\" and \"community.\"   |  \"new policy,\" \"positive impact,\" and \"community.\" \nThe rewritten sentence uses the words \"recently     |  The rewritten sentence uses the words \"recently   \nintroduced initiative,\" \"undoubtedly bring about,\"  |  introduced initiative,\" \"undoubtedly bring about,\"\n\"beneficial effect,\" and \"local population.\" These  |  \"beneficial effect,\" and \"local population.\" These\nwords convey the same meaning as the original       |  words convey the same meaning as the original     \nsentence but with a different tone and style. The   |  sentence but with a different tone and style. The \nuse of synonyms like \"recently introduced\" instead  |  use of synonyms like \"recently introduced\" instead\nof \"new\" and \"initiative\" instead of \"policy\" adds  |  of \"new\" and \"initiative\" instead of \"policy\" adds\nvariety to the sentence. Similarly, \"undoubtedly    |  variety to the sentence. Similarly, \"undoubtedly  \nbring about\" replaces \"will have,\" and \"beneficial  |  bring about\" replaces \"will have,\" and \"beneficial\neffect\" replaces \"positive impact.\" The words       |  effect\" replaces \"positive impact.\" The words     \n\"local population\" replace \"community\" to maintain  |  \"local population\" replace \"community\" to maintain\nthe original meaning. This approach ensures that    |  the original meaning. This approach ensures that  \nthe rewritten sentence conveys the same message as  |  the rewritten sentence conveys the same message as\nthe original but with a fresh perspective.   ###    |  the original but with a fresh perspective.   ###  \nCode Explanation: No code is required for this      |  Code Explanation: No code is required for this    \ntask as it involves rewriting sentences using       |  task as it involves rewriting sentences using     \ndifferent words. The provided response              |  different words. The provided response            \ndemonstrates how to rewrite sentences while         |  demonstrates how to rewrite a sentence while      \nmaintaining their original meaning but with a       |  maintaining its original meaning. The explanation \ndifferent tone and style. The explanation and       |  and example use case further illustrate the       \nexample use case illustrate the process of using    |  process of rewriting sentences using synonyms and \nsynonyms and rephrasing sentences to convey the     |  different word choices.   ### Advice: When        \nsame message in a fresh way.   ### Advice: When     |  rewriting sentences, consider the context and the \nrewriting sentences using different words,          |  intended meaning. Choose synonyms that accurately \nconsider the context and the intended audience.     |  convey the original message while adding variety  \nChoose synonyms that accurately convey the          |  to the sentence. This approach can help improve   \noriginal meaning and maintain the tone and style    |  writing style and make the content more engaging  \nof the sentence. Rephrasing sentences can help to   |  for readers.   ### Additional Information:        \navoid repetition, add variety, and make the text    |  Rewriting sentences using different words can be a\nmore engaging for the reader.   ### Step-by-Step    |  useful technique in various writing contexts, such\nSolution: 1. Identify the key words and phrases in  |  as academic writing, creative writing, and        \nthe original sentence that need to be replaced. 2.  |  professional communication. It can help authors   \nChoose synonyms that accurately convey the          |  express their ideas more effectively and make     \noriginal meaning and maintain the tone and style    |  their writing more engaging and diverse. By using \nof the sentence. 3. Rephrase the sentence using     |  synonyms and different word choices, writers can  \nthe chosen synonyms and maintain the original       |  convey the same meaning while adding variety to   \nmeaning. 4. Review the rewritten sentence to        |  their sentences, making their writing more        \nensure it conveys the same message as the original  |  enjoyable to read.   ### Step-by-Step Solution: 1.\nbut with a fresh perspective.   ### Step-by-Step    |  Identify the original sentence and its meaning. 2.\nSolution Explanation: The step-by-step solution     |  Choose synonyms for the key words in the original \nprovides a clear guide on how to rewrite sentences  |  sentence. 3. Rewrite the sentence using the chosen\nusing different words. It emphasizes the            |  synonyms while maintaining its original meaning.  \nimportance of identifying key words and phrases,    |  4. Review the rewritten sentence to ensure it     \nchoosing synonyms, rephrasing the sentence, and     |  conveys the same message as the original sentence \nreviewing the rewritten sentence to ensure it       |  but with a fresh perspective.  ### Step-by-Step   \nconveys the same message as the original. This      |  Solution Explanation: The step-by-step solution   \napproach ensures that the rewritten sentence        |  involves identifying the original sentence,       \nmaintains its original meaning but with a fresh     |  choosing synonyms for its key words, rewriting the\nperspective.   ### Step-by-Step Solution Code: No   |  sentence using the chosen synonyms, and reviewing \ncode is required for this task as it involves       |  the rewritten sentence. This process ensures that \nrewriting sentences using different words. The      |  the rewritten sentence conveys the same meaning as\nprovided step-by-step solution demonstrates the     |  the original sentence but with a different tone   \nprocess of rewriting sentences while maintaining    |  and style. By following these steps, writers can  \ntheir original meaning but with a different tone    |  effectively rewrite sentences using different     \nand style.   ### Step-by-Step Solution Advice:      |  words while maintaining their original meaning.   \nWhen rewriting sentences using different words,     |  ### Step-by-Step Solution Code: No code is        \nconsider the context and the intended audience.     |  required for this task as it involves rewriting   \nChoose synonyms that accurately convey the          |  sentences using different words. The provided     \noriginal meaning and maintain the tone and style    |  step-by-step solution demonstrates the process of \nof the sentence. Rephrasing sentences can help to   |  rewriting sentences while maintaining their       \navoid repetition, add variety, and make the text    |  original meaning.   ### Step-by-Step Solution     \nmore engaging for the reader.   ### Step-by-Step    |  Advice: When rewriting sentences, consider the    \nSolution Example Use Case: Rewrite the following    |  context and the intended meaning. Choose synonyms \nsentence using different words: \"The new policy     |  that accurately convey the original message while \nwill have a positive impact on the community.\"      |  adding variety to the sentence. This approach can \nRewritten sentence: \"The recently introduced        |  help improve writing style and make the content   \ninitiative will undoubtedly bring about a           |  more engaging for readers.   ### Step-by-Step     \nbeneficial effect on the local population.\"   In    |  Solution Additional Information: Rewriting        \nthis example, the original sentence uses the words  |  sentences using different words can be a useful   \n\"new policy,\" \"positive impact,\" and \"community.\"   |  technique in various writing contexts, such as    \nThe rewritten sentence uses the words \"recently     |  academic writing, creative writing, and           \nintroduced initiative,\" \"undoubtedly bring about,\"  |  professional communication. It can help authors   \n\"beneficial effect,\" and \"local population.\" These  |  express their ideas more effectively and make     \nwords convey the same meaning as the original       |  their writing more engaging and diverse. By using \nsentence but with a different tone and style. The   |  synonyms and different word choices, writers can  \nuse of synonyms like \"recently introduced\" instead  |  convey the same meaning while adding variety to   \nof \"new\" and \"initiative\" instead of \"policy\" adds  |  their sentences, making their writing more        \nvariety to the sentence. Similarly, \"undoubtedly    |  enjoyable to read.   ### Step-by-Step Solution    \nbring about\" replaces \"will have,\" and \"beneficial  |  Step-by-Step Solution: 1. Identify the original   \neffect\" replaces \"positive impact.\" The words       |  sentence and its meaning. 2. Choose synonyms for  \n\"local population\" replace \"community\" to           |  the key words in the original sentence. 3. Rewrite\n                                                    |  the sentence using the chosen synonyms while      \n                                                    |  maintaining its original meaning. 4. Review the   \n                                                    |  rewritten sentence to ensure it conveys the same  \n                                                    |  message as the original sentence but with a fresh \n                                                    |  perspective.  ### Step-by-Step Solution Step-by-  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T13:21:47.010133Z",
          "iopub.execute_input": "2024-11-25T13:21:47.010468Z",
          "iopub.status.idle": "2024-11-25T13:22:51.828498Z",
          "shell.execute_reply.started": "2024-11-25T13:21:47.010438Z",
          "shell.execute_reply": "2024-11-25T13:22:51.827622Z"
        },
        "outputId": "d9f8a633-c018-4367-8766-f607b836f18d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Write a    |  completes the request.  ### Instruction: Write a  \nreview of the restaurant.  ### Input: The           |  review of the restaurant.  ### Input: The         \nrestaurant is called La Taqueria.  ### Response:    |  restaurant is called La Taqueria.  ### Response:  \nLa Taqueria is a vibrant and bustling eatery that   |  La Taqueria is a vibrant and bustling eatery that \nserves authentic Mexican cuisine. Upon entering,    |  serves authentic Mexican cuisine. Upon entering,  \ncustomers are immediately immersed in a lively      |  customers are immediately immersed in a lively    \natmosphere, complete with colorful decorations and  |  atmosphere, complete with colorful decorations and\nthe enticing aroma of freshly prepared dishes. The  |  the enticing aroma of freshly prepared dishes. The\nstaff is friendly and attentive, ensuring that      |  staff is friendly and attentive, ensuring that    \nevery guest feels welcome and well cared for.  The  |  every guest feels welcome and well cared for.  The\nmenu at La Taqueria is extensive, offering a wide   |  menu at La Taqueria is extensive, offering a wide \nvariety of traditional Mexican favorites. From      |  variety of traditional Mexican favorites. From    \nclassic tacos and burritos to more adventurous      |  classic tacos and burritos to more adventurous    \noptions like chiles rellenos and carne asada,       |  options like chiles rellenos and carne asada,     \nthere's something for every palate. The dishes are  |  there's something for every palate. The dishes are\nmade with fresh, high-quality ingredients, and the  |  made with fresh, high-quality ingredients, and the\nflavors are bold and authentic.  One of the         |  flavors are bold and authentic.  One of the       \nstandout features of La Taqueria is its commitment  |  standout features of La Taqueria is its commitment\nto using locally sourced ingredients whenever       |  to using locally sourced ingredients whenever     \npossible. This not only supports the local          |  possible. This not only supports the local        \ncommunity but also ensures that the food is as      |  community but also ensures that the food is as    \nfresh and flavorful as possible. The restaurant     |  fresh and flavorful as possible. The restaurant   \nalso offers a variety of vegetarian and vegan       |  also offers a variety of vegetarian and vegan     \noptions, making it a great choice for diners with   |  options, making it a great choice for diners with \ndietary restrictions.  In addition to its           |  dietary restrictions.  In addition to its         \nexcellent food and welcoming atmosphere, La         |  excellent food, La Taqueria also offers a full bar\nTaqueria also offers a full bar with a wide         |  with a wide selection of cocktails, beers, and    \nselection of cocktails, beers, and wines. The       |  wines. The margaritas are particularly noteworthy,\nmargaritas are particularly noteworthy, made with   |  made with fresh lime juice and a touch of         \nfresh lime juice and a touch of sweetness.          |  sweetness.  Overall, La Taqueria is a fantastic   \nOverall, La Taqueria is a fantastic choice for      |  choice for anyone looking for a delicious and     \nanyone looking for a delicious and authentic        |  authentic Mexican dining experience. With its     \nMexican dining experience. Whether you're in the    |  lively atmosphere, extensive menu, and commitment \nmood for a casual meal with friends or a special    |  to using locally sourced ingredients, it's a      \noccasion celebration, this restaurant is sure to    |  restaurant that is sure to please even the most   \nimpress. With its vibrant atmosphere, extensive     |  discerning diners. Whether you're in the mood for \nmenu, and commitment to quality, La Taqueria is a   |  a casual meal with friends or a special occasion  \nmust-visit destination for food lovers of all       |  celebration, La Taqueria is a great choice. Don't \nages. Rating: 5/5 stars.                            |  miss out on the opportunity to experience this    \n                                                    |  fantastic eatery for yourself! Rating: 5/5 stars. \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}