{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-01T05:28:37.951601Z","iopub.execute_input":"2024-12-01T05:28:37.952280Z","iopub.status.idle":"2024-12-01T05:29:29.149116Z","shell.execute_reply.started":"2024-12-01T05:28:37.952247Z","shell.execute_reply":"2024-12-01T05:29:29.147862Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-12-01T05:29:29.151556Z","iopub.execute_input":"2024-12-01T05:29:29.152295Z","iopub.status.idle":"2024-12-01T05:29:48.573194Z","shell.execute_reply.started":"2024-12-01T05:29:29.152249Z","shell.execute_reply":"2024-12-01T05:29:48.572199Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-12-01T05:29:48.575680Z","iopub.execute_input":"2024-12-01T05:29:48.576034Z","iopub.status.idle":"2024-12-01T05:29:48.588504Z","shell.execute_reply.started":"2024-12-01T05:29:48.575994Z","shell.execute_reply":"2024-12-01T05:29:48.586109Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'unsloth/Hermes-2-Pro-Mistral-7B'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-01T05:29:48.591937Z","iopub.execute_input":"2024-12-01T05:29:48.592324Z","iopub.status.idle":"2024-12-01T05:29:48.619397Z","shell.execute_reply.started":"2024-12-01T05:29:48.592287Z","shell.execute_reply":"2024-12-01T05:29:48.618253Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-12-01T05:29:48.620479Z","iopub.execute_input":"2024-12-01T05:29:48.620845Z","iopub.status.idle":"2024-12-01T05:29:48.635926Z","shell.execute_reply.started":"2024-12-01T05:29:48.620792Z","shell.execute_reply":"2024-12-01T05:29:48.635108Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:29:48.636963Z","iopub.execute_input":"2024-12-01T05:29:48.637212Z","iopub.status.idle":"2024-12-01T05:36:20.033634Z","shell.execute_reply.started":"2024-12-01T05:29:48.637189Z","shell.execute_reply":"2024-12-01T05:36:20.032851Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f38d96ce6bd4319b5443b2a5d7e2745"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972f0513860e4c48aa542fd2a1827503"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9c03c5c102420aaa2edbe252eae212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec37bd9496604c47b57b42db9a8d9c50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bac24d40f2e4c89872e014babf80a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43d7491dfcbb4684921076cb820f1f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30cd127d70064a57ba1d08299565060d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abab2740fe6044879d28786a1044a392"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32032, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n  )\n  (lm_head): Linear(in_features=4096, out_features=32032, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:20.034923Z","iopub.execute_input":"2024-12-01T05:36:20.035224Z","iopub.status.idle":"2024-12-01T05:36:20.042702Z","shell.execute_reply.started":"2024-12-01T05:36:20.035197Z","shell.execute_reply":"2024-12-01T05:36:20.041875Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 3752333312\nTrainable parameters : 262672384\nTrainable percentage: 7.00%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:20.043663Z","iopub.execute_input":"2024-12-01T05:36:20.043929Z","iopub.status.idle":"2024-12-01T05:36:21.993186Z","shell.execute_reply.started":"2024-12-01T05:36:20.043904Z","shell.execute_reply":"2024-12-01T05:36:21.992180Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/6.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d154bac534a4c348fce71a4fae5e899"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2fe39e3dd41415ba39bd8b2bf680d1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a3bd90d17bf43229457834fb9b021a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/643 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df81d71af8fb48c29daa677895cdd535"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b09339510a244e29823e4f856b48aa3"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:21.994497Z","iopub.execute_input":"2024-12-01T05:36:21.994825Z","iopub.status.idle":"2024-12-01T05:36:21.998903Z","shell.execute_reply.started":"2024-12-01T05:36:21.994782Z","shell.execute_reply":"2024-12-01T05:36:21.998042Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 384","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:22.001414Z","iopub.execute_input":"2024-12-01T05:36:22.001677Z","iopub.status.idle":"2024-12-01T05:36:22.013449Z","shell.execute_reply.started":"2024-12-01T05:36:22.001650Z","shell.execute_reply":"2024-12-01T05:36:22.012667Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:22.014598Z","iopub.execute_input":"2024-12-01T05:36:22.014948Z","iopub.status.idle":"2024-12-01T05:36:24.760743Z","shell.execute_reply.started":"2024-12-01T05:36:22.014912Z","shell.execute_reply":"2024-12-01T05:36:24.760028Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7827d0225745839f6a4ab6157aa3f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"alpaca_data_cleaned.json:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230126027aec498cbcfb76052be73287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc641eaf8fc0418d9f4ac2c52c5fba97"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.761753Z","iopub.execute_input":"2024-12-01T05:36:24.762096Z","iopub.status.idle":"2024-12-01T05:36:24.768768Z","shell.execute_reply.started":"2024-12-01T05:36:24.762069Z","shell.execute_reply":"2024-12-01T05:36:24.767959Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.769846Z","iopub.execute_input":"2024-12-01T05:36:24.770173Z","iopub.status.idle":"2024-12-01T05:36:24.790114Z","shell.execute_reply.started":"2024-12-01T05:36:24.770136Z","shell.execute_reply":"2024-12-01T05:36:24.789394Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.791023Z","iopub.execute_input":"2024-12-01T05:36:24.791250Z","iopub.status.idle":"2024-12-01T05:36:24.798760Z","shell.execute_reply.started":"2024-12-01T05:36:24.791226Z","shell.execute_reply":"2024-12-01T05:36:24.797886Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.799905Z","iopub.execute_input":"2024-12-01T05:36:24.800300Z","iopub.status.idle":"2024-12-01T05:36:24.810120Z","shell.execute_reply.started":"2024-12-01T05:36:24.800263Z","shell.execute_reply":"2024-12-01T05:36:24.809123Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.811218Z","iopub.execute_input":"2024-12-01T05:36:24.811882Z","iopub.status.idle":"2024-12-01T05:36:24.821491Z","shell.execute_reply.started":"2024-12-01T05:36:24.811788Z","shell.execute_reply":"2024-12-01T05:36:24.820638Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.822555Z","iopub.execute_input":"2024-12-01T05:36:24.822839Z","iopub.status.idle":"2024-12-01T05:36:24.831608Z","shell.execute_reply.started":"2024-12-01T05:36:24.822783Z","shell.execute_reply":"2024-12-01T05:36:24.830861Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:24.832442Z","iopub.execute_input":"2024-12-01T05:36:24.832643Z","iopub.status.idle":"2024-12-01T05:36:25.378476Z","shell.execute_reply.started":"2024-12-01T05:36:24.832622Z","shell.execute_reply":"2024-12-01T05:36:25.377614Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1d45e130c6400283d111f1f5091e4c"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:25.379477Z","iopub.execute_input":"2024-12-01T05:36:25.379846Z","iopub.status.idle":"2024-12-01T05:36:25.384692Z","shell.execute_reply.started":"2024-12-01T05:36:25.379786Z","shell.execute_reply":"2024-12-01T05:36:25.383829Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:25.385609Z","iopub.execute_input":"2024-12-01T05:36:25.385891Z","iopub.status.idle":"2024-12-01T05:36:25.407468Z","shell.execute_reply.started":"2024-12-01T05:36:25.385865Z","shell.execute_reply":"2024-12-01T05:36:25.406707Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:25.408542Z","iopub.execute_input":"2024-12-01T05:36:25.408907Z","iopub.status.idle":"2024-12-01T05:36:33.850153Z","shell.execute_reply.started":"2024-12-01T05:36:25.408869Z","shell.execute_reply":"2024-12-01T05:36:33.849254Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49558fa22d7401c8f56209c2a15345b"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.851437Z","iopub.execute_input":"2024-12-01T05:36:33.852225Z","iopub.status.idle":"2024-12-01T05:36:33.859325Z","shell.execute_reply.started":"2024-12-01T05:36:33.852183Z","shell.execute_reply":"2024-12-01T05:36:33.858288Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.860363Z","iopub.execute_input":"2024-12-01T05:36:33.860609Z","iopub.status.idle":"2024-12-01T05:36:33.923185Z","shell.execute_reply.started":"2024-12-01T05:36:33.860578Z","shell.execute_reply":"2024-12-01T05:36:33.922239Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.924277Z","iopub.execute_input":"2024-12-01T05:36:33.924617Z","iopub.status.idle":"2024-12-01T05:36:33.930373Z","shell.execute_reply.started":"2024-12-01T05:36:33.924588Z","shell.execute_reply":"2024-12-01T05:36:33.929474Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.931322Z","iopub.execute_input":"2024-12-01T05:36:33.931597Z","iopub.status.idle":"2024-12-01T05:36:33.954840Z","shell.execute_reply.started":"2024-12-01T05:36:33.931557Z","shell.execute_reply":"2024-12-01T05:36:33.953994Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [1, 20811, 349, 396, 13126, 369, 13966, 264, 3...   \n1  [1, 20811, 349, 396, 13126, 369, 13966, 264, 3...   \n2  [1, 20811, 349, 396, 13126, 369, 13966, 264, 3...   \n3  [1, 20811, 349, 396, 13126, 369, 13966, 264, 3...   \n4  [1, 20811, 349, 396, 13126, 369, 13966, 264, 3...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[1, 20811, 349, 396, 13126, 369, 13966, 264, 3...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[1, 20811, 349, 396, 13126, 369, 13966, 264, 3...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[1, 20811, 349, 396, 13126, 369, 13966, 264, 3...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[1, 20811, 349, 396, 13126, 369, 13966, 264, 3...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[1, 20811, 349, 396, 13126, 369, 13966, 264, 3...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.955787Z","iopub.execute_input":"2024-12-01T05:36:33.956068Z","iopub.status.idle":"2024-12-01T05:36:33.960776Z","shell.execute_reply.started":"2024-12-01T05:36:33.956043Z","shell.execute_reply":"2024-12-01T05:36:33.959958Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.962112Z","iopub.execute_input":"2024-12-01T05:36:33.962524Z","iopub.status.idle":"2024-12-01T05:36:33.971049Z","shell.execute_reply.started":"2024-12-01T05:36:33.962487Z","shell.execute_reply":"2024-12-01T05:36:33.970221Z"}},"outputs":[{"name":"stdout","text":"[1, 20811, 349, 396, 13126, 369, 13966, 264, 3638, 28725, 5881, 1360, 395, 396, 2787, 369, 5312, 3629, 2758, 28723, 12018, 264, 2899, 369, 6582, 1999, 2691, 274, 272, 2159, 28723, 13, 13, 27332, 3133, 3112, 28747, 13, 27554, 1374, 272, 2078, 16067, 304, 9051, 871, 2191, 7335, 28723, 13, 13, 27332, 11232, 28747, 13, 13849, 15014, 19002, 2560, 297, 264, 9684, 4768, 2142, 28711, 2467, 7371, 315, 829, 459, 4530, 1560, 28756, 28711, 2467, 347, 624, 4530, 263, 28725, 1043, 315, 4857, 28756, 28711, 2467, 2382, 1060, 624, 390, 2082, 390, 315, 829, 28756, 28711, 1551, 970, 378, 16127, 297, 272, 916, 20621, 362, 8511, 28711, 28756, 28711, 11341, 2056, 272, 799, 28725, 390, 776, 390, 4968, 2142, 28711, 2467, 2461, 5230, 272, 1873, 3452, 2142, 28711, 17098, 378, 403, 10109, 28724, 304, 2613, 7656, 8511, 28711, 1227, 900, 390, 354, 369, 272, 9720, 736, 28756, 28711, 28769, 316, 15903, 706, 1528, 684, 272, 1348, 2142, 28711, 1014, 15014, 369, 3970, 13387, 4897, 28756, 28711, 657, 8049, 708, 3707, 553, 4056, 1036, 269, 2687, 5923, 28711, 6155, 28725, 315, 1749, 272, 907, 354, 1698, 1370, 8263, 28711, 28802, 299, 8215, 910, 1069, 8681, 356, 298, 1069, 2142, 28711, 28737, 6217, 286, 513, 315, 1023, 2270, 1567, 852, 5923, 28711, 28756, 28711, 28737, 4579, 347, 7124, 456, 395, 264, 19553, 28756, 28711, 11600, 2956, 14506, 304, 14506, 12211, 9941, 28711, 13849, 15014, 19002, 2560, 297, 264, 4768, 28725, 304, 315, 28821, 28756, 28711, 28737, 2056, 272, 624, 2108, 19948, 486, 2142, 28711, 2467, 369, 659, 1269, 544, 272, 5133, 28723, 13, 13, 27332, 12107, 28747, 13, 1014, 2191, 7335, 302, 272, 16067, 349, 272, 9545, 302, 2492, 10475, 304, 272, 5088, 302, 1395, 10475, 356, 624, 28742, 28713, 1411, 28723, 415, 17153, 349, 12565, 395, 264, 5161, 1444, 989, 12924, 304, 12665, 2183, 14779, 272, 624, 2108, 19948, 28725, 690, 12665, 17187, 652, 1411, 2659, 28723, 32000, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.977003Z","iopub.execute_input":"2024-12-01T05:36:33.977269Z","iopub.status.idle":"2024-12-01T05:36:33.982487Z","shell.execute_reply.started":"2024-12-01T05:36:33.977244Z","shell.execute_reply":"2024-12-01T05:36:33.981638Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.983389Z","iopub.execute_input":"2024-12-01T05:36:33.983656Z","iopub.status.idle":"2024-12-01T05:36:33.992101Z","shell.execute_reply.started":"2024-12-01T05:36:33.983617Z","shell.execute_reply":"2024-12-01T05:36:33.991336Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:33.993235Z","iopub.execute_input":"2024-12-01T05:36:33.994069Z","iopub.status.idle":"2024-12-01T05:36:34.001677Z","shell.execute_reply.started":"2024-12-01T05:36:33.994031Z","shell.execute_reply":"2024-12-01T05:36:34.000860Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:34.002561Z","iopub.execute_input":"2024-12-01T05:36:34.002791Z","iopub.status.idle":"2024-12-01T05:36:34.012207Z","shell.execute_reply.started":"2024-12-01T05:36:34.002769Z","shell.execute_reply":"2024-12-01T05:36:34.011509Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 32\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:34.013104Z","iopub.execute_input":"2024-12-01T05:36:34.013417Z","iopub.status.idle":"2024-12-01T05:36:34.022185Z","shell.execute_reply.started":"2024-12-01T05:36:34.013390Z","shell.execute_reply":"2024-12-01T05:36:34.021370Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:34.023146Z","iopub.execute_input":"2024-12-01T05:36:34.023398Z","iopub.status.idle":"2024-12-01T05:36:35.213138Z","shell.execute_reply.started":"2024-12-01T05:36:34.023374Z","shell.execute_reply":"2024-12-01T05:36:35.212191Z"}},"outputs":[{"name":"stdout","text":"trainable params: 83,886,080 || all params: 7,325,880,320 || trainable%: 1.1451\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:35.214203Z","iopub.execute_input":"2024-12-01T05:36:35.214499Z","iopub.status.idle":"2024-12-01T05:36:35.234380Z","shell.execute_reply.started":"2024-12-01T05:36:35.214469Z","shell.execute_reply":"2024-12-01T05:36:35.233526Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32032, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n  )\n  (lm_head): Linear(in_features=4096, out_features=32032, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:35.235465Z","iopub.execute_input":"2024-12-01T05:36:35.235750Z","iopub.status.idle":"2024-12-01T05:36:35.255710Z","shell.execute_reply.started":"2024-12-01T05:36:35.235721Z","shell.execute_reply":"2024-12-01T05:36:35.254998Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 3836219392\nTrainable parameters : 83886080\nTrainable percentage: 2.19%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:35.256689Z","iopub.execute_input":"2024-12-01T05:36:35.256971Z","iopub.status.idle":"2024-12-01T05:36:35.271455Z","shell.execute_reply.started":"2024-12-01T05:36:35.256941Z","shell.execute_reply":"2024-12-01T05:36:35.270637Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:35.272428Z","iopub.execute_input":"2024-12-01T05:36:35.272712Z","iopub.status.idle":"2024-12-01T05:36:35.322593Z","shell.execute_reply.started":"2024-12-01T05:36:35.272683Z","shell.execute_reply":"2024-12-01T05:36:35.321767Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec01_05-36-35_2e6f6d08fba1,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:35.323724Z","iopub.execute_input":"2024-12-01T05:36:35.324032Z","iopub.status.idle":"2024-12-01T05:36:37.242729Z","shell.execute_reply.started":"2024-12-01T05:36:35.324003Z","shell.execute_reply":"2024-12-01T05:36:37.242062Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x78540cbe9690>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:36:37.243842Z","iopub.execute_input":"2024-12-01T05:36:37.244191Z","iopub.status.idle":"2024-12-01T07:03:30.098056Z","shell.execute_reply.started":"2024-12-01T05:36:37.244153Z","shell.execute_reply":"2024-12-01T07:03:30.097314Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 83,886,080\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112879333333896, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19aca13935f64e13a16adbfb7c4d7345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241201_053648-r00mxcwh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/r00mxcwh' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/r00mxcwh' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/r00mxcwh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:26:21, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.304300</td>\n      <td>0.894652</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.757300</td>\n      <td>0.697313</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.654600</td>\n      <td>0.676615</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.655600</td>\n      <td>0.667681</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.618700</td>\n      <td>0.662334</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.619600</td>\n      <td>0.659053</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.609500</td>\n      <td>0.656116</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.618200</td>\n      <td>0.654684</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.609900</td>\n      <td>0.653973</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.550200</td>\n      <td>0.653831</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.6997732019424439, metrics={'train_runtime': 5212.4006, 'train_samples_per_second': 0.307, 'train_steps_per_second': 0.038, 'total_flos': 2.68316958523392e+16, 'train_loss': 0.6997732019424439, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:03:30.099084Z","iopub.execute_input":"2024-12-01T07:03:30.099361Z","iopub.status.idle":"2024-12-01T07:06:42.626531Z","shell.execute_reply.started":"2024-12-01T07:03:30.099324Z","shell.execute_reply":"2024-12-01T07:06:42.625526Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.6538311839103699, 'eval_runtime': 192.5143, 'eval_samples_per_second': 1.039, 'eval_steps_per_second': 0.26, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:06:42.627793Z","iopub.execute_input":"2024-12-01T07:06:42.628169Z","iopub.status.idle":"2024-12-01T07:06:44.570291Z","shell.execute_reply.started":"2024-12-01T07:06:42.628133Z","shell.execute_reply":"2024-12-01T07:06:44.569388Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Hermes-2-Pro-Mistral-7B/snapshots/69aa177971081db319c485212ec7f81dafcd6d8a/config.json\nModel config MistralConfig {\n  \"_name_or_path\": \"NousResearch/Hermes-2-Pro-Mistral-7B\",\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 32032\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Hermes-2-Pro-Mistral-7B/snapshots/69aa177971081db319c485212ec7f81dafcd6d8a/config.json\nModel config MistralConfig {\n  \"_name_or_path\": \"NousResearch/Hermes-2-Pro-Mistral-7B\",\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 32032\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:06:44.571411Z","iopub.execute_input":"2024-12-01T07:06:44.571677Z","iopub.status.idle":"2024-12-01T07:06:44.839537Z","shell.execute_reply.started":"2024-12-01T07:06:44.571653Z","shell.execute_reply":"2024-12-01T07:06:44.838474Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:06:44.840815Z","iopub.execute_input":"2024-12-01T07:06:44.841098Z","iopub.status.idle":"2024-12-01T07:06:44.851985Z","shell.execute_reply.started":"2024-12-01T07:06:44.841072Z","shell.execute_reply":"2024-12-01T07:06:44.851050Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:06:44.853277Z","iopub.execute_input":"2024-12-01T07:06:44.853670Z","iopub.status.idle":"2024-12-01T07:06:46.240294Z","shell.execute_reply.started":"2024-12-01T07:06:44.853628Z","shell.execute_reply":"2024-12-01T07:06:46.239607Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:06:46.241324Z","iopub.execute_input":"2024-12-01T07:06:46.241589Z","iopub.status.idle":"2024-12-01T07:07:04.867399Z","shell.execute_reply.started":"2024-12-01T07:06:46.241563Z","shell.execute_reply":"2024-12-01T07:07:04.866661Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Hermes-2-Pro-Mistral-7B/snapshots/69aa177971081db319c485212ec7f81dafcd6d8a/config.json\nModel config MistralConfig {\n  \"_name_or_path\": \"unsloth/Hermes-2-Pro-Mistral-7B\",\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 32032\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Hermes-2-Pro-Mistral-7B/snapshots/69aa177971081db319c485212ec7f81dafcd6d8a/model.safetensors.index.json\nInstantiating MistralForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"use_cache\": false\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c06835619cc4d3f969124d020ef5989"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing MistralForCausalLM.\n\nAll the weights of MistralForCausalLM were initialized from the model checkpoint at unsloth/Hermes-2-Pro-Mistral-7B.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Hermes-2-Pro-Mistral-7B/snapshots/69aa177971081db319c485212ec7f81dafcd6d8a/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"do_sample\": true,\n  \"eos_token_id\": 32000\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32032, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): MistralRMSNorm((4096,), eps=1e-05)\n  )\n  (lm_head): Linear(in_features=4096, out_features=32032, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.868541Z","iopub.execute_input":"2024-12-01T07:07:04.868905Z","iopub.status.idle":"2024-12-01T07:07:04.878893Z","shell.execute_reply.started":"2024-12-01T07:07:04.868867Z","shell.execute_reply":"2024-12-01T07:07:04.878109Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 3752333312\nTrainable parameters : 262672384\nTrainable percentage: 7.00%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.879783Z","iopub.execute_input":"2024-12-01T07:07:04.880041Z","iopub.status.idle":"2024-12-01T07:07:04.910263Z","shell.execute_reply.started":"2024-12-01T07:07:04.880017Z","shell.execute_reply":"2024-12-01T07:07:04.909212Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32032, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n      )\n      (lm_head): Linear(in_features=4096, out_features=32032, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.911313Z","iopub.execute_input":"2024-12-01T07:07:04.911577Z","iopub.status.idle":"2024-12-01T07:07:04.937768Z","shell.execute_reply.started":"2024-12-01T07:07:04.911553Z","shell.execute_reply":"2024-12-01T07:07:04.937020Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 3920105472\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.938760Z","iopub.execute_input":"2024-12-01T07:07:04.939036Z","iopub.status.idle":"2024-12-01T07:07:04.944431Z","shell.execute_reply.started":"2024-12-01T07:07:04.939012Z","shell.execute_reply":"2024-12-01T07:07:04.943577Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def post_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.945437Z","iopub.execute_input":"2024-12-01T07:07:04.945687Z","iopub.status.idle":"2024-12-01T07:07:04.955121Z","shell.execute_reply.started":"2024-12-01T07:07:04.945653Z","shell.execute_reply":"2024-12-01T07:07:04.954453Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.956073Z","iopub.execute_input":"2024-12-01T07:07:04.956379Z","iopub.status.idle":"2024-12-01T07:07:04.964548Z","shell.execute_reply.started":"2024-12-01T07:07:04.956344Z","shell.execute_reply":"2024-12-01T07:07:04.963733Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:07:04.965594Z","iopub.execute_input":"2024-12-01T07:07:04.965863Z","iopub.status.idle":"2024-12-01T07:08:41.520135Z","shell.execute_reply.started":"2024-12-01T07:07:04.965834Z","shell.execute_reply":"2024-12-01T07:08:41.519281Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    3752333312                     |                     3920105472                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Classify   |  completes the request.  ### Instruction: Classify \nthe following news report into three categories:    |  the following news report into three categories:  \nPolitics, Economics and Social.  ### Input: The     |  Politics, Economics and Social.  ### Input: The   \nUnited Nations Security Council has unanimously     |  United Nations Security Council has unanimously   \nadopted resolution 2371 that establishes a tough    |  adopted resolution 2371 that establishes a tough  \nnew sanctions regime against North Korea in         |  new sanctions regime against North Korea in       \nresponse to its ongoing weapons program.  ###       |  response to its ongoing weapons program.  ###     \nResponse: The given news report can be classified   |  Response: The given news report can be classified \nunder the category of Politics. This is because     |  under the category of Politics. This is because   \nthe news is about the United Nations Security       |  the news is about the United Nations Security     \nCouncil adopting a resolution (which is related to  |  Council adopting a resolution (which is related to\ninternational politics) to impose sanctions on      |  international politics) to impose sanctions on    \nNorth Korea due to its ongoing weapons program.     |  North Korea due to its ongoing weapons program.   \nThe topic does not primarily deal with economic     |  The topic does not primarily deal with economic   \naspects or social issues.  Category: Politics:::::  |  aspects or social issues.  However, it should be  \n::::::::::::::::::::::::::::::::::::::::::::::::::  |  noted that a news report can sometimes have       \n::::::::::::::::::::::::::::::::::::::::::::::::::  |  elements from multiple categories. In this case,  \n::::::::::::::::::::::::::::::::::::::::::::::::::  |  while politics is the primary category, there     \n::::::::::::::::::::::::::::::::::::::::::::::::::  |  could be a secondary connection to economics if   \n::::::::::::::::::: также:: также:: также::         |  one wants to explore the potential impact of      \nтакже:: также:: также:: также:: также:: также::     |  sanctions on North Korea's economy. But overall,  \nтакже:: также:: также:: также:: также:: также::     |  the main focus of the news report is on political \nтакже:: также:: также:: также:: также:: также::     |  actions taken by the United Nations Security      \nтакже:: также:: также:: также:: также:: также::     |  Council.                                          \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также:: также:: также:: также:: также::     |                                                    \nтакже:: также: также:: также: также: также: также:  |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также: также: также: также: также:    |                                                    \nтакже: также: также                                 |                                                    \n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:36:56.242860Z","iopub.execute_input":"2024-12-01T07:36:56.243618Z","iopub.status.idle":"2024-12-01T07:40:08.766824Z","shell.execute_reply.started":"2024-12-01T07:36:56.243585Z","shell.execute_reply":"2024-12-01T07:40:08.765969Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    3752333312                     |                     3920105472                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na rap verse about the given topic.  ### Input:      |  a rap verse about the given topic.  ### Input:    \nTopic: The importance of learning  ### Response:    |  Topic: The importance of learning  ### Response:  \nYo, listen up, I've got a story to tell, 'Bout the  |  Yo, listen up, I've got a story to tell, 'Bout the\npower of knowledge, it's time to yell, Learning is  |  power of knowledge, it's time to yell, Learning is\nthe key to success, don't let it<pad8>, It's the    |  the key to success, don't let it<pad8>, It's the  \nfoundation, the tool to progress.  From history to  |  foundation, the tool to progress.  From history to\nscience, math to art, Each subject holds a lesson   |  science, math to art, Each subject holds a lesson \nin its heart, It opens doors, it broadens minds,    |  in its heart, It opens doors, it broadens minds,  \nIgnites passions, sparks creativity and combines.   |  Ignites passions, sparks creativity and combines. \nThe wisdom we gain, it's priceless indeed, It's     |  The wisdom we gain, it's priceless indeed, It's   \nthe compass that guides us, the knowledge we need,  |  the compass that guides us, the knowledge we need,\nIt's the armor that protects us from harm, The      |  It's the armor that protects us from harm, The    \nlight that shines when the darkness is too calm.    |  light that shines when the darkness is too calm.  \nSo don't be afraid to hit the books, To ask         |  So don't be afraid to hit the books, To ask       \nquestions, to seek knowledge in walks, For the      |  questions, to seek knowledge in walks, For the    \nmore we learn, the more we grow, And the brighter   |  more we learn, the more we grow, And the brighter \nour future, the further we'll go.  Learning is the  |  our future, the further we'll go.  Learning is the\nkey, it's not just a phrase, It's the foundation    |  key, it's not just a phrase, It's the foundation  \nthat paves the way, To success, to wisdom, to a     |  that paves the way, To success, to wisdom, to a   \nlife well-lived, So embrace the journey, and let    |  life well-lived, So embrace the journey, and let  \nknowledge be your guide.  That's right, my          |  knowledge be given.  That's right, my friends, the\nfriends, the importance of learning, It's a         |  importance of learning, It's a message to share,  \nmessage to share, a lesson to discern, For          |  it's a lesson to earning, For knowledge is power, \nknowledge is power, it's the truth we can't deny,   |  it's the truth we can't deny, So let's keep on    \nSo let's keep on learning, let's reach for the      |  learning, let's reach for the sky.  (Repeat) The  \nsky.  (Repeat) The importance of learning, It's     |  importance of learning, it's a message to share,  \nthe compass that guides us, the knowledge we're     |  Let's keep on climbing, let's never stop and      \nearning, So don't be afraid to hit the books, For   |  stare, For the more we learn, the more we grow,   \nthe more we learn, the more we grow.  Learning,     |  And the brighter our future, the further we'll go.\nlearning, it's our duty, our right, To seek         |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nknowledge, to shine bright, So let's embrace this   |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \njourney, this path to success, And let learning be  |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nour guide, our unending progress.  ### Output:      |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nYo, I've got a message, a story to convey, About    |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nthe power that learning holds, so let me say, It's  |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nthe key to growth, the tool to excel, A foundation  |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nthat shapes us, a story to tell.  From history to   |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nscience, art to math, Each subject holds a lesson,  |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \na treasure trove, It broadens our minds, ignites    |  10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 \nour passions, And sparks creativity, a true         |  10.0 10.0 10.0 10.0                               \nsensation.  The wisdom we gain, it's priceless,     |                                                    \nindeed, A compass that guides us, a shield we       |                                                    \nneed, It protects us from harm, it lights up the    |                                                    \nway, When the darkness is too much, it shows the    |                                                    \nway.  So don't be afraid to dive in, to seek and    |                                                    \nfind, For the more we learn, the more we expand     |                                                    \nour mind, And the brighter our future, the further  |                                                    \nwe'll go, With learning by our side, we'll surely   |                                                    \ngrow.  Learning is the key, it's not just a         |                                                    \nphrase, It's the foundation that paves the way, To  |                                                    \nsuccess, to wisdom, to a life well-lived, So        |                                                    \nembrace the journey, let knowledge be your guide.   |                                                    \nThat's right, my friends, the importance of         |                                                    \nlearning, It's a message to share, a lesson to      |                                                    \ndiscern, For knowledge is power, it's the truth we  |                                                    \ncan't deny, So let's keep on learning, let's reach  |                                                    \nfor the sky.  (Repeat) The importance of learning,  |                                                    \nIt's the compass that guides us, the knowledge      |                                                    \nwe're earning, So don't be afraid to hit the        |                                                    \nbooks, For the more we learn, the more we grow.     |                                                    \nLearning, learning, it's our duty, our right, To    |                                                    \nseek knowledge, to shine bright, So let's embrace   |                                                    \nthis journey, this path to success, And let         |                                                    \nlearning be our guide, our unending progress.       |                                                    \n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:09:08.060888Z","iopub.execute_input":"2024-12-01T07:09:08.061148Z","iopub.status.idle":"2024-12-01T07:11:02.019693Z","shell.execute_reply.started":"2024-12-01T07:09:08.061121Z","shell.execute_reply":"2024-12-01T07:11:02.019023Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    3752333312                     |                     3920105472                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse:  Once upon a time, in a small village     |  Response:  Once upon a time, in a small village   \nnestled in the heart of a lush green valley, there  |  nestled in the heart of a lush green valley, there\nlived a young couple, Lila and Daniel. They were    |  lived a young couple, Lila and Daniel. They were  \ninseparable, and their love for each other was the  |  inseparable, and their love for each other was the\ntalk of the town. Their laughter echoed through     |  talk of the town. Their laughter echoed through   \nthe streets, and their love story was the envy of   |  the streets, and their love story was the envy of \nall who heard it.  One sunny morning, Daniel left   |  all who heard it.  One sunny morning, Daniel left \nthe village to work in the city, promising to       |  the village to work in the city, promising to     \nreturn as soon as he had made his fortune. Lila     |  return as soon as he had made his fortune. Lila   \nwaited for him with bated breath, filling their     |  waited for him with bated breath, filling their   \nsmall cottage with the warmth of her love and       |  small cottage with the warmth of her love and     \ndreams of their reunion.  Days turned into weeks,   |  dreams of their reunion.  Days turned into weeks, \nand weeks into months. Lila eagerly awaited every   |  and weeks into months. Lila eagerly awaited every \nletter that arrived, reading and re-reading         |  letter that arrived, reading and re-reading       \nDaniel's words of love and promises to return       |  Daniel's words of love and promises to return     \nsoon. But one day, a letter arrived that was        |  soon. But one day, a letter arrived that was      \ndifferent from the rest. It was brief and to the    |  different from the rest. It was brief and to the  \npoint, informing Lila of Daniel's untimely demise   |  point, informing Lila of Daniel's untimely demise \nin a tragic accident at work.  Lila's world         |  in a tragic accident at work.  Lila's world       \nshattered into a million pieces. She could not      |  shattered into a million pieces. She could not    \nbelieve that the love of her life was no more. The  |  believe that the love of her life was no more. The\nvillage mourned with her, but no words could ease   |  village mourned with her, but no words could ease \nher pain. She spent days and nights crying,         |  her pain. She spent days and nights crying,       \nmissing the touch, the smell, and the sound of      |  missing the touch, the laughter, and the warmth of\nDaniel.  As time passed, Lila slowly started        |  Daniel.  As time passed, Lila slowly began to pick\npicking up the pieces of her shattered heart. She   |  up the pieces of her shattered heart. She found   \nfound solace in the memories of Daniel and the      |  solace in the memories of Daniel and the love they\nlove they shared. She would often sit under the     |  shared. She would often sit under the tree they   \ntree they used to sit on, and talk to the wind      |  used to sit on, watching the sunset, and remember \nabout Daniel, sharing her happiness and sorrow      |  the promises they made to each other.  One day,   \nwith it.  One day, while sitting under the tree,    |  while walking through the woods, Lila stumbled    \nLila saw a young boy, no more than ten, sitting     |  upon a small, beautiful flower. It was unlike any \nalone, crying. He looked lost and alone, just like  |  flower she had ever seen before. She plucked it   \nLila did when she lost Daniel. Lila walked up to    |  and took it home, placing it in a vase in the     \nthe boy, and as she held him, she realized that     |  window sill. The flower bloomed, and its vibrant  \nlove and loss were two sides of the same coin.      |  colors filled Lila's heart with hope.  From then  \nLila held the boy, and in that moment, she          |  on, every time Lila looked at the flower, she was \nrealized that she could keep Daniel's memory alive  |  reminded of Daniel and the love they shared. She  \nby loving and caring for others. She realized that  |  realized that even though love can be lost, it can\nlove never dies, it just transforms into different  |  also be found in the most unexpected places. The  \nforms. And so, Lila took the boy home, raised him   |  flower became a symbol of hope and love for Lila, \nas her own, and filled his life with the same love  |  and she lived the rest of her life cherishing the \nand joy that Daniel had given her.  In the end,     |  memories of Daniel and the love they shared, while\nLila's love for Daniel did not die with him, but    |  also embracing the new love that bloomed in her   \nlived on through her, in the form of the boy, and   |  heart.  And so, the story of love and loss became \nthe love she shared with him. Her love and loss     |  a tale of hope and new beginnings, as Lila lived  \nbecame a story of hope, and a testament to the      |  the rest of her days surrounded by the love she so\nfact that love can conquer even the toughest of     |  deeply desired.                                   \ntimes.  And so, Lila lived the rest of her life,    |                                                    \nsurrounded by love, and with the memory of Daniel   |                                                    \nalways in her heart. She realized that love and     |                                                    \nloss were two sides of the same coin, and that      |                                                    \nlove could never be lost, only transformed into     |                                                    \ndifferent forms.  The end.                          |                                                    \n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T07:52:22.360290Z","iopub.execute_input":"2024-12-01T07:52:22.360991Z","iopub.status.idle":"2024-12-01T07:55:43.971104Z","shell.execute_reply.started":"2024-12-01T07:52:22.360956Z","shell.execute_reply":"2024-12-01T07:55:43.970257Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    3752333312                     |                     3920105472                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Compose a  |  completes the request.  ### Instruction: Compose a\npoem on the theme of autumn.  ### Input:   ###      |  poem on the theme of autumn.  ### Input:   ###    \nResponse:   Autumn's gentle touch, a whispering     |  Response:   Autumn's gentle touch, a whispering   \nbreeze, A kaleidoscope of colors, a sight that      |  breeze, A kaleidoscope of colors, a sight that    \ndoes please, The leaves, they fall, a dance to the  |  does please, The leaves, they fall, a dance to the\nground, A symphony of nature, a sight profound.     |  ground, A symphony of nature, a sight profound.   \nThe air, it crisps, a chill in the air, A           |  The air, it crisps, a chill in the air, A         \nharbinger of change, a season so rare, The days     |  harbinger of change, a season so rare, The days   \ngrow shorter, the nights, they draw near, A time    |  grow shorter, the nights, they draw near, A time  \nof transition, a season so dear.  The harvest is    |  of transition, a season so dear.  The harvest is  \nin, a bounty so grand, A testament to the earth's   |  in, a bounty so grand, A testament to the earth's \nbountiful hand, The fruits and the veggies, a       |  bountiful hand, The fruits and the veggies, a     \nfeast for the eye, A time to be thankful, a time    |  feast for the eye, A time to be thankful, a time  \nto be spry.  As autumn unfolds, a beauty so         |  to be spry.  As autumn unfolds, a beauty so       \nbright, A reminder of life, a cycle so tight, A     |  bright, A reminder of life, a cycle so tight, A   \nseason of change, a time to reflect, A time to      |  season of change, a time to reflect, A time to    \nembrace, the moments we've met.  So let us          |  embrace, the moments we've met.  So let us        \nrejoice, in autumn's sweet song, A time to be       |  rejoice, in autumn's sweet song, A time to be     \ngrateful, a time to belong, For in this season, a   |  grateful, a time to belong, For in this season, a \nmagic so pure, A love for life, a feeling secure.   |  magic so pure, A love for life, a feeling secure. \n                                                    |  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n                                                    |  21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37\n                                                    |  38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n                                                    |  55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n                                                    |  72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88\n                                                    |  89 90 91 92 93 94 95 96 97 98 99 100 101 102 103  \n                                                    |  104 105 106 107 108 109 110 111 112 113 114 115   \n                                                    |  116 117 118 119 120 121 122 123 124 125 126 127   \n                                                    |  128 129 130 131 132 133 134 135 136 137 138 явля́ \n                                                    |  yourself with the beauty of autumn, A time to     \n                                                    |  embrace the warmth and the chill, A season of     \n                                                    |  change, a sight to behold, A moment in time, a    \n                                                    |  memory to instill.  So let us revel in autumn's   \n                                                    |  embrace, A time to be grateful, a time to reflect,\n                                                    |  A season of change, a beauty to trace, A love for \n                                                    |  life, a feeling to perfect.  For in this season, a\n                                                    |  magic so pure, A love for life, a feeling secure, \n                                                    |  A time to be thankful, a moment to cherish, A     \n                                                    |  season of change, a beauty to caress.  And as we  \n                                                    |  journey through this autumn's delight, A time to  \n                                                    |  be present, a moment to ignite, May we find       \n                                                    |  gratitude in every leaf that falls, And cherish   \n                                                    |  the beauty that                                   \n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T08:01:59.902215Z","iopub.execute_input":"2024-12-01T08:01:59.903038Z","iopub.status.idle":"2024-12-01T08:03:06.830528Z","shell.execute_reply.started":"2024-12-01T08:01:59.903001Z","shell.execute_reply":"2024-12-01T08:03:06.829635Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    3752333312                     |                     3920105472                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe 3 main components of a simple robotic system    |  the 3 main components of a simple robotic system  \nin a conversational manner as if you were talking   |  in a conversational manner as if you were talking \nto a friend.  ### Input:   ### Response:  Hey       |  to a friend.  ### Input:   ### Response:  Hey     \nthere! So, imagine we're talking about a simple     |  there! So, imagine we're talking about a simple   \nrobotic system, like a little robot that can move   |  robotic system, like a little robot that can move \naround and do some tasks. There are 3 main          |  around and do some tasks. There are 3 main        \ncomponents that make this robot work, just like     |  components that make this robot work, just like   \nhow we have our brain, heart, and other organs      |  how we have our brain, heart, and other organs    \nthat keep us alive and functioning.  First, we      |  that keep us alive and functioning.  First, we    \nhave the 'controller' which is like the robot's     |  have the 'controller' which is like the robot's   \nbrain. It's responsible for making decisions and    |  brain. It's responsible for making decisions and  \nsending commands to the other parts of the robot.   |  sending commands to the other parts of the robot. \nThink of it like the boss of the robot, telling it  |  Think of it as the central hub that controls the  \nwhat to do and when to do it.  Second, we have the  |  robot's actions.  Second, we have the 'actuator.' \n'actuator.' This is like the robot's muscles.       |  This is like the robot's muscles. Actuators are   \nActuators are devices that allow the robot to move  |  devices that allow the robot to move or change its\nand interact with its environment. For example, if  |  position. They're what make the robot's arms or   \nthe robot needs to pick up an object, the actuator  |  legs move, or make it pick up objects.  Lastly, we\nwould be the motor or mechanism that enables it to  |  have the 'sensor.' This is like the robot's eyes  \ndo so.  Lastly, we have the 'sensor.' This is like  |  and ears. Sensors are used to detect things in the\nthe robot's eyes and ears, allowing it to 'see'     |  environment, like light or sound. They help the   \nand 'hear' what's happening around it. Sensors are  |  robot 'see' where it is and what's happening      \ndevices that detect changes in the environment and  |  around it, so it can make decisions and interact  \nsend this information back to the controller. This  |  with the world.  So, to sum it up, a simple       \nway, the robot can react to what's happening        |  robotic system has a controller (like the brain), \naround it, like avoiding an obstacle or finding     |  actuators (like muscles), and sensors (like eyes  \nits way back to its charging station.  So, to sum   |  and ears). These 3 components work together to    \nit up, a simple robotic system has a controller     |  make the robot move, perceive its environment, and\n(like the brain), actuators (like muscles), and     |  make decisions. It's kind of like having a        \nsensors (like eyes and ears), all working together  |  miniature, automated assistant that can help with \nto make the robot function and perform tasks. It's  |  tasks!                                            \nkind of like a miniature team of helpers, each      |                                                    \nwith their own job, to make the robot efficient     |                                                    \nand effective!                                      |                                                    \n","output_type":"stream"}],"execution_count":84}]}