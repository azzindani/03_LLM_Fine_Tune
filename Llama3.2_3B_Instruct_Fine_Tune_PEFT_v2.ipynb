{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-24T11:18:38.422288Z","iopub.execute_input":"2024-11-24T11:18:38.425159Z","iopub.status.idle":"2024-11-24T11:19:27.767957Z","shell.execute_reply.started":"2024-11-24T11:18:38.425103Z","shell.execute_reply":"2024-11-24T11:19:27.766992Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-24T11:19:27.769768Z","iopub.execute_input":"2024-11-24T11:19:27.770075Z","iopub.status.idle":"2024-11-24T11:19:47.985780Z","shell.execute_reply.started":"2024-11-24T11:19:27.770046Z","shell.execute_reply":"2024-11-24T11:19:47.984818Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-24T11:19:47.986834Z","iopub.execute_input":"2024-11-24T11:19:47.987085Z","iopub.status.idle":"2024-11-24T11:19:47.994378Z","shell.execute_reply.started":"2024-11-24T11:19:47.987061Z","shell.execute_reply":"2024-11-24T11:19:47.992776Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'unsloth/Llama-3.2-3B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-24T11:19:47.996177Z","iopub.execute_input":"2024-11-24T11:19:47.996449Z","iopub.status.idle":"2024-11-24T11:19:48.025857Z","shell.execute_reply.started":"2024-11-24T11:19:47.996422Z","shell.execute_reply":"2024-11-24T11:19:48.025038Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-24T11:19:48.026948Z","iopub.execute_input":"2024-11-24T11:19:48.027254Z","iopub.status.idle":"2024-11-24T11:19:48.038387Z","shell.execute_reply.started":"2024-11-24T11:19:48.027230Z","shell.execute_reply":"2024-11-24T11:19:48.037598Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:19:48.039406Z","iopub.execute_input":"2024-11-24T11:19:48.039805Z","iopub.status.idle":"2024-11-24T11:22:29.942362Z","shell.execute_reply.started":"2024-11-24T11:19:48.039769Z","shell.execute_reply":"2024-11-24T11:22:29.941593Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/928 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f649d4a076a24dc3bacfd1f3a69599db"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7eb66246d4c414686e1a728df07e4e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ea5f8dcf3a428aac467da841912418"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:29.943523Z","iopub.execute_input":"2024-11-24T11:22:29.943796Z","iopub.status.idle":"2024-11-24T11:22:29.950626Z","shell.execute_reply.started":"2024-11-24T11:22:29.943769Z","shell.execute_reply":"2024-11-24T11:22:29.949717Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:29.951938Z","iopub.execute_input":"2024-11-24T11:22:29.952282Z","iopub.status.idle":"2024-11-24T11:22:32.451038Z","shell.execute_reply.started":"2024-11-24T11:22:29.952245Z","shell.execute_reply":"2024-11-24T11:22:32.450403Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d601ae72805e4bc7ab7744e616e1f0e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9166193d239b46f6a58d6840fa1f1d60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cdf02fbc1314fa7bbaf724084ce8fd0"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:32.452279Z","iopub.execute_input":"2024-11-24T11:22:32.452638Z","iopub.status.idle":"2024-11-24T11:22:32.456887Z","shell.execute_reply.started":"2024-11-24T11:22:32.452599Z","shell.execute_reply":"2024-11-24T11:22:32.456056Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 512","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:32.460397Z","iopub.execute_input":"2024-11-24T11:22:32.460687Z","iopub.status.idle":"2024-11-24T11:22:32.466318Z","shell.execute_reply.started":"2024-11-24T11:22:32.460662Z","shell.execute_reply":"2024-11-24T11:22:32.465524Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:32.467332Z","iopub.execute_input":"2024-11-24T11:22:32.467622Z","iopub.status.idle":"2024-11-24T11:22:37.394768Z","shell.execute_reply.started":"2024-11-24T11:22:32.467586Z","shell.execute_reply":"2024-11-24T11:22:37.394057Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcee027044c1492b8e9019a7b489618c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"alpaca_data_cleaned.json:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c890da107a2402f978bcae2b7ccaf69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5139df5c69c45d086ace6cdd34e0dd7"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.395926Z","iopub.execute_input":"2024-11-24T11:22:37.396562Z","iopub.status.idle":"2024-11-24T11:22:37.402660Z","shell.execute_reply.started":"2024-11-24T11:22:37.396520Z","shell.execute_reply":"2024-11-24T11:22:37.401790Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.403741Z","iopub.execute_input":"2024-11-24T11:22:37.404062Z","iopub.status.idle":"2024-11-24T11:22:37.421570Z","shell.execute_reply.started":"2024-11-24T11:22:37.403985Z","shell.execute_reply":"2024-11-24T11:22:37.420664Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.422497Z","iopub.execute_input":"2024-11-24T11:22:37.422744Z","iopub.status.idle":"2024-11-24T11:22:37.430155Z","shell.execute_reply.started":"2024-11-24T11:22:37.422720Z","shell.execute_reply":"2024-11-24T11:22:37.429265Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.431227Z","iopub.execute_input":"2024-11-24T11:22:37.431516Z","iopub.status.idle":"2024-11-24T11:22:37.438856Z","shell.execute_reply.started":"2024-11-24T11:22:37.431493Z","shell.execute_reply":"2024-11-24T11:22:37.438056Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.439970Z","iopub.execute_input":"2024-11-24T11:22:37.440487Z","iopub.status.idle":"2024-11-24T11:22:37.448320Z","shell.execute_reply.started":"2024-11-24T11:22:37.440461Z","shell.execute_reply":"2024-11-24T11:22:37.447545Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.449187Z","iopub.execute_input":"2024-11-24T11:22:37.449507Z","iopub.status.idle":"2024-11-24T11:22:37.457805Z","shell.execute_reply.started":"2024-11-24T11:22:37.449444Z","shell.execute_reply":"2024-11-24T11:22:37.456897Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:37.458990Z","iopub.execute_input":"2024-11-24T11:22:37.459440Z","iopub.status.idle":"2024-11-24T11:22:38.003060Z","shell.execute_reply.started":"2024-11-24T11:22:37.459403Z","shell.execute_reply":"2024-11-24T11:22:38.002234Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf2ed7d4c128441aac65337cab6a63b2"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:38.004164Z","iopub.execute_input":"2024-11-24T11:22:38.004518Z","iopub.status.idle":"2024-11-24T11:22:38.009365Z","shell.execute_reply.started":"2024-11-24T11:22:38.004467Z","shell.execute_reply":"2024-11-24T11:22:38.008479Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:38.010613Z","iopub.execute_input":"2024-11-24T11:22:38.010975Z","iopub.status.idle":"2024-11-24T11:22:38.029439Z","shell.execute_reply.started":"2024-11-24T11:22:38.010931Z","shell.execute_reply":"2024-11-24T11:22:38.028680Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:38.030330Z","iopub.execute_input":"2024-11-24T11:22:38.030568Z","iopub.status.idle":"2024-11-24T11:22:46.357284Z","shell.execute_reply.started":"2024-11-24T11:22:38.030539Z","shell.execute_reply":"2024-11-24T11:22:46.356438Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"538fa2ac72e34d9a984d728c1d8c211c"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.358405Z","iopub.execute_input":"2024-11-24T11:22:46.358678Z","iopub.status.idle":"2024-11-24T11:22:46.365240Z","shell.execute_reply.started":"2024-11-24T11:22:46.358652Z","shell.execute_reply":"2024-11-24T11:22:46.364423Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.366454Z","iopub.execute_input":"2024-11-24T11:22:46.366791Z","iopub.status.idle":"2024-11-24T11:22:46.444404Z","shell.execute_reply.started":"2024-11-24T11:22:46.366754Z","shell.execute_reply":"2024-11-24T11:22:46.443582Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.445480Z","iopub.execute_input":"2024-11-24T11:22:46.446020Z","iopub.status.idle":"2024-11-24T11:22:46.451631Z","shell.execute_reply.started":"2024-11-24T11:22:46.445963Z","shell.execute_reply":"2024-11-24T11:22:46.450760Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.452677Z","iopub.execute_input":"2024-11-24T11:22:46.453023Z","iopub.status.idle":"2024-11-24T11:22:46.475647Z","shell.execute_reply.started":"2024-11-24T11:22:46.452967Z","shell.execute_reply":"2024-11-24T11:22:46.474917Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [128004, 128004, 128004, 128004, 128004, 12800...   \n1  [128004, 128004, 128004, 128004, 128004, 12800...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128004, 128004, 128004, 128004, 128004, 12800...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.476432Z","iopub.execute_input":"2024-11-24T11:22:46.476672Z","iopub.status.idle":"2024-11-24T11:22:46.481785Z","shell.execute_reply.started":"2024-11-24T11:22:46.476648Z","shell.execute_reply":"2024-11-24T11:22:46.480859Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|eot_id|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.482904Z","iopub.execute_input":"2024-11-24T11:22:46.483262Z","iopub.status.idle":"2024-11-24T11:22:46.493175Z","shell.execute_reply.started":"2024-11-24T11:22:46.483226Z","shell.execute_reply":"2024-11-24T11:22:46.492382Z"}},"outputs":[{"name":"stdout","text":"[128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 11, 35526, 449, 459, 1988, 430, 5825, 4726, 2317, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 2127, 56956, 279, 2728, 33894, 323, 10765, 1202, 1925, 7057, 382, 14711, 5688, 512, 11874, 19795, 37441, 3640, 304, 264, 14071, 7732, 27362, 77, 3112, 14931, 358, 1436, 539, 5944, 2225, 1734, 3112, 387, 832, 63865, 11, 1317, 358, 14980, 1734, 3112, 7111, 1523, 832, 439, 3117, 439, 358, 1436, 1734, 1271, 1405, 433, 30280, 304, 279, 1234, 74189, 18364, 77, 1734, 12487, 3952, 279, 1023, 11, 439, 1120, 439, 6762, 27362, 77, 3112, 3515, 8530, 279, 2731, 3802, 27362, 77, 18433, 433, 574, 16763, 88, 323, 4934, 10051, 18364, 77, 27831, 439, 369, 430, 279, 12579, 1070, 1734, 56568, 24634, 1124, 2216, 922, 279, 1890, 27362, 89330, 19795, 430, 6693, 18813, 11203, 1734, 644, 11141, 912, 3094, 1047, 8348, 11025, 3776, 7255, 77, 12174, 11, 358, 2163, 279, 1176, 369, 2500, 1938, 15114, 77, 29174, 14392, 1268, 1648, 11767, 389, 311, 1648, 27362, 77, 40, 93762, 422, 358, 1288, 3596, 2586, 1203, 7255, 77, 1734, 40, 4985, 387, 11890, 420, 449, 264, 31238, 1734, 50982, 61752, 17051, 323, 17051, 16472, 7338, 77, 11874, 19795, 37441, 3640, 304, 264, 7732, 11, 323, 358, 2345, 59, 77, 40, 3952, 279, 832, 2753, 31796, 555, 27362, 77, 3112, 430, 706, 1903, 682, 279, 6811, 382, 14711, 6075, 512, 791, 1925, 7057, 315, 279, 33894, 374, 279, 12939, 315, 3339, 11709, 323, 279, 5536, 315, 1884, 11709, 389, 832, 596, 2324, 13, 578, 19114, 374, 17011, 449, 264, 5597, 1990, 1403, 13006, 323, 13967, 41011, 279, 832, 2753, 31796, 11, 902, 13967, 21483, 872, 2324, 3217, 13, 128009]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.499788Z","iopub.execute_input":"2024-11-24T11:22:46.500100Z","iopub.status.idle":"2024-11-24T11:22:46.504986Z","shell.execute_reply.started":"2024-11-24T11:22:46.500075Z","shell.execute_reply":"2024-11-24T11:22:46.504308Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.506051Z","iopub.execute_input":"2024-11-24T11:22:46.506370Z","iopub.status.idle":"2024-11-24T11:22:46.514639Z","shell.execute_reply.started":"2024-11-24T11:22:46.506333Z","shell.execute_reply":"2024-11-24T11:22:46.514019Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.515702Z","iopub.execute_input":"2024-11-24T11:22:46.516051Z","iopub.status.idle":"2024-11-24T11:22:46.525830Z","shell.execute_reply.started":"2024-11-24T11:22:46.516013Z","shell.execute_reply":"2024-11-24T11:22:46.525011Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.526948Z","iopub.execute_input":"2024-11-24T11:22:46.527292Z","iopub.status.idle":"2024-11-24T11:22:46.533617Z","shell.execute_reply.started":"2024-11-24T11:22:46.527257Z","shell.execute_reply":"2024-11-24T11:22:46.532937Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.534598Z","iopub.execute_input":"2024-11-24T11:22:46.535360Z","iopub.status.idle":"2024-11-24T11:22:46.541901Z","shell.execute_reply.started":"2024-11-24T11:22:46.535333Z","shell.execute_reply":"2024-11-24T11:22:46.541057Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:46.542873Z","iopub.execute_input":"2024-11-24T11:22:46.543133Z","iopub.status.idle":"2024-11-24T11:22:47.842387Z","shell.execute_reply.started":"2024-11-24T11:22:46.543109Z","shell.execute_reply":"2024-11-24T11:22:47.841495Z"}},"outputs":[{"name":"stdout","text":"trainable params: 97,255,424 || all params: 3,310,005,248 || trainable%: 2.9382\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:47.843469Z","iopub.execute_input":"2024-11-24T11:22:47.843760Z","iopub.status.idle":"2024-11-24T11:22:47.857795Z","shell.execute_reply.started":"2024-11-24T11:22:47.843733Z","shell.execute_reply":"2024-11-24T11:22:47.856909Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:47.858836Z","iopub.execute_input":"2024-11-24T11:22:47.859133Z","iopub.status.idle":"2024-11-24T11:22:47.881837Z","shell.execute_reply.started":"2024-11-24T11:22:47.859103Z","shell.execute_reply":"2024-11-24T11:22:47.881013Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1900719104\nTrainable parameters : 97255424\nTrainable percentage: 5.12%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:47.882834Z","iopub.execute_input":"2024-11-24T11:22:47.883140Z","iopub.status.idle":"2024-11-24T11:22:47.896331Z","shell.execute_reply.started":"2024-11-24T11:22:47.883101Z","shell.execute_reply":"2024-11-24T11:22:47.895455Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:47.897491Z","iopub.execute_input":"2024-11-24T11:22:47.898292Z","iopub.status.idle":"2024-11-24T11:22:47.934923Z","shell.execute_reply.started":"2024-11-24T11:22:47.898257Z","shell.execute_reply":"2024-11-24T11:22:47.934031Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov24_11-22-47_6a1f1d21b7e6,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:47.936192Z","iopub.execute_input":"2024-11-24T11:22:47.936463Z","iopub.status.idle":"2024-11-24T11:22:49.883881Z","shell.execute_reply.started":"2024-11-24T11:22:47.936434Z","shell.execute_reply":"2024-11-24T11:22:49.883059Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7b414816b610>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:22:49.884891Z","iopub.execute_input":"2024-11-24T11:22:49.885152Z","iopub.status.idle":"2024-11-24T12:18:53.975181Z","shell.execute_reply.started":"2024-11-24T11:22:49.885125Z","shell.execute_reply":"2024-11-24T12:18:53.974204Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 97,255,424\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113730666668035, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6db0af239b294365a271213b283fa78d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_112259-gis3xuom</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/gis3xuom' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/gis3xuom' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/gis3xuom</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 55:39, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.993500</td>\n      <td>1.825907</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.687300</td>\n      <td>1.510052</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.304600</td>\n      <td>1.178737</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.115900</td>\n      <td>1.147627</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.112700</td>\n      <td>1.134612</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.083100</td>\n      <td>1.127962</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.106400</td>\n      <td>1.124334</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.060400</td>\n      <td>1.122617</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.092000</td>\n      <td>1.121871</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.020000</td>\n      <td>1.121765</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.2575746250152589, metrics={'train_runtime': 3363.6623, 'train_samples_per_second': 0.476, 'train_steps_per_second': 0.059, 'total_flos': 1.4810766901248e+16, 'train_loss': 1.2575746250152589, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:18:53.976448Z","iopub.execute_input":"2024-11-24T12:18:53.976820Z","iopub.status.idle":"2024-11-24T12:20:54.971585Z","shell.execute_reply.started":"2024-11-24T12:18:53.976780Z","shell.execute_reply":"2024-11-24T12:20:54.970739Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 01:58]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 1.1217646598815918, 'eval_runtime': 120.9816, 'eval_samples_per_second': 1.653, 'eval_steps_per_second': 0.413, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:20:54.972751Z","iopub.execute_input":"2024-11-24T12:20:54.973039Z","iopub.status.idle":"2024-11-24T12:20:57.606510Z","shell.execute_reply.started":"2024-11-24T12:20:54.972985Z","shell.execute_reply":"2024-11-24T12:20:57.605805Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:20:57.607500Z","iopub.execute_input":"2024-11-24T12:20:57.607725Z","iopub.status.idle":"2024-11-24T12:20:57.898740Z","shell.execute_reply.started":"2024-11-24T12:20:57.607702Z","shell.execute_reply":"2024-11-24T12:20:57.897916Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:20:57.899750Z","iopub.execute_input":"2024-11-24T12:20:57.900065Z","iopub.status.idle":"2024-11-24T12:20:57.910455Z","shell.execute_reply.started":"2024-11-24T12:20:57.900029Z","shell.execute_reply":"2024-11-24T12:20:57.909521Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:20:57.911650Z","iopub.execute_input":"2024-11-24T12:20:57.911894Z","iopub.status.idle":"2024-11-24T12:20:59.411078Z","shell.execute_reply.started":"2024-11-24T12:20:57.911870Z","shell.execute_reply":"2024-11-24T12:20:59.410117Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:20:59.412220Z","iopub.execute_input":"2024-11-24T12:20:59.412491Z","iopub.status.idle":"2024-11-24T12:21:07.619699Z","shell.execute_reply.started":"2024-11-24T12:20:59.412464Z","shell.execute_reply":"2024-11-24T12:21:07.618934Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"unsloth/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ]\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/Llama-3.2-3B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.620848Z","iopub.execute_input":"2024-11-24T12:21:07.621204Z","iopub.status.idle":"2024-11-24T12:21:07.631041Z","shell.execute_reply.started":"2024-11-24T12:21:07.621164Z","shell.execute_reply":"2024-11-24T12:21:07.630278Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.631987Z","iopub.execute_input":"2024-11-24T12:21:07.632257Z","iopub.status.idle":"2024-11-24T12:21:07.656418Z","shell.execute_reply.started":"2024-11-24T12:21:07.632232Z","shell.execute_reply":"2024-11-24T12:21:07.655714Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 3072)\n        (layers): ModuleList(\n          (0-27): 28 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.657354Z","iopub.execute_input":"2024-11-24T12:21:07.657587Z","iopub.status.idle":"2024-11-24T12:21:07.680814Z","shell.execute_reply.started":"2024-11-24T12:21:07.657563Z","shell.execute_reply":"2024-11-24T12:21:07.680066Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1997974528\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.682016Z","iopub.execute_input":"2024-11-24T12:21:07.682578Z","iopub.status.idle":"2024-11-24T12:21:07.689783Z","shell.execute_reply.started":"2024-11-24T12:21:07.682539Z","shell.execute_reply":"2024-11-24T12:21:07.689132Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def post_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.690897Z","iopub.execute_input":"2024-11-24T12:21:07.691246Z","iopub.status.idle":"2024-11-24T12:21:07.699946Z","shell.execute_reply.started":"2024-11-24T12:21:07.691210Z","shell.execute_reply":"2024-11-24T12:21:07.699200Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:07.701008Z","iopub.execute_input":"2024-11-24T12:21:07.701327Z","iopub.status.idle":"2024-11-24T12:21:07.709787Z","shell.execute_reply.started":"2024-11-24T12:21:07.701290Z","shell.execute_reply":"2024-11-24T12:21:07.709027Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:46:15.926575Z","iopub.execute_input":"2024-11-24T12:46:15.926923Z","iopub.status.idle":"2024-11-24T12:46:45.185510Z","shell.execute_reply.started":"2024-11-24T12:46:15.926895Z","shell.execute_reply":"2024-11-24T12:46:45.184683Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Compose a  |  completes the request.  ### Instruction: Compose a\npoem about a single color.  ### Input:   ###        |  poem about a single color.  ### Input:   ###      \nResponse: \"Amidst the whispers of a summer breeze,  |  Response: \"Amidst the whispers of a summer breeze,\nLies a hue that stirs the soul with ease.           |  Lies a hue that stirs the soul with ease.         \nCerulean, a canvas of the sky, A reflection of the  |  Cerulean, a canvas of the sky, A reflection of the\nheavens, passing by.  In morning's glow, it softly  |  heavens, passing by.  In morning's glow, it softly\nshines, A gentle reminder of life's divine. As      |  shines, A gentle reminder of life's divine. As    \nsunbeams dance, its beauty's told, A color born of  |  sunbeams dance, its beauty's told, A color born of\nheaven's heart of gold.  In art and dreams, it      |  heaven's heart of gold.  In twilight's hush, it   \nfinds its place, A symbol of the infinite's gentle  |  softly gleams, A soothing balm for weary dreams. A\nface. Cerulean's beauty, pure and true, A color     |  symbol of hope, a promise made, Cerulean's beauty \nthat in hearts, forever shines through.\"  ---       |  is forever displayed.\"  This poem explores the    \nNote: The response is a poem that captures the      |  theme of the color cerulean, describing its       \nessence of the color cerulean, exploring its        |  various appearances throughout the day and its    \nemotional and symbolic significance. It weaves      |  emotional resonance. It uses imagery and metaphor \ntogether imagery, metaphor, and symbolism to        |  to convey the sense of calm and serenity that the \nconvey the beauty and significance of this color.   |  color evokes. The poem's structure and language   \n                                                    |  are designed to evoke a sense of wonder and       \n                                                    |  appreciation for the beauty of the color.         \n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:58:08.827359Z","iopub.execute_input":"2024-11-24T12:58:08.827699Z","iopub.status.idle":"2024-11-24T12:59:37.988032Z","shell.execute_reply.started":"2024-11-24T12:58:08.827670Z","shell.execute_reply":"2024-11-24T12:59:37.987077Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na possible future for humankind if artificial       |  a possible future for humankind if artificial     \nintelligence (AI) becomes more advanced and         |  intelligence (AI) becomes more advanced and       \nprevalent.  ### Input:   ### Response: As AI        |  prevalent.  ### Input:   ### Response: As AI      \ncontinues to advance and become more prevalent in   |  continues to advance and become more prevalent in \nvarious aspects of life, it is likely that          |  various aspects of life, it is likely that        \nhumankind will undergo significant                  |  humankind will undergo significant                \ntransformations. Here's a possible future:  **Year  |  transformations. Here's a possible future:  **Year\n2154: The AI-Driven Era**  By the mid-22nd          |  2154: The Age of Augmented Intelligence**  By the \ncentury, AI has become an integral part of human    |  mid-22nd century, AI has reached an unprecedented \nsociety. It has transformed industries,             |  level of sophistication, permeating every aspect  \nrevolutionized healthcare, and enabled              |  of human life. Virtual assistants, now            \nunprecedented levels of innovation and progress.    |  indistinguishable from human-like entities, manage\nThe AI-driven economy has created new job           |  daily tasks, freeing humans to focus on creative  \nopportunities, and the concept of work has evolved  |  pursuits. Cities are designed with AI-driven      \nto focus on creative and high-value tasks.          |  infrastructure, optimizing energy consumption,    \n**Global Cooperation and Governance**  The          |  waste management, and public services.  **The Rise\nincreasing reliance on AI has led to the            |  of the Luminari**  A new class of humans, known as\nestablishment of a global AI governance framework.  |  the Luminari, emerges. These individuals have     \nThis framework ensures that AI development and      |  augmented their bodies with AI-powered implants,  \ndeployment are aligned with human values, ethics,   |  enhancing their cognitive abilities, physical     \nand the well-being of all nations. The United       |  prowess, and emotional intelligence. The Luminari \nNations has been reformed to include a dedicated    |  become the driving force behind humanity's        \nAI department, which oversees the development and   |  progress, leveraging AI to solve complex problems \nuse of AI worldwide.  **The Rise of the Post-       |  and push the boundaries of scientific discovery.  \nScarcity Economy**  With AI's help, the global      |  **The AI-Driven Economy**  The global economy is  \neconomy has transitioned to a post-scarcity model.  |  transformed as AI assumes the roles of managers,  \nAdvanced technologies like nanotechnology,          |  analysts, and creatives. Humans focus on high-    \nbiotechnology, and renewable energy have made       |  level decision-making, innovation, and artistic   \nresources virtually unlimited. This has led to a    |  expression. The concept of work becomes obsolete, \nsignificant reduction in poverty, hunger, and       |  and the notion of a universal basic income is     \ndisease. The concept of money has been redefined,   |  implemented to ensure everyone's basic needs are  \nand a universal basic income has been implemented   |  met.  **The Evolution of Education**  Education is\nto ensure everyone's basic needs are met.  **The    |  revolutionized as AI-powered adaptive learning    \nEvolution of Human Intelligence**  As AI becomes    |  systems become the norm. Personalized learning    \nmore advanced, humans have begun to augment their   |  paths are tailored to each individual's strengths,\nintelligence with AI-powered implants and brain-    |  weaknesses, and interests, ensuring that every    \ncomputer interfaces. This has enabled people to     |  person has the opportunity to reach their full    \naccess vast amounts of knowledge, enhance their     |  potential.  **The Challenges of a Post-Scarcity   \ncognitive abilities, and even achieve a form of     |  Society**  As AI assumes the roles of managers and\ndigital immortality. The human brain has become a   |  analysts, the concept of scarcity becomes         \nhub for AI processing, blurring the lines between   |  increasingly irrelevant. However, this also raises\nhuman and machine intelligence.  **The New Human    |  questions about purpose, meaning, and fulfillment.\nExperience**  In this future, humans have more      |  Humans must adapt to a world where work is no     \ntime to focus on personal growth, creativity, and   |  longer the primary driver of motivation and       \nrelationships. The concept of work has been         |  satisfaction.  **The Future of Human              \nredefined, and people are free to pursue their      |  Relationships**  With the rise of AI-driven       \npassions without the burden of a 9-to-5 job.        |  companionship, human relationships evolve. People \nVirtual and augmented reality have become           |  form deep connections with AI entities, which     \nindistinguishable from reality itself, allowing     |  provide emotional support, empathy, and           \nhumans to explore and experience the world in ways  |  understanding. These relationships become an      \npreviously unimaginable.  **Challenges and          |  integral part of human life, complementing        \nConcerns**  While this future holds many promises,  |  traditional social bonds.  **The Path Forward**   \nit also raises concerns about the potential risks   |  As humanity embarks on this new era of augmented  \nof advanced AI. Ensuring that AI is aligned with    |  intelligence, it is essential to address the      \nhuman values and ethics has become a top priority.  |  challenges that arise. Governments, corporations, \nThe development of AI has also led to new forms of  |  and individuals must work together to create a    \ncybercrime, data breaches, and AI-related job       |  society that values human well-being, creativity, \ndisplacement.  **Conclusion**  The future of        |  and fulfillment. By embracing the possibilities of\nhumankind in 2154 is one of unprecedented progress  |  AI, we can create a brighter future for all.  This\nand transformation. As AI continues to advance, it  |  possible future highlights the potential benefits \nis essential that we prioritize responsible AI      |  and challenges of an AI-driven world. As we       \ndevelopment, governance, and use. By working        |  continue to advance in this area, it is crucial to\ntogether, we can create a future where humans and   |  prioritize human well-being, creativity, and      \nAI collaborate to create a better world for all.    |  fulfillment, ensuring that the benefits of AI are \n                                                    |  shared by all.                                    \n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T12:21:54.184689Z","iopub.execute_input":"2024-11-24T12:21:54.184957Z","iopub.status.idle":"2024-11-24T12:23:09.452079Z","shell.execute_reply.started":"2024-11-24T12:21:54.184930Z","shell.execute_reply":"2024-11-24T12:23:09.451135Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse: The old wooden rocking chair creaked as   |  Response: The old wooden rocking chair creaked as \nEmma gently rocked back and forth, her eyes fixed   |  Emma gently rocked back and forth, her eyes fixed \non the faded photograph in her hand. It was a       |  on the faded photograph in her hand. It was a     \npicture of her and Jack, taken on their first       |  picture of her and Jack, taken on their first     \ndate, just a few months before the war had torn     |  date, just a few months before the war had torn   \nthem apart. The memories of that fateful day still  |  them apart. The memories of that fateful day still\nlingered, like the scent of freshly cut grass on a  |  lingered, like the scent of freshly cut grass on a\nsummer afternoon.  Their love had been a flame      |  summer afternoon.  Their love had been a flame    \nthat burned bright and true, but it was             |  that burned bright and true, but it was           \nextinguished by the cruel hand of fate. Jack had    |  extinguished by the cruel hand of fate. Jack had  \nbeen called to fight, and Emma had waited           |  been called to fight, and Emma had waited         \nanxiously for his return, her heart heavy with the  |  anxiously for his return, her heart heavy with the\nweight of uncertainty. But the days turned into     |  weight of uncertainty. But the days turned into   \nweeks, and the weeks into months, and the months    |  weeks, and the weeks into months, and the months  \ninto years. The letters stopped coming, and the     |  into years. The letters stopped coming, and the   \nsilence was deafening.  As Emma rocked, she felt    |  silence was deafening.  As Emma rocked, she felt  \nthe ache of loss still keenly. She had thought she  |  the ache of loss still keenly. She had thought she\nhad moved on, that the pain had dulled with time.   |  had moved on, that the pain had dulled with time. \nBut the photograph brought it all back, and she     |  But the photograph brought it all back, and she   \nfelt the sting of tears in her eyes. She            |  felt the sting of tears in her eyes. She          \nremembered the way Jack used to smile at her, the   |  remembered the way Jack used to smile at her, the \nway his eyes crinkled at the corners when he        |  way his eyes crinkled at the corners when he      \nlaughed. She remembered the way he used to hold     |  laughed. She remembered the way he used to hold   \nher hand, the way his fingers intertwined with      |  her hand, the way his fingers intertwined with    \nhers like the branches of a tree.  The war had      |  hers like the branches of a tree.  The war had    \ntaken him from her, but it had also taken a part    |  taken him from her, but it had also taken a part  \nof her. She felt like a part of her had been left   |  of her. She had learned to live with the grief, to\nbehind, like a piece of her heart was still with    |  find solace in the memories of their time         \nJack, waiting for him to return. The rocking chair  |  together. But some days, like today, the pain felt\nseemed to sway in time with her heartbeat, as if    |  like it was still raw, still fresh.  As she       \nit too felt the weight of her sorrow.  As the sun   |  rocked, Emma felt a sense of peace settle over    \ndipped below the horizon, casting the room in a     |  her. She knew that Jack was gone, but she also    \nwarm orange glow, Emma felt a sense of peace wash   |  knew that their love would never truly die. It    \nover her. She knew that Jack was gone, but she      |  would live on in her heart, a flame that would    \nalso knew that their love would never truly die.    |  burn bright for the rest of her days. And with    \nIt would live on in her heart, a flame that would   |  that thought, she felt a sense of comfort, a sense\nburn bright and true, even in the darkest of        |  of knowing that she was not alone in her grief.   \ntimes. And as she rocked, she felt the warmth of    |  The photograph slipped from her hand, and Emma    \nthat flame, a reminder that even in loss, there is  |  caught it just as it was about to fall. She looked\nalways love to be found.                            |  at it again, and this time, she saw not just the  \n                                                    |  memories of their time together, but also the     \n                                                    |  promise of a new beginning. She knew that she     \n                                                    |  would always carry Jack with her, in her heart and\n                                                    |  in her memories. And with that thought, she felt a\n                                                    |  sense of love and loss that was both overwhelming \n                                                    |  and beautiful.                                    \n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:00:37.116402Z","iopub.execute_input":"2024-11-24T13:00:37.116721Z","iopub.status.idle":"2024-11-24T13:01:13.544110Z","shell.execute_reply.started":"2024-11-24T13:00:37.116694Z","shell.execute_reply":"2024-11-24T13:01:13.543211Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe personality traits of an introvert  ### Input:  |  the personality traits of an introvert  ### Input:\n### Response: An introvert is typically             |  ### Response: An introvert is typically           \ncharacterized by several personality traits that    |  characterized by several personality traits that  \nset them apart from extroverts. Some key traits     |  set them apart from extroverts. Some key traits   \ninclude:  *   **Reserved nature**: Introverts tend  |  include:  *   **Reserved nature**: Introverts tend\nto be more reserved and may take time to warm up    |  to be more reserved and may take time to warm up  \nto new people or situations. *   **Independent      |  to new people or situations. *   **Independent    \nthinking**: Introverts often prefer to think for    |  thinking**: Introverts often prefer to think for  \nthemselves and may be more inclined to reflect on   |  themselves and may be more inclined to reflect on \ntheir thoughts and feelings. *   **Low-key social   |  their thoughts and feelings. *   **Low-key social \ninteractions**: Introverts may prefer smaller,      |  interactions**: Introverts may prefer smaller,    \nmore low-key social gatherings or one-on-one        |  more low-key social gatherings or may even prefer \ninteractions, rather than large group settings. *   |  to spend time alone. *   **Active listening**:    \n**Energy conservation**: Introverts often conserve  |  Introverts are often skilled listeners and may be \ntheir energy by avoiding excessive social           |  more attentive to the conversations around them. *\ninteraction or stimulation, and may need time       |  **Self-motivation**: Introverts tend to be self-  \nalone to recharge. *   **Deep thinking**:           |  motivated and may be more inclined to work        \nIntroverts may be more inclined to engage in deep,  |  independently. *   **Emotional depth**: Introverts\nintrospective thinking, and may be more likely to   |  may be more emotionally expressive and may be more\nexplore complex ideas and emotions. *               |  attuned to the emotions of those around them.     \n**Authenticity**: Introverts often value            |  These traits can vary from person to person, and  \nauthenticity and honesty in their relationships     |  not all introverts will exhibit all of these      \nand interactions, and may be more likely to speak   |  characteristics. However, they are common         \ntheir minds and be themselves.  These traits are    |  personality traits associated with introversion.  \nnot universal and may vary from person to person,   |                                                    \nbut they are common characteristics associated      |                                                    \nwith introversion.                                  |                                                    \n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:03:42.875532Z","iopub.execute_input":"2024-11-24T13:03:42.875877Z","iopub.status.idle":"2024-11-24T13:04:08.516863Z","shell.execute_reply.started":"2024-11-24T13:03:42.875847Z","shell.execute_reply":"2024-11-24T13:04:08.516013Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Name 3     |  completes the request.  ### Instruction: Name 3   \nelements that are characteristics of a well-        |  elements that are characteristics of a well-      \nstructured essay.  ### Input:   ### Response: A     |  structured essay.  ### Input:   ### Response: A   \nwell-structured essay typically includes the        |  well-structured essay typically includes the      \nfollowing three elements:  1. **Clear Thesis        |  following three elements:  1. **Clear Thesis      \nStatement**: A clear and concise thesis statement   |  Statement**: A clear and concise thesis statement \nthat sets the tone for the entire essay, providing  |  that sets the tone for the entire essay, providing\na clear direction and focus for the reader. 2.      |  a clear direction and focus for the reader. 2.    \n**Logical Organization**: A logical organization    |  **Organized Body Paragraphs**: Well-organized body\nof ideas, with each paragraph building upon the     |  paragraphs that provide evidence and supporting   \nprevious one to create a cohesive narrative that    |  details to develop and expand on the thesis       \nflows smoothly from one idea to the next. 3.        |  statement, typically following a logical structure\n**Effective Transitions**: Effective transitions    |  such as introduction, body, and conclusion. 3.    \nthat connect each paragraph to the next, using      |  **Effective Transitions and Conclusion**:         \ntransitional phrases or words to guide the reader   |  Effective transitions between paragraphs that     \nthrough the essay and create a sense of continuity  |  guide the reader through the essay, and a strong  \nand flow.  These three elements work together to    |  conclusion that summarizes the main points and    \ncreate a well-structured essay that is clear,       |  reiterates the thesis statement, leaving a lasting\nconcise, and engaging, making it easier for the     |  impression on the reader.  These three elements   \nreader to follow the author's argument or point.    |  work together to create a cohesive and well-      \n                                                    |  structured essay that effectively communicates the\n                                                    |  writer's message.                                 \n","output_type":"stream"}],"execution_count":71}]}