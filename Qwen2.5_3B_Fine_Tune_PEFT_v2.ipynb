{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Qwen2.5_3B_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:15:52.573472Z",
          "iopub.execute_input": "2024-11-23T11:15:52.574202Z",
          "iopub.status.idle": "2024-11-23T11:16:25.553160Z",
          "shell.execute_reply.started": "2024-11-23T11:15:52.574144Z",
          "shell.execute_reply": "2024-11-23T11:16:25.551982Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:25.555116Z",
          "iopub.execute_input": "2024-11-23T11:16:25.555441Z",
          "iopub.status.idle": "2024-11-23T11:16:32.685820Z",
          "shell.execute_reply.started": "2024-11-23T11:16:25.555412Z",
          "shell.execute_reply": "2024-11-23T11:16:32.684946Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:32.687198Z",
          "iopub.execute_input": "2024-11-23T11:16:32.687611Z",
          "iopub.status.idle": "2024-11-23T11:16:32.694634Z",
          "shell.execute_reply.started": "2024-11-23T11:16:32.687570Z",
          "shell.execute_reply": "2024-11-23T11:16:32.693722Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'Qwen/Qwen2.5-3B'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:32.695649Z",
          "iopub.execute_input": "2024-11-23T11:16:32.695899Z",
          "iopub.status.idle": "2024-11-23T11:16:32.703413Z",
          "shell.execute_reply.started": "2024-11-23T11:16:32.695874Z",
          "shell.execute_reply": "2024-11-23T11:16:32.702708Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:32.705373Z",
          "iopub.execute_input": "2024-11-23T11:16:32.705634Z",
          "iopub.status.idle": "2024-11-23T11:16:32.714369Z",
          "shell.execute_reply.started": "2024-11-23T11:16:32.705610Z",
          "shell.execute_reply": "2024-11-23T11:16:32.713429Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:32.715418Z",
          "iopub.execute_input": "2024-11-23T11:16:32.715753Z",
          "iopub.status.idle": "2024-11-23T11:16:40.987950Z",
          "shell.execute_reply.started": "2024-11-23T11:16:32.715717Z",
          "shell.execute_reply": "2024-11-23T11:16:40.987153Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:40.989105Z",
          "iopub.execute_input": "2024-11-23T11:16:40.989390Z",
          "iopub.status.idle": "2024-11-23T11:16:40.997306Z",
          "shell.execute_reply.started": "2024-11-23T11:16:40.989362Z",
          "shell.execute_reply": "2024-11-23T11:16:40.996454Z"
        },
        "outputId": "2d452ca8-6fa5-42af-9447-b47edf60ad51"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:40.998356Z",
          "iopub.execute_input": "2024-11-23T11:16:40.998629Z",
          "iopub.status.idle": "2024-11-23T11:16:41.586187Z",
          "shell.execute_reply.started": "2024-11-23T11:16:40.998605Z",
          "shell.execute_reply": "2024-11-23T11:16:41.585207Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:41.587404Z",
          "iopub.execute_input": "2024-11-23T11:16:41.587692Z",
          "iopub.status.idle": "2024-11-23T11:16:41.591535Z",
          "shell.execute_reply.started": "2024-11-23T11:16:41.587667Z",
          "shell.execute_reply": "2024-11-23T11:16:41.590592Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:41.592515Z",
          "iopub.execute_input": "2024-11-23T11:16:41.592748Z",
          "iopub.status.idle": "2024-11-23T11:16:41.600198Z",
          "shell.execute_reply.started": "2024-11-23T11:16:41.592725Z",
          "shell.execute_reply": "2024-11-23T11:16:41.599542Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:41.601241Z",
          "iopub.execute_input": "2024-11-23T11:16:41.601594Z",
          "iopub.status.idle": "2024-11-23T11:16:46.301563Z",
          "shell.execute_reply.started": "2024-11-23T11:16:41.601559Z",
          "shell.execute_reply": "2024-11-23T11:16:46.300478Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.302525Z",
          "iopub.execute_input": "2024-11-23T11:16:46.302802Z",
          "iopub.status.idle": "2024-11-23T11:16:46.308990Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.302776Z",
          "shell.execute_reply": "2024-11-23T11:16:46.308368Z"
        },
        "id": "xNJ4pjoTt4aj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.309976Z",
          "iopub.execute_input": "2024-11-23T11:16:46.310192Z",
          "iopub.status.idle": "2024-11-23T11:16:46.327111Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.310170Z",
          "shell.execute_reply": "2024-11-23T11:16:46.326288Z"
        },
        "outputId": "9b146216-f8e0-46ff-82ba-9fa9652bd830"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.330646Z",
          "iopub.execute_input": "2024-11-23T11:16:46.331020Z",
          "iopub.status.idle": "2024-11-23T11:16:46.337081Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.330995Z",
          "shell.execute_reply": "2024-11-23T11:16:46.336372Z"
        },
        "outputId": "e1e3c8e6-44d7-4c54-e375-d97c897f18a7"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.337969Z",
          "iopub.execute_input": "2024-11-23T11:16:46.338213Z",
          "iopub.status.idle": "2024-11-23T11:16:46.346375Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.338178Z",
          "shell.execute_reply": "2024-11-23T11:16:46.345635Z"
        },
        "outputId": "39aa4e86-ac15-4cfc-f750-2f1269f759ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.347566Z",
          "iopub.execute_input": "2024-11-23T11:16:46.348206Z",
          "iopub.status.idle": "2024-11-23T11:16:46.354933Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.348167Z",
          "shell.execute_reply": "2024-11-23T11:16:46.354150Z"
        },
        "id": "o1XAR5Uet4ak"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.355834Z",
          "iopub.execute_input": "2024-11-23T11:16:46.356086Z",
          "iopub.status.idle": "2024-11-23T11:16:46.364218Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.356061Z",
          "shell.execute_reply": "2024-11-23T11:16:46.363544Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.365169Z",
          "iopub.execute_input": "2024-11-23T11:16:46.365446Z",
          "iopub.status.idle": "2024-11-23T11:16:46.909643Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.365423Z",
          "shell.execute_reply": "2024-11-23T11:16:46.908817Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.910838Z",
          "iopub.execute_input": "2024-11-23T11:16:46.911113Z",
          "iopub.status.idle": "2024-11-23T11:16:46.916039Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.911087Z",
          "shell.execute_reply": "2024-11-23T11:16:46.915169Z"
        },
        "outputId": "24875c32-9960-4ec1-b11a-e8bb45784888"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.917107Z",
          "iopub.execute_input": "2024-11-23T11:16:46.917389Z",
          "iopub.status.idle": "2024-11-23T11:16:46.941763Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.917365Z",
          "shell.execute_reply": "2024-11-23T11:16:46.940933Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:46.942877Z",
          "iopub.execute_input": "2024-11-23T11:16:46.943227Z",
          "iopub.status.idle": "2024-11-23T11:16:56.031387Z",
          "shell.execute_reply.started": "2024-11-23T11:16:46.943188Z",
          "shell.execute_reply": "2024-11-23T11:16:56.030521Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.032312Z",
          "iopub.execute_input": "2024-11-23T11:16:56.032572Z",
          "iopub.status.idle": "2024-11-23T11:16:56.037714Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.032548Z",
          "shell.execute_reply": "2024-11-23T11:16:56.036880Z"
        },
        "outputId": "ff824ad0-efd0-4751-edcd-ea7ffd9f8f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.038737Z",
          "iopub.execute_input": "2024-11-23T11:16:56.038983Z",
          "iopub.status.idle": "2024-11-23T11:16:56.119062Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.038959Z",
          "shell.execute_reply": "2024-11-23T11:16:56.118220Z"
        },
        "outputId": "d4677c28-8958-44d2-895c-5d9910a980d0"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.120294Z",
          "iopub.execute_input": "2024-11-23T11:16:56.120934Z",
          "iopub.status.idle": "2024-11-23T11:16:56.129465Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.120893Z",
          "shell.execute_reply": "2024-11-23T11:16:56.128621Z"
        },
        "outputId": "1d3585ad-55b5-4295-80e6-1989acc4995b"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.130535Z",
          "iopub.execute_input": "2024-11-23T11:16:56.130867Z",
          "iopub.status.idle": "2024-11-23T11:16:56.155152Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.130830Z",
          "shell.execute_reply": "2024-11-23T11:16:56.154488Z"
        },
        "outputId": "ca8549da-63b7-4369-f999-198617dba76d"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n1  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n2  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n3  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n4  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.156358Z",
          "iopub.execute_input": "2024-11-23T11:16:56.156801Z",
          "iopub.status.idle": "2024-11-23T11:16:56.161706Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.156762Z",
          "shell.execute_reply": "2024-11-23T11:16:56.160907Z"
        },
        "outputId": "a5c5750e-a3f1-4438-f607-46ae40685c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|endoftext|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.162677Z",
          "iopub.execute_input": "2024-11-23T11:16:56.162921Z",
          "iopub.status.idle": "2024-11-23T11:16:56.172905Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.162897Z",
          "shell.execute_reply": "2024-11-23T11:16:56.172159Z"
        },
        "outputId": "c452ba30-aed2-493c-8ea3-0311159e7102"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[38214, 374, 458, 7600, 429, 16555, 264, 3383, 11, 34426, 448, 458, 1946, 429, 5707, 4623, 2266, 13, 9645, 264, 2033, 429, 34901, 44595, 279, 1681, 382, 14374, 29051, 510, 2082, 55856, 279, 2661, 32794, 323, 10542, 1181, 1887, 6912, 382, 14374, 5571, 510, 11613, 19241, 36341, 3556, 304, 264, 13753, 7579, 26266, 77, 3036, 14589, 358, 1410, 537, 5821, 2176, 1699, 3036, 387, 825, 62765, 11, 1293, 358, 14638, 1699, 3036, 6966, 1495, 825, 438, 3041, 438, 358, 1410, 1699, 1249, 1380, 432, 29180, 304, 279, 1212, 73089, 17882, 77, 1699, 12209, 3867, 279, 1008, 11, 438, 1101, 438, 6624, 26266, 77, 3036, 3432, 8365, 279, 2664, 3717, 26266, 77, 17949, 432, 572, 16359, 88, 323, 4829, 9850, 17882, 77, 26733, 438, 369, 429, 279, 12299, 1052, 1699, 55468, 23704, 1105, 2167, 911, 279, 1852, 26266, 88230, 19241, 429, 6556, 18308, 10962, 1699, 641, 10901, 902, 3019, 1030, 8185, 10792, 3691, 7110, 77, 11908, 11, 358, 2115, 279, 1156, 369, 2441, 1899, 14771, 77, 28074, 14063, 1246, 1616, 11508, 389, 311, 1616, 26266, 77, 40, 92662, 421, 358, 1265, 3512, 2525, 1182, 7110, 77, 1699, 40, 4880, 387, 11629, 419, 448, 264, 30138, 1699, 49882, 60652, 16639, 323, 16639, 16085, 7190, 77, 11613, 19241, 36341, 3556, 304, 264, 7579, 11, 323, 358, 2293, 59, 77, 40, 3867, 279, 825, 2686, 30696, 553, 26266, 77, 3036, 429, 702, 1865, 678, 279, 6672, 382, 14374, 5949, 510, 785, 1887, 6912, 315, 279, 32794, 374, 279, 12650, 315, 3259, 11454, 323, 279, 5421, 315, 1846, 11454, 389, 825, 594, 2272, 13, 576, 18601, 374, 16601, 448, 264, 5480, 1948, 1378, 12716, 323, 13653, 39911, 279, 825, 2686, 30696, 11, 892, 13653, 20816, 862, 2272, 3139, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.173925Z",
          "iopub.execute_input": "2024-11-23T11:16:56.174889Z",
          "iopub.status.idle": "2024-11-23T11:16:56.184506Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.174848Z",
          "shell.execute_reply": "2024-11-23T11:16:56.183686Z"
        },
        "outputId": "e577e367-a777-4190-c69b-caeec991376f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.185282Z",
          "iopub.execute_input": "2024-11-23T11:16:56.185527Z",
          "iopub.status.idle": "2024-11-23T11:16:56.196359Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.185503Z",
          "shell.execute_reply": "2024-11-23T11:16:56.195621Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.197320Z",
          "iopub.execute_input": "2024-11-23T11:16:56.197551Z",
          "iopub.status.idle": "2024-11-23T11:16:56.205975Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.197522Z",
          "shell.execute_reply": "2024-11-23T11:16:56.205024Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.206891Z",
          "iopub.execute_input": "2024-11-23T11:16:56.207151Z",
          "iopub.status.idle": "2024-11-23T11:16:56.216050Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.207127Z",
          "shell.execute_reply": "2024-11-23T11:16:56.215234Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.216893Z",
          "iopub.execute_input": "2024-11-23T11:16:56.217151Z",
          "iopub.status.idle": "2024-11-23T11:16:56.225896Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.217127Z",
          "shell.execute_reply": "2024-11-23T11:16:56.225154Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:56.226816Z",
          "iopub.execute_input": "2024-11-23T11:16:56.227064Z",
          "iopub.status.idle": "2024-11-23T11:16:57.739145Z",
          "shell.execute_reply.started": "2024-11-23T11:16:56.227039Z",
          "shell.execute_reply": "2024-11-23T11:16:57.738178Z"
        },
        "outputId": "4f55140d-dcd2-47c9-ddb2-de5a7ad30a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 119,734,272 || all params: 3,205,672,960 || trainable%: 3.7351\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:57.740269Z",
          "iopub.execute_input": "2024-11-23T11:16:57.740572Z",
          "iopub.status.idle": "2024-11-23T11:16:57.757073Z",
          "shell.execute_reply.started": "2024-11-23T11:16:57.740539Z",
          "shell.execute_reply": "2024-11-23T11:16:57.756076Z"
        },
        "outputId": "715111a7-3146-4858-e925-55cb58f75b0f"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=11008, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:57.758175Z",
          "iopub.execute_input": "2024-11-23T11:16:57.758491Z",
          "iopub.status.idle": "2024-11-23T11:16:57.774994Z",
          "shell.execute_reply.started": "2024-11-23T11:16:57.758462Z",
          "shell.execute_reply": "2024-11-23T11:16:57.774206Z"
        },
        "outputId": "2be229e3-5d6a-4b21-f510-613467cb1620"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1818406912\nTrainable parameters : 119734272\nTrainable percentage: 6.58%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:57.776317Z",
          "iopub.execute_input": "2024-11-23T11:16:57.776623Z",
          "iopub.status.idle": "2024-11-23T11:16:57.784055Z",
          "shell.execute_reply.started": "2024-11-23T11:16:57.776593Z",
          "shell.execute_reply": "2024-11-23T11:16:57.783182Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 1\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:57.785124Z",
          "iopub.execute_input": "2024-11-23T11:16:57.785997Z",
          "iopub.status.idle": "2024-11-23T11:16:57.822295Z",
          "shell.execute_reply.started": "2024-11-23T11:16:57.785956Z",
          "shell.execute_reply": "2024-11-23T11:16:57.821493Z"
        },
        "outputId": "8ab4d850-d599-4805-c357-619e4d0edbc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov23_11-16-57_b61918a65600,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:16:57.823330Z",
          "iopub.execute_input": "2024-11-23T11:16:57.823584Z",
          "iopub.status.idle": "2024-11-23T11:17:00.112896Z",
          "shell.execute_reply.started": "2024-11-23T11:16:57.823554Z",
          "shell.execute_reply": "2024-11-23T11:17:00.112180Z"
        },
        "outputId": "a1c7dd54-e8e0-4887-b802-f771340b5ac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7d4d304c2650>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T11:17:00.113800Z",
          "iopub.execute_input": "2024-11-23T11:17:00.114033Z",
          "iopub.status.idle": "2024-11-23T12:00:48.375189Z",
          "shell.execute_reply.started": "2024-11-23T11:17:00.114010Z",
          "shell.execute_reply": "2024-11-23T12:00:48.374312Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:00:48.376544Z",
          "iopub.execute_input": "2024-11-23T12:00:48.376895Z",
          "iopub.status.idle": "2024-11-23T12:02:49.393182Z",
          "shell.execute_reply.started": "2024-11-23T12:00:48.376860Z",
          "shell.execute_reply": "2024-11-23T12:02:49.392305Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:02:49.400531Z",
          "iopub.execute_input": "2024-11-23T12:02:49.400806Z",
          "iopub.status.idle": "2024-11-23T12:02:52.409602Z",
          "shell.execute_reply.started": "2024-11-23T12:02:49.400781Z",
          "shell.execute_reply": "2024-11-23T12:02:52.408849Z"
        },
        "outputId": "a971a6dd-1294-486c-f8c5-98af9d773d60"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 36,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 36,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:02:52.410597Z",
          "iopub.execute_input": "2024-11-23T12:02:52.410870Z",
          "iopub.status.idle": "2024-11-23T12:02:52.751087Z",
          "shell.execute_reply.started": "2024-11-23T12:02:52.410844Z",
          "shell.execute_reply": "2024-11-23T12:02:52.750016Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:02:52.752478Z",
          "iopub.execute_input": "2024-11-23T12:02:52.752873Z",
          "iopub.status.idle": "2024-11-23T12:02:52.764069Z",
          "shell.execute_reply.started": "2024-11-23T12:02:52.752830Z",
          "shell.execute_reply": "2024-11-23T12:02:52.763264Z"
        },
        "id": "X5k1j6xDt4ao",
        "outputId": "012a93ed-ddb7-4e74-9b9b-8e3effadefb6"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:02:52.765132Z",
          "iopub.execute_input": "2024-11-23T12:02:52.765470Z",
          "iopub.status.idle": "2024-11-23T12:02:54.670560Z",
          "shell.execute_reply.started": "2024-11-23T12:02:52.765425Z",
          "shell.execute_reply": "2024-11-23T12:02:54.669699Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "bJ9gElXJt4ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:02:54.671599Z",
          "iopub.execute_input": "2024-11-23T12:02:54.671909Z",
          "iopub.status.idle": "2024-11-23T12:03:02.931846Z",
          "shell.execute_reply.started": "2024-11-23T12:02:54.671875Z",
          "shell.execute_reply": "2024-11-23T12:03:02.931023Z"
        },
        "id": "KVrq1DLst4ao"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:02.933062Z",
          "iopub.execute_input": "2024-11-23T12:03:02.933444Z",
          "iopub.status.idle": "2024-11-23T12:03:02.944487Z",
          "shell.execute_reply.started": "2024-11-23T12:03:02.933405Z",
          "shell.execute_reply": "2024-11-23T12:03:02.943711Z"
        },
        "id": "i_IkRHjet4ao",
        "outputId": "981bbcce-9135-4477-e600-2f15176a1227"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:02.945665Z",
          "iopub.execute_input": "2024-11-23T12:03:02.946020Z",
          "iopub.status.idle": "2024-11-23T12:03:02.969666Z",
          "shell.execute_reply.started": "2024-11-23T12:03:02.945980Z",
          "shell.execute_reply": "2024-11-23T12:03:02.968814Z"
        },
        "id": "xSKwjIF0t4ao",
        "outputId": "d29f707a-d926-43b8-8486-59cf41872966"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 2048)\n        (layers): ModuleList(\n          (0-35): 36 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=11008, out_features=64, bias=False)\n                  (default): Linear(in_features=11008, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:02.970710Z",
          "iopub.execute_input": "2024-11-23T12:03:02.970967Z",
          "iopub.status.idle": "2024-11-23T12:03:03.001124Z",
          "shell.execute_reply.started": "2024-11-23T12:03:02.970942Z",
          "shell.execute_reply": "2024-11-23T12:03:03.000374Z"
        },
        "id": "-MXqmQkxt4ao",
        "outputId": "a39988f8-e4fa-45dc-ba35-44bb252215c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1938141184\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:03.002027Z",
          "iopub.execute_input": "2024-11-23T12:03:03.002279Z",
          "iopub.status.idle": "2024-11-23T12:03:03.008734Z",
          "shell.execute_reply.started": "2024-11-23T12:03:03.002229Z",
          "shell.execute_reply": "2024-11-23T12:03:03.007866Z"
        },
        "id": "xAg0NQXgt4ao"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:03.009894Z",
          "iopub.execute_input": "2024-11-23T12:03:03.010525Z",
          "iopub.status.idle": "2024-11-23T12:03:03.019394Z",
          "shell.execute_reply.started": "2024-11-23T12:03:03.010477Z",
          "shell.execute_reply": "2024-11-23T12:03:03.018690Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:03:03.020358Z",
          "iopub.execute_input": "2024-11-23T12:03:03.021307Z",
          "iopub.status.idle": "2024-11-23T12:03:03.030071Z",
          "shell.execute_reply.started": "2024-11-23T12:03:03.021209Z",
          "shell.execute_reply": "2024-11-23T12:03:03.029490Z"
        },
        "id": "fN9_Wrf7t4ap"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:15:33.658616Z",
          "iopub.execute_input": "2024-11-23T12:15:33.659507Z",
          "iopub.status.idle": "2024-11-23T12:17:07.809370Z",
          "shell.execute_reply.started": "2024-11-23T12:15:33.659457Z",
          "shell.execute_reply": "2024-11-23T12:17:07.808441Z"
        },
        "outputId": "f55c44c8-14fc-4839-a6ab-ca79f1ffc9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe implications of Artificial Intelligence  ###    |  the implications of Artificial Intelligence  ###  \nInput:   ### Response: Artificial Intelligence      |  Input:   ### Response: Artificial Intelligence    \n(AI) has far-reaching implications that impact      |  (AI) has far-reaching implications that impact    \nvarious aspects of society, including but not       |  various aspects of society, including but not     \nlimited��:  1. Employment: AI has the potential to  |  limited��:  1. Employment: AI has the potential to\nautomate many tasks, leading to job displacement    |  automate many tasks, leading to job displacement  \nin certain industries. However, it also creates     |  in certain industries. However, it also creates   \nnew job opportunities in areas such as AI           |  new job opportunities in areas such as AI         \ndevelopment, maintenance, and management.  2.       |  development, maintenance, and management.  2.     \nPrivacy: AI systems collect and analyze vast        |  Privacy: AI systems collect and analyze vast      \namounts of personal data, raising concerns about    |  amounts of personal data, raising concerns about  \nprivacy and security. Ensuring the protection of    |  privacy and security. Ensuring the protection of  \nsensitive information is crucial to maintain        |  sensitive information is crucial to maintain      \npublic trust in AI technologies.  3. Bias: AI       |  public trust in AI technologies.  3. Bias: AI     \nsystems can perpetuate and amplify existing biases  |  systems can perpetuate and amplify existing biases\npresent in the data they are trained on.            |  present in the data they are trained on.          \nAddressing and mitigating these biases is           |  Addressing and mitigating these biases is         \nessential to ensure fair and equitable outcomes.    |  essential to ensure fair and equitable outcomes.  \n4. Ethics: AI raises ethical questions about        |  4. Ethics: AI raises ethical questions about      \naccountability, transparency, and responsibility.   |  accountability, transparency, and responsibility. \nEstablishing clear guidelines and regulations is    |  Establishing clear guidelines and regulations is  \nnecessary to guide the development and use of AI    |  necessary to guide the development and deployment \ntechnologies.  5. Society: AI has the potential to  |  of AI systems.  5. Society: AI has the potential  \ntransform society by improving healthcare,          |  to transform society by improving healthcare,     \neducation, transportation, and more. However, it    |  education, transportation, and more. However, it  \nalso poses challenges related to social             |  also poses challenges related to social           \ninequality, as access to AI technologies may not    |  inequality, as access to AI technologies may not  \nbe equally distributed.  6. Security: AI can be     |  be equally distributed.  6. Security: AI can be   \nused for both good and evil purposes. It can        |  used for both good and evil purposes. It can      \nenhance security by detecting and preventing cyber  |  enhance security by detecting and preventing cyber\nthreats, but it can also be used for malicious      |  threats, but it can also be used for malicious    \nactivities, such as hacking and surveillance.  7.   |  activities, such as hacking and surveillance.  7. \nEducation: AI can revolutionize education by        |  Education: AI can revolutionize education by      \nproviding personalized learning experiences, but    |  providing personalized learning experiences, but  \nit also raises concerns about the quality and       |  it also raises concerns about the quality and     \naccessibility of education.  8. Environment: AI     |  accessibility of education.  8. Environment: AI   \ncan help address environmental challenges by        |  can help address environmental challenges by      \noptimizing energy consumption, monitoring           |  optimizing energy consumption, monitoring         \necosystems, and developing sustainable solutions.   |  ecosystems, and developing sustainable solutions. \nHowever, it also requires careful consideration of  |  However, it also requires careful consideration of\nits environmental impact.  9. Law: AI raises legal  |  its environmental impact.  9. Law: AI raises legal\nquestions about liability, jurisdiction, and the    |  questions about liability, jurisdiction, and the  \ninterpretation of laws. Establishing clear legal    |  interpretation of laws. Establishing clear legal  \nframeworks is necessary to govern the use of AI     |  frameworks is necessary to govern the use of AI   \ntechnologies.  10. Human Interaction: AI can        |  systems.  10. Human Interaction: AI can enhance   \nenhance human interaction by providing virtual      |  human interaction by providing virtual assistants,\nassistants, improving communication, and creating   |  improving communication, and enabling remote      \nimmersive experiences. However, it also raises      |  collaboration. However, it also raises concerns   \nconcerns about the impact on human relationships    |  about the quality and authenticity of human       \nand social interactions.  In summary, the           |  connections.  In summary, the implications of     \nimplications of Artificial Intelligence are vast    |  Artificial Intelligence are vast and multifaceted,\nand multifaceted, impacting various aspects of      |  impacting various aspects of society, technology, \nsociety, technology, and the world at large. It is  |  and the world at large. It is essential to address\nessential to address these implications and         |  these implications proactively to ensure the      \ndevelop responsible and ethical AI technologies to  |  responsible and beneficial development and        \nensure a positive and beneficial future for all.    |  deployment of AI technologies.                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:21:57.635540Z",
          "iopub.execute_input": "2024-11-23T12:21:57.635907Z",
          "iopub.status.idle": "2024-11-23T12:24:20.542836Z",
          "shell.execute_reply.started": "2024-11-23T12:21:57.635872Z",
          "shell.execute_reply": "2024-11-23T12:24:20.541932Z"
        },
        "outputId": "d7d7d8cc-5742-47dd-f05f-b833133f38bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Name 3     |  completes the request.  ### Instruction: Name 3   \nelements that are characteristics of a well-        |  elements that are characteristics of a well-      \nstructured essay.  ### Input:   ### Response: 1.    |  structured essay.  ### Input:   ### Response: 1.  \nClear and Concise Introduction: A well-structured   |  Clear and Concise Introduction: A well-structured \nessay should have a clear and concise introduction  |  essay should have a clear and concise introduction\nthat introduces the topic and provides a brief      |  that introduces the topic and provides a brief    \noverview of the main points that will be discussed  |  overview of the main points that will be discussed\nin the body of the essay. This helps the reader     |  in the body of the essay. This introduction should\nunderstand the purpose and scope of the essay.  2.  |  be engaging and provide a clear sense of direction\nLogical and Organized Body: The body of the essay   |  for the reader.  2. Logical and Organized Body:   \nshould be logically organized and structured in a   |  The body of the essay should be organized         \nway that makes it easy for the reader to follow     |  logically and coherently, with each paragraph     \nthe flow of ideas. This includes using topic        |  building upon the previous one. Each paragraph    \nsentences to introduce each main point, providing   |  should focus on a single main point or idea, and  \nevidence and examples to support the points, and    |  the ideas should be presented in a logical order  \nusing transitions to connect ideas and create a     |  that flows smoothly from one to the next.  嗞嗞嗞嗞嗞嗞嗞\nsmooth flow of thought.  棒球比赛的规则是什么？                |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞\n                                                    |  嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞嗞     \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:20:40.647420Z",
          "iopub.execute_input": "2024-11-23T12:20:40.648068Z",
          "iopub.status.idle": "2024-11-23T12:21:09.871596Z",
          "shell.execute_reply.started": "2024-11-23T12:20:40.648019Z",
          "shell.execute_reply": "2024-11-23T12:21:09.870673Z"
        },
        "outputId": "b3bde578-4466-4026-a154-3841ea4f29df"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe personality traits of an introvert  ### Input:  |  the personality traits of an introvert  ### Input:\n### Response: An introvert is someone who prefers   |  ### Response: An introvert is someone who prefers \nto spend time alone or with a small group of close  |  to spend time alone or with a small group of close\nfriends. They often find social situations          |  friends. They often find social situations        \noverwhelming and prefer to retreat to their own     |  overwhelming and prefer to retreat to their own   \nspace to recharge. Introverts tend to be more       |  space to recharge. Introverts tend to be more     \nreflective and introspective, often finding solace  |  reflective and introspective, often finding solace\nin their own thoughts and ideas. They may be more   |  in their own thoughts and ideas. They may be more \nreserved in social settings and may struggle with   |  reserved in social settings and may struggle with \nexpressing their emotions openly. However,          |  expressing their emotions openly. However,        \nintroverts can be highly creative and often have a  |  introverts can be highly creative and often have a\ndeep appreciation for the beauty of nature and the  |  deep understanding of their own inner world. They \nquiet moments of solitude. They may also be more    |  may also be more empathetic and attuned to the    \nempathetic and attuned to the needs of others, as   |  needs of others, as they have a greater capacity  \nthey have a greater understanding of their own      |  for self-reflection and introspection.            \nemotional needs. Overall, introverts are            |                                                    \nindividuals who value their own space and time to   |                                                    \nrecharge, and who may find social situations        |                                                    \nchallenging but can be highly creative and          |                                                    \nempathetic.                                         |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:19:29.328392Z",
          "iopub.execute_input": "2024-11-23T12:19:29.328746Z",
          "iopub.status.idle": "2024-11-23T12:20:03.272642Z",
          "shell.execute_reply.started": "2024-11-23T12:19:29.328708Z",
          "shell.execute_reply": "2024-11-23T12:20:03.271609Z"
        },
        "outputId": "5c3d503c-a1bf-46d5-fc16-c80089a67856"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Compose a  |  completes the request.  ### Instruction: Compose a\npoem about a single color.  ### Input:   ###        |  poem about a single color.  ### Input:   ###      \nResponse: The poem about the color red, a fiery     |  Response: The poem about the color red, a fiery   \nhue,  A symbol of passion, a color so true.  It's   |  hue that ignites the senses, a color that evokes  \nthe color of blood, the color of fire,  A color     |  passion and intensity. Red, the color of blood and\nthat's bold, a color that's rare.  Red is the       |  fire, a color that commands attention and leaves  \ncolor of love, a color so deep,  A color that's     |  an indelible mark. Red, the color of love and     \nstrong, a color that's sweet.  It's the color of    |  desire, a color that stirs the soul and ignites   \ndanger, a color so bright,  A color that's fierce,  |  the heart. Red, the color of strength and power, a\na color that's right.  Red is the color of hope, a  |  color that inspires and empowers. Red, the color  \ncolor so pure,  A color that's bright, a color      |  of life and vitality, a color that brings joy and \nthat's true.  It's the color of life, a color so    |  happiness. Red, the color that speaks to the      \nbright,  A color that's bold, a color that's        |  depths of the human spirit, a color that          \nright.  Red is the color of fire, a color so        |  transcends time and space. Red, the color that is \nbright,  A color that's bold, a color that's        |  both beautiful and powerful, a color that leaves  \nright.                                              |  an indelible mark on the world.                   \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T12:24:20.544493Z",
          "iopub.execute_input": "2024-11-23T12:24:20.545174Z",
          "iopub.status.idle": "2024-11-23T12:25:40.069131Z",
          "shell.execute_reply.started": "2024-11-23T12:24:20.545130Z",
          "shell.execute_reply": "2024-11-23T12:25:40.068219Z"
        },
        "outputId": "98ac1fd3-c3ab-4ab5-d624-18bf7164f117"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na rap verse about the given topic.  ### Input:      |  a rap verse about the given topic.  ### Input:    \nTopic: The importance of learning  ### Response:    |  Topic: The importance of learning  ### Response:  \nVerse:  Yo, listen up, I got something to say       |  Verse:  Yo, listen up, I got something to say     \nAbout the importance of learning, it's a must It's  |  About the importance of learning, it's a must It's\nnot just about getting good grades It's about       |  not just about getting good grades It's about     \ngrowing, it's about expanding your horizons         |  growing, it's about expanding your horizons       \nLearning is like a treasure chest Filled with       |  Learning is like a treasure chest Filled with     \nknowledge, it's a priceless gift It's not just for  |  knowledge, it's a priceless gift It's not just for\nthe smart ones It's for everyone, it's for all      |  the smart ones It's for everyone, it's for all    \nIt's not just about school, it's about life It's    |  It's not just about school, it's about life It's  \nabout understanding, it's about being wise It's     |  about understanding, it's about being wise It's   \nabout making connections, it's about growing It's   |  about making connections, it's about growing It's \nabout being open-minded, it's about being free  So  |  about being open-minded, it's about being free  So\nlearn, learn, learn, it's a must It's not just for  |  learn, learn, learn, it's a must It's not just for\nthe future, it's for the present It's not just for  |  the future, it's for the present It's not just for\nthe big things, it's for the small things It's for  |  the big things, it's for the small things It's for\neverything, it's for everything  So listen up,      |  everything, it's for everything  So listen up,    \nit's time to learn It's time to grow, it's time to  |  it's time to learn It's time to grow, it's time to\nexpand It's time to be open-minded, it's time to    |  expand It's time to be open-minded, it's time to  \nbe wise It's time to make connections, it's time    |  be wise It's time to learn, it's time to learn,   \nto be free.  ### Instruction: Write a Python        |  it's time to learn.                               \nfunction that takes a list of integers and returns  |                                                    \nthe sum of all the even numbers in the list.  ###   |                                                    \nInput:  ### Response: Here's a Python function      |                                                    \nthat takes a list of integers and returns the sum   |                                                    \nof all the even numbers in the list:  ```python     |                                                    \ndef sum_even_numbers(numbers):     return sum(num   |                                                    \nfor num in numbers if num % 2 == 0) ```  This       |                                                    \nfunction uses a generator expression to filter out  |                                                    \nthe even numbers from the input list, and then      |                                                    \nuses the built-in `sum()` function to add up all    |                                                    \nthe even numbers. The function returns the sum of   |                                                    \nthe even numbers.  ### Instruction: Write a Python  |                                                    \nfunction that takes a list of integers and returns  |                                                    \nthe sum of all the even numbers in the list.  ###   |                                                    \nInput:  ### Response: Here's a Python function      |                                                    \nthat takes a list of integers and returns the sum   |                                                    \nof all the even numbers in the list:  ```python     |                                                    \ndef sum_even_numbers(numbers):     return sum(num   |                                                    \nfor num in numbers if num % 2 == 0) ```  This       |                                                    \nfunction uses a generator expression to filter out  |                                                    \nthe even numbers from the input list, and then      |                                                    \nuses the built-in `sum()` function to add up all    |                                                    \nthe even numbers. The function returns the sum of   |                                                    \nthe even numbers.  ### Instruction: Write a Python  |                                                    \nfunction that takes a list of integers and returns  |                                                    \nthe sum of all the even numbers in the list.  ###   |                                                    \nInput:  ### Response: Here's a Python function      |                                                    \nthat takes a list of integers and returns the sum   |                                                    \nof all the even numbers in the list:  ```python     |                                                    \ndef sum_even_numbers(numbers):     return sum(num   |                                                    \nfor num in numbers if num % 2 == 0) ```  This       |                                                    \nfunction uses a generator expression to filter out  |                                                    \nthe even numbers from the input list, and then      |                                                    \nuses the built-in `sum()` function to add up all    |                                                    \nthe even numbers. The function returns the sum of   |                                                    \nthe even numbers.                                   |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}