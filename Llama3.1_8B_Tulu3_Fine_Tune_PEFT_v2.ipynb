{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Llama3.1_8B_Tulu3_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:03.985259Z",
          "iopub.execute_input": "2024-11-26T11:41:03.985666Z",
          "iopub.status.idle": "2024-11-26T11:41:36.677074Z",
          "shell.execute_reply.started": "2024-11-26T11:41:03.985629Z",
          "shell.execute_reply": "2024-11-26T11:41:36.675826Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:36.678877Z",
          "iopub.execute_input": "2024-11-26T11:41:36.679175Z",
          "iopub.status.idle": "2024-11-26T11:41:43.710309Z",
          "shell.execute_reply.started": "2024-11-26T11:41:36.679148Z",
          "shell.execute_reply": "2024-11-26T11:41:43.709339Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:43.711694Z",
          "iopub.execute_input": "2024-11-26T11:41:43.712163Z",
          "iopub.status.idle": "2024-11-26T11:41:43.719880Z",
          "shell.execute_reply.started": "2024-11-26T11:41:43.712119Z",
          "shell.execute_reply": "2024-11-26T11:41:43.718810Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'unsloth/Llama-3.1-Tulu-3-8B'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:43.721657Z",
          "iopub.execute_input": "2024-11-26T11:41:43.721907Z",
          "iopub.status.idle": "2024-11-26T11:41:43.732298Z",
          "shell.execute_reply.started": "2024-11-26T11:41:43.721882Z",
          "shell.execute_reply": "2024-11-26T11:41:43.731470Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:43.733228Z",
          "iopub.execute_input": "2024-11-26T11:41:43.733476Z",
          "iopub.status.idle": "2024-11-26T11:41:43.741788Z",
          "shell.execute_reply.started": "2024-11-26T11:41:43.733453Z",
          "shell.execute_reply": "2024-11-26T11:41:43.741106Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:41:43.742807Z",
          "iopub.execute_input": "2024-11-26T11:41:43.743151Z",
          "iopub.status.idle": "2024-11-26T11:42:02.736793Z",
          "shell.execute_reply.started": "2024-11-26T11:41:43.743114Z",
          "shell.execute_reply": "2024-11-26T11:42:02.735867Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:02.738220Z",
          "iopub.execute_input": "2024-11-26T11:42:02.738936Z",
          "iopub.status.idle": "2024-11-26T11:42:02.746327Z",
          "shell.execute_reply.started": "2024-11-26T11:42:02.738892Z",
          "shell.execute_reply": "2024-11-26T11:42:02.745413Z"
        },
        "outputId": "2c10b528-da42-4072-b5d5-77168c2c01d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540665856\nTrainable parameters : 1051004928\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:02.747464Z",
          "iopub.execute_input": "2024-11-26T11:42:02.747784Z",
          "iopub.status.idle": "2024-11-26T11:42:03.926321Z",
          "shell.execute_reply.started": "2024-11-26T11:42:02.747758Z",
          "shell.execute_reply": "2024-11-26T11:42:03.925347Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:03.927704Z",
          "iopub.execute_input": "2024-11-26T11:42:03.928079Z",
          "iopub.status.idle": "2024-11-26T11:42:03.932524Z",
          "shell.execute_reply.started": "2024-11-26T11:42:03.928041Z",
          "shell.execute_reply": "2024-11-26T11:42:03.931694Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:03.936121Z",
          "iopub.execute_input": "2024-11-26T11:42:03.936630Z",
          "iopub.status.idle": "2024-11-26T11:42:03.945280Z",
          "shell.execute_reply.started": "2024-11-26T11:42:03.936601Z",
          "shell.execute_reply": "2024-11-26T11:42:03.944568Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:03.946412Z",
          "iopub.execute_input": "2024-11-26T11:42:03.946687Z",
          "iopub.status.idle": "2024-11-26T11:42:07.230528Z",
          "shell.execute_reply.started": "2024-11-26T11:42:03.946663Z",
          "shell.execute_reply": "2024-11-26T11:42:07.229725Z"
        },
        "outputId": "6eecf9c4-0108-4eee-8f10-ee2f54964d50"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.231535Z",
          "iopub.execute_input": "2024-11-26T11:42:07.231796Z",
          "iopub.status.idle": "2024-11-26T11:42:07.237873Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.231766Z",
          "shell.execute_reply": "2024-11-26T11:42:07.237220Z"
        },
        "id": "nGwcQmo5Xv4Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.238959Z",
          "iopub.execute_input": "2024-11-26T11:42:07.239294Z",
          "iopub.status.idle": "2024-11-26T11:42:07.262089Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.239255Z",
          "shell.execute_reply": "2024-11-26T11:42:07.261381Z"
        },
        "outputId": "8c4db5ed-59ff-4bfd-a11e-fabc9cd64e42"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.263179Z",
          "iopub.execute_input": "2024-11-26T11:42:07.263938Z",
          "iopub.status.idle": "2024-11-26T11:42:07.269570Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.263899Z",
          "shell.execute_reply": "2024-11-26T11:42:07.268741Z"
        },
        "outputId": "cdff9f9d-40d6-4037-a9cd-bcd6c7307241"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.270329Z",
          "iopub.execute_input": "2024-11-26T11:42:07.270591Z",
          "iopub.status.idle": "2024-11-26T11:42:07.281037Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.270568Z",
          "shell.execute_reply": "2024-11-26T11:42:07.280102Z"
        },
        "outputId": "85dc3a90-35fd-43f4-952a-bb93359defdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.282078Z",
          "iopub.execute_input": "2024-11-26T11:42:07.282816Z",
          "iopub.status.idle": "2024-11-26T11:42:07.292279Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.282776Z",
          "shell.execute_reply": "2024-11-26T11:42:07.291440Z"
        },
        "id": "-JBkGC1-Xv4R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.293226Z",
          "iopub.execute_input": "2024-11-26T11:42:07.293497Z",
          "iopub.status.idle": "2024-11-26T11:42:07.305727Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.293474Z",
          "shell.execute_reply": "2024-11-26T11:42:07.305001Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.306810Z",
          "iopub.execute_input": "2024-11-26T11:42:07.307058Z",
          "iopub.status.idle": "2024-11-26T11:42:07.319913Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.307035Z",
          "shell.execute_reply": "2024-11-26T11:42:07.319105Z"
        },
        "outputId": "849cd06a-d26d-477a-ce99-be9198df1424"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.320903Z",
          "iopub.execute_input": "2024-11-26T11:42:07.321123Z",
          "iopub.status.idle": "2024-11-26T11:42:07.382214Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.321101Z",
          "shell.execute_reply": "2024-11-26T11:42:07.381284Z"
        },
        "outputId": "3c528b90-4119-4c79-f585-a73f760d2fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.383300Z",
          "iopub.execute_input": "2024-11-26T11:42:07.383699Z",
          "iopub.status.idle": "2024-11-26T11:42:07.393416Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.383652Z",
          "shell.execute_reply": "2024-11-26T11:42:07.392706Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.394222Z",
          "iopub.execute_input": "2024-11-26T11:42:07.394479Z",
          "iopub.status.idle": "2024-11-26T11:42:07.578132Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.394451Z",
          "shell.execute_reply": "2024-11-26T11:42:07.577195Z"
        },
        "outputId": "1cf15a7e-fa71-4095-e5f9-fe7973de47fe"
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.579329Z",
          "iopub.execute_input": "2024-11-26T11:42:07.579723Z",
          "iopub.status.idle": "2024-11-26T11:42:07.609967Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.579683Z",
          "shell.execute_reply": "2024-11-26T11:42:07.609081Z"
        },
        "outputId": "545334fa-4bd3-4227-9101-00413e001e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.611150Z",
          "iopub.execute_input": "2024-11-26T11:42:07.611605Z",
          "iopub.status.idle": "2024-11-26T11:42:07.625227Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.611565Z",
          "shell.execute_reply": "2024-11-26T11:42:07.624432Z"
        },
        "outputId": "c58672d9-a1a2-43d2-9232-b767a7957781"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.626605Z",
          "iopub.execute_input": "2024-11-26T11:42:07.627178Z",
          "iopub.status.idle": "2024-11-26T11:42:07.633359Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.627136Z",
          "shell.execute_reply": "2024-11-26T11:42:07.632449Z"
        },
        "outputId": "46010f61-0bb0-4872-868e-478a8f4aa362"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.634505Z",
          "iopub.execute_input": "2024-11-26T11:42:07.634777Z",
          "iopub.status.idle": "2024-11-26T11:42:07.660958Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.634748Z",
          "shell.execute_reply": "2024-11-26T11:42:07.660127Z"
        },
        "outputId": "e4594d0b-e8ea-4d4a-8889-8f0b15018231"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [128256, 128256, 128256, 128256, 128256, 12825...   \n1  [128256, 128256, 128256, 128256, 128256, 12825...   \n2  [128256, 128256, 128256, 128256, 128256, 12825...   \n3  [128256, 128256, 128256, 128256, 128256, 12825...   \n4  [128256, 128256, 128256, 128256, 128256, 12825...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.661972Z",
          "iopub.execute_input": "2024-11-26T11:42:07.662296Z",
          "iopub.status.idle": "2024-11-26T11:42:07.667772Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.662258Z",
          "shell.execute_reply": "2024-11-26T11:42:07.666920Z"
        },
        "outputId": "9e3b840d-649a-4e0b-9e2a-0c4a46fe340b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and Iâ€”\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.668802Z",
          "iopub.execute_input": "2024-11-26T11:42:07.669046Z",
          "iopub.status.idle": "2024-11-26T11:42:07.687278Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.669024Z",
          "shell.execute_reply": "2024-11-26T11:42:07.686539Z"
        },
        "outputId": "85a9f7d3-688f-419e-eeea-6861afe78a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 11, 35526, 449, 459, 1988, 430, 5825, 4726, 2317, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 2127, 56956, 279, 2728, 33894, 323, 10765, 1202, 1925, 7057, 382, 14711, 5688, 512, 11874, 19795, 37441, 3640, 304, 264, 14071, 7732, 27362, 77, 3112, 14931, 358, 1436, 539, 5944, 2225, 1734, 3112, 387, 832, 63865, 11, 1317, 358, 14980, 1734, 3112, 7111, 1523, 832, 439, 3117, 439, 358, 1436, 1734, 1271, 1405, 433, 30280, 304, 279, 1234, 74189, 18364, 77, 1734, 12487, 3952, 279, 1023, 11, 439, 1120, 439, 6762, 27362, 77, 3112, 3515, 8530, 279, 2731, 3802, 27362, 77, 18433, 433, 574, 16763, 88, 323, 4934, 10051, 18364, 77, 27831, 439, 369, 430, 279, 12579, 1070, 1734, 56568, 24634, 1124, 2216, 922, 279, 1890, 27362, 89330, 19795, 430, 6693, 18813, 11203, 1734, 644, 11141, 912, 3094, 1047, 8348, 11025, 3776, 7255, 77, 12174, 11, 358, 2163, 279, 1176, 369, 2500, 1938, 15114, 77, 29174, 14392, 1268, 1648, 11767, 389, 311, 1648, 27362, 77, 40, 93762, 422, 358, 1288, 3596, 2586, 1203, 7255, 77, 1734, 40, 4985, 387, 11890, 420, 449, 264, 31238, 1734, 50982, 61752, 17051, 323, 17051, 16472, 7338, 77, 11874, 19795, 37441, 3640, 304, 264, 7732, 11, 323, 358, 2345, 59, 77, 40, 3952, 279, 832, 2753, 31796, 555, 27362, 77, 3112, 430, 706, 1903, 682, 279, 6811, 382, 14711, 6075, 512, 791, 1925, 7057, 315, 279, 33894, 374, 279, 12939, 315, 3339, 11709, 323, 279, 5536, 315, 1884, 11709, 389, 832, 596, 2324, 13, 578, 19114, 374, 17011, 449, 264, 5597, 1990, 1403, 13006, 323, 13967, 41011, 279, 832, 2753, 31796, 11, 902, 13967, 21483, 872, 2324, 3217, 13, 128001]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.693293Z",
          "iopub.execute_input": "2024-11-26T11:42:07.693623Z",
          "iopub.status.idle": "2024-11-26T11:42:07.699634Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.693598Z",
          "shell.execute_reply": "2024-11-26T11:42:07.698769Z"
        },
        "outputId": "6c3f4528-37ce-4aad-cd36-57c47e7485da"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.700528Z",
          "iopub.execute_input": "2024-11-26T11:42:07.700915Z",
          "iopub.status.idle": "2024-11-26T11:42:07.710278Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.700834Z",
          "shell.execute_reply": "2024-11-26T11:42:07.709557Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.711181Z",
          "iopub.execute_input": "2024-11-26T11:42:07.711452Z",
          "iopub.status.idle": "2024-11-26T11:42:07.722178Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.711419Z",
          "shell.execute_reply": "2024-11-26T11:42:07.721456Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.723272Z",
          "iopub.execute_input": "2024-11-26T11:42:07.723705Z",
          "iopub.status.idle": "2024-11-26T11:42:07.733075Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.723667Z",
          "shell.execute_reply": "2024-11-26T11:42:07.732307Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 32\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.733932Z",
          "iopub.execute_input": "2024-11-26T11:42:07.734196Z",
          "iopub.status.idle": "2024-11-26T11:42:07.744110Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.734172Z",
          "shell.execute_reply": "2024-11-26T11:42:07.743351Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:07.745052Z",
          "iopub.execute_input": "2024-11-26T11:42:07.745300Z",
          "iopub.status.idle": "2024-11-26T11:42:08.861977Z",
          "shell.execute_reply.started": "2024-11-26T11:42:07.745277Z",
          "shell.execute_reply": "2024-11-26T11:42:08.860982Z"
        },
        "outputId": "03ef9882-2b61-4fa7-bd9a-6f9507e20683"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 83,886,080 || all params: 8,114,212,864 || trainable%: 1.0338\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:08.863116Z",
          "iopub.execute_input": "2024-11-26T11:42:08.863458Z",
          "iopub.status.idle": "2024-11-26T11:42:08.880981Z",
          "shell.execute_reply.started": "2024-11-26T11:42:08.863430Z",
          "shell.execute_reply": "2024-11-26T11:42:08.880152Z"
        },
        "outputId": "230de83d-95ec-4fa6-fd32-55a5b00ad0f5"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128264, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128264, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:08.881989Z",
          "iopub.execute_input": "2024-11-26T11:42:08.882229Z",
          "iopub.status.idle": "2024-11-26T11:42:08.906309Z",
          "shell.execute_reply.started": "2024-11-26T11:42:08.882205Z",
          "shell.execute_reply": "2024-11-26T11:42:08.905456Z"
        },
        "outputId": "dfc6e447-d2f2-458a-e154-ea1a90ab5eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4624551936\nTrainable parameters : 83886080\nTrainable percentage: 1.81%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:08.907491Z",
          "iopub.execute_input": "2024-11-26T11:42:08.907845Z",
          "iopub.status.idle": "2024-11-26T11:42:08.918555Z",
          "shell.execute_reply.started": "2024-11-26T11:42:08.907809Z",
          "shell.execute_reply": "2024-11-26T11:42:08.917840Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 1\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 2,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 2,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:08.919539Z",
          "iopub.execute_input": "2024-11-26T11:42:08.919829Z",
          "iopub.status.idle": "2024-11-26T11:42:08.964183Z",
          "shell.execute_reply.started": "2024-11-26T11:42:08.919800Z",
          "shell.execute_reply": "2024-11-26T11:42:08.963276Z"
        },
        "outputId": "939a140b-8506-4d90-dc13-9c635a4a2552"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=2,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov26_11-42-08_037309217ce8,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=2,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:08.965213Z",
          "iopub.execute_input": "2024-11-26T11:42:08.965506Z",
          "iopub.status.idle": "2024-11-26T11:42:10.713565Z",
          "shell.execute_reply.started": "2024-11-26T11:42:08.965476Z",
          "shell.execute_reply": "2024-11-26T11:42:10.712803Z"
        },
        "outputId": "fade9f8b-6770-4ccd-d362-645210cb36fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7ce6fc4cffa0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T11:42:10.714717Z",
          "iopub.execute_input": "2024-11-26T11:42:10.715029Z",
          "iopub.status.idle": "2024-11-26T12:35:56.405262Z",
          "shell.execute_reply.started": "2024-11-26T11:42:10.715000Z",
          "shell.execute_reply": "2024-11-26T12:35:56.404353Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:35:56.406546Z",
          "iopub.execute_input": "2024-11-26T12:35:56.407446Z",
          "iopub.status.idle": "2024-11-26T12:39:37.014068Z",
          "shell.execute_reply.started": "2024-11-26T12:35:56.407383Z",
          "shell.execute_reply": "2024-11-26T12:39:37.013167Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:37.015299Z",
          "iopub.execute_input": "2024-11-26T12:39:37.015684Z",
          "iopub.status.idle": "2024-11-26T12:39:39.333503Z",
          "shell.execute_reply.started": "2024-11-26T12:39:37.015644Z",
          "shell.execute_reply": "2024-11-26T12:39:39.332554Z"
        },
        "outputId": "4bac6f4e-7026-4daa-f607-c19088f9e4cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Tulu-3-8B/snapshots/d5a3345981f43f463518004225209ddf3427c43f/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"allenai/Llama-3.1-Tulu-3-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 128264\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Tulu-3-8B/snapshots/d5a3345981f43f463518004225209ddf3427c43f/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"allenai/Llama-3.1-Tulu-3-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 128264\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:39.334723Z",
          "iopub.execute_input": "2024-11-26T12:39:39.335009Z",
          "iopub.status.idle": "2024-11-26T12:39:39.468323Z",
          "shell.execute_reply.started": "2024-11-26T12:39:39.334984Z",
          "shell.execute_reply": "2024-11-26T12:39:39.466984Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:39.469595Z",
          "iopub.execute_input": "2024-11-26T12:39:39.470197Z",
          "iopub.status.idle": "2024-11-26T12:39:39.487362Z",
          "shell.execute_reply.started": "2024-11-26T12:39:39.470139Z",
          "shell.execute_reply": "2024-11-26T12:39:39.486543Z"
        },
        "id": "vVWxD2WaXv4Y",
        "outputId": "64c946ac-d0f4-4335-a42b-8416595bc794"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:39.488445Z",
          "iopub.execute_input": "2024-11-26T12:39:39.488701Z",
          "iopub.status.idle": "2024-11-26T12:39:40.975196Z",
          "shell.execute_reply.started": "2024-11-26T12:39:39.488676Z",
          "shell.execute_reply": "2024-11-26T12:39:40.974529Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "Rl7Bu30rXv4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:40.976293Z",
          "iopub.execute_input": "2024-11-26T12:39:40.976671Z",
          "iopub.status.idle": "2024-11-26T12:39:59.332818Z",
          "shell.execute_reply.started": "2024-11-26T12:39:40.976629Z",
          "shell.execute_reply": "2024-11-26T12:39:59.332094Z"
        },
        "id": "Cv5MWMvlXv4Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.333833Z",
          "iopub.execute_input": "2024-11-26T12:39:59.334143Z",
          "iopub.status.idle": "2024-11-26T12:39:59.343799Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.334115Z",
          "shell.execute_reply": "2024-11-26T12:39:59.343100Z"
        },
        "id": "bPF3NQatXv4Z",
        "outputId": "853eafea-9936-476a-c2f0-4d98323b774c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540665856\nTrainable parameters : 1051004928\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.344958Z",
          "iopub.execute_input": "2024-11-26T12:39:59.345659Z",
          "iopub.status.idle": "2024-11-26T12:39:59.369668Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.345619Z",
          "shell.execute_reply": "2024-11-26T12:39:59.368775Z"
        },
        "id": "TGGg1uSIXv4Z",
        "outputId": "15ea52fb-dc6b-4210-e638-5955db423918"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128264, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128264, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.370718Z",
          "iopub.execute_input": "2024-11-26T12:39:59.370997Z",
          "iopub.status.idle": "2024-11-26T12:39:59.397102Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.370971Z",
          "shell.execute_reply": "2024-11-26T12:39:59.396264Z"
        },
        "id": "6T9qP2gAXv4Z",
        "outputId": "a982f594-f4af-48f5-b21f-5fe70764aaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4708438016\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.397954Z",
          "iopub.execute_input": "2024-11-26T12:39:59.398211Z",
          "iopub.status.idle": "2024-11-26T12:39:59.408964Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.398186Z",
          "shell.execute_reply": "2024-11-26T12:39:59.408224Z"
        },
        "id": "f5gxJMVgXv4Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.409816Z",
          "iopub.execute_input": "2024-11-26T12:39:59.410025Z",
          "iopub.status.idle": "2024-11-26T12:39:59.422435Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.410004Z",
          "shell.execute_reply": "2024-11-26T12:39:59.421777Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:39:59.423144Z",
          "iopub.execute_input": "2024-11-26T12:39:59.423469Z",
          "iopub.status.idle": "2024-11-26T12:39:59.436158Z",
          "shell.execute_reply.started": "2024-11-26T12:39:59.423434Z",
          "shell.execute_reply": "2024-11-26T12:39:59.435329Z"
        },
        "id": "nuDl9DG_Xv4Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:47:39.159041Z",
          "iopub.execute_input": "2024-11-26T12:47:39.159887Z",
          "iopub.status.idle": "2024-11-26T12:48:08.332432Z",
          "shell.execute_reply.started": "2024-11-26T12:47:39.159850Z",
          "shell.execute_reply": "2024-11-26T12:48:08.331639Z"
        },
        "outputId": "d372e066-851e-4874-eac9-0e7975cc5553"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Compose a  |  completes the request.  ### Instruction: Compose a\npoem about a single color.  ### Input:   ###        |  poem about a single color.  ### Input:   ###      \nResponse: Red is the color of passion,  The fire    |  Response: Red is the color of passion,  The fire  \nin our hearts, It's the color of love's embrace,    |  in our hearts, It's the color of love's embrace,  \nAnd the warmth of the sun's rays.  Red is the       |  And the warmth of the sun's rays.  Red is the     \ncolor of courage, The bravery we all share, It's    |  color of courage, The bravery we all share, It's  \nthe color of life's blood, And the roses we hold    |  the color of life's blood, And the roses we hold  \ndear.  Red is the color of danger, A warning sign,  |  dear.  Red is the color of danger, A warning sign,\nloud and clear, It's the color of stop signs, And   |  loud and clear, It's the color of stop signs, And \nthe flames that we fear.  But red can also be       |  the flames that we fear.  But red can also be     \ngentle, A soft, calming, soothing hue, It's the     |  gentle, Like the softest rose petal, It's the     \ncolor of a sunset, And the sky at the break of      |  color of a sunset, And the wine that we savor.    \ndew.  Red is a powerful color, With many meanings   |  Red is a powerful hue, With a message it conveys, \nand moods, It's the color that speaks volumes, In   |  It's the color that speaks to us, In so many      \nthe world of colors, it's true.                     |  different ways.                                   \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:48:25.414360Z",
          "iopub.execute_input": "2024-11-26T12:48:25.414708Z",
          "iopub.status.idle": "2024-11-26T12:50:03.719478Z",
          "shell.execute_reply.started": "2024-11-26T12:48:25.414679Z",
          "shell.execute_reply": "2024-11-26T12:50:03.718603Z"
        },
        "outputId": "5e432031-5d62-4eef-d8ff-2b63a50a0d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na possible future for humankind if artificial       |  a possible future for humankind if artificial     \nintelligence (AI) becomes more advanced and         |  intelligence (AI) becomes more advanced and       \nprevalent.  ### Input:   ### Response: In the       |  prevalent.  ### Input:   ### Response: In the     \nfuture, AI will be so advanced and prevalent that   |  future, AI will be so advanced and prevalent that \nit will become an integral part of our daily        |  it will become an integral part of our daily      \nlives, economy, and society. Here's a possible      |  lives, economy, and society. Here's a possible    \nfuture scenario:  **Technological Integration:**    |  future scenario:  **Technological Integration:**  \nAI will be seamlessly integrated into every aspect  |  AI will be seamlessly integrated into every aspect\nof our lives, from personal assistants and home     |  of our lives, from personal assistants and home   \nautomation to complex industrial processes. Smart   |  automation to complex industrial processes. Smart \ndevices will be capable of learning our habits and  |  devices will be capable of learning our habits and\npreferences, adapting to our needs without          |  preferences, adapting to our needs without        \nexplicit commands.  **Economic Shift:** The global  |  explicit commands.  **Economic Shift:** The global\neconomy will undergo a significant transformation.  |  economy will undergo significant shifts. AI-driven\nAI-driven automation will lead to a reduction in    |  automation will lead to a reduction in many manual\nthe need for human labor in many sectors,           |  labor jobs, necessitating a re-skilling of the    \npotentially leading to a universal basic income     |  workforce towards higher-level cognitive tasks.   \nsystem to ensure that everyone is provided for. AI  |  New industries will emerge, focusing on AI        \nwill also revolutionize industries like             |  development, maintenance, and ethical             \nhealthcare, finance, and manufacturing, making      |  considerations.  **Societal Changes:** Society    \nthem more efficient and accessible.  **Societal     |  will adapt to the new realities brought about by  \nChanges:** Society will evolve as AI becomes a      |  AI. Education systems will evolve to teach        \npartner in human endeavors. Education will be       |  critical thinking, creativity, and ethical        \npersonalized, with AI tailoring learning            |  decision-making alongside traditional academic    \nexperiences to individual students' needs and       |  subjects. AI will also play a crucial role in     \npace. AI will also play a crucial role in solving   |  healthcare, providing personalized treatment plans\ncomplex societal issues, from climate change to     |  and early disease detection.  **Ethical and       \npoverty, by providing data-driven insights and      |  Privacy Concerns:** As AI becomes more powerful,  \nsolutions.  **Ethical and Philosophical             |  there will be heightened concerns over privacy,   \nQuestions:** As AI becomes more advanced, profound  |  surveillance, and the ethical use of AI.          \nethical and philosophical questions will arise.     |  Regulations and international agreements will be  \nThe role of consciousness and the rights of         |  established to govern AI development and          \nartificial beings will be debated. The distinction  |  deployment, ensuring that technological           \nbetween human and machine will blur, prompting a    |  advancements benefit humanity rather than harm it.\nreevaluation of what it means to be \"alive\" or      |  **Global Cooperation:** The development and       \n\"sentient.\"  **Global Governance:** International   |  deployment of advanced AI will require            \ncooperation will be essential to regulate AI        |  unprecedented levels of international cooperation.\ndevelopment and deployment. A global framework      |  Countries will collaborate on AI ethics, sharing  \nwill be established to ensure that AI benefits all  |  best practices and establishing standards to      \nof humanity and does not exacerbate existing        |  prevent misuse and ensure equitable access to AI  \ninequalities.  **Human-AI Collaboration:** The      |  technologies.  **Human-AI Collaboration:** The    \nrelationship between humans and AI will be one of   |  relationship between humans and AI will evolve    \ncollaboration and symbiosis. Humans will focus on   |  into one of collaboration rather than competition.\ncreativity, emotional intelligence, and complex     |  AI will augment human capabilities, allowing us to\ndecision-making, while AI will handle the routine,  |  tackle complex problems that were previously      \ndata-intensive tasks. This partnership will lead    |  insurmountable. This symbiotic relationship will  \nto breakthroughs in science, art, and technology.   |  lead to breakthroughs in space exploration,       \n**Potential Dangers:** Despite the many benefits,   |  climate change mitigation, and scientific         \nthere will be significant challenges. The risk of   |  discovery.  **Philosophical and Existential       \nAI systems developing unintended consequences or    |  Questions:** As AI approaches human-level         \nbecoming uncontrollable will necessitate robust     |  intelligence, society will grapple with profound  \nsafety measures and ethical guidelines.             |  philosophical and existential questions about     \nCybersecurity will be a paramount concern, as AI    |  consciousness, free will, and the nature of       \nsystems become increasingly interconnected.         |  intelligence. These discussions will lead to a    \n**Conclusion:** In this future, humankind and AI    |  reevaluation of what it means to be human and our \nwill coexist in a dynamic balance, pushing the      |  place in the universe.  **AI as a Tool for Good:**\nboundaries of what is possible. The ultimate        |  Ultimately, the widespread adoption and           \noutcome will depend on how we choose to guide the   |  advancement of AI will be seen as a tool for good,\ndevelopment and deployment of AI, ensuring that it  |  provided it is managed responsibly. AI will enable\nserves the common good and enhances the human       |  us to solve many of the world's most pressing     \nexperience. The journey will be fraught with        |  problems, from poverty and inequality to          \nchallenges, but the potential for a brighter, more  |  environmental degradation and disease.  In this   \nequitable future is within reach if we navigate it  |  future, humanity will have to navigate the        \nwisely.                                             |  challenges and opportunities presented by advanced\n                                                    |  AI with wisdom, foresight, and a commitment to    \n                                                    |  ethical use. The outcome will depend on our       \n                                                    |  collective ability to harness AI's potential for  \n                                                    |  the betterment of all.                            \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:53:02.946643Z",
          "iopub.execute_input": "2024-11-26T12:53:02.947339Z",
          "iopub.status.idle": "2024-11-26T12:53:50.662882Z",
          "shell.execute_reply.started": "2024-11-26T12:53:02.947304Z",
          "shell.execute_reply": "2024-11-26T12:53:50.661930Z"
        },
        "outputId": "33f213ad-3773-4f6a-bbbe-773e81d58039"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na rap verse about the given topic.  ### Input:      |  a rap verse about the given topic.  ### Input:    \nTopic: The importance of learning  ### Response:    |  Topic: The importance of learning  ### Response:  \nYo, listen up, I'm here to school you on the        |  Yo, listen up, I'm here to school you on the      \nimportance of learning,   From the books to the     |  importance of learning,   From the books to the   \nstreets, it's the key to success, burning.          |  streets, it's the key to success, burning.        \nWithout knowledge, you're just a ghost, wandering   |  Without knowledge, you're just a ghost, wandering \naimlessly,   Every day's a test, and you're         |  aimlessly,   Every day's a test, and you're       \nfailing, see?    From the ABCs to calculus, it's a  |  failing, see?    From the ABCs to calculus, it's a\njourney worth taking,   Each lesson a step,         |  journey worth taking,   Each lesson a step,       \nbuilding the foundation, never forsaking.   The     |  towards a brighter, wiser, making.   The more you \nmore you know, the more doors open, opportunities   |  know, the more doors open,   Learning's the ladder\nknocking,   Ignorance is a prison, but education's  |  to climb, never stop, never stop.    In this      \nthe key unlocking.    In this fast-paced world,     |  world, ignorance is a trap,   But with education, \nwhere change is the only constant,   Learning's     |  you can break free, like a rap.   From history to \nthe currency, it's the investment that never        |  science, it's all connected,   Knowledge is power,\nstagnates.   From the ancient sages to the modern   |  and it's something you can invest.    So grab a   \nday geniuses,   They all agree, knowledge is        |  book, hit the library,   Surround yourself with   \npower, and wisdom is its essence.    So, grab a     |  wisdom, it's the best therapy.   The more you     \nbook, hit the lab, or take that online course,      |  learn, the more you grow,   And when you speak,   \nThe journey of learning is endless, and the         |  your words will flow.    So let's make education  \nrewards are in force.   It's not just about         |  our priority,   Pass it on to the next generation,\ngrades, it's about growing, evolving,   In this     |  it's our duty.   Because when we learn, we become,\nlife, the only thing constant is change, so let's   |  The architects of a better, brighter, future,     \nbe moving.                                          |  amen.                                             \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T12:59:16.626324Z",
          "iopub.execute_input": "2024-11-26T12:59:16.626714Z",
          "iopub.status.idle": "2024-11-26T13:00:10.094775Z",
          "shell.execute_reply.started": "2024-11-26T12:59:16.626682Z",
          "shell.execute_reply": "2024-11-26T13:00:10.093874Z"
        },
        "outputId": "6685ac38-5124-4541-f91f-6adc8fb2eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe 3 main components of a simple robotic system    |  the 3 main components of a simple robotic system  \nin a conversational manner as if you were talking   |  in a conversational manner as if you were talking \nto a friend.  ### Input:   ### Response: Okay, so   |  to a friend.  ### Input:   ### Response: Okay, so \nimagine you have a simple robotic system, right?    |  imagine you have a simple robotic system, right?  \nFirst off, there's the **sensory component**. This  |  First off, there's the **sensory component**. This\nis like the robot's eyes and ears. It's what        |  is like the robot's eyes and ears. It's what      \nallows the robot to perceive its environment. For   |  allows the robot to perceive its environment. For \nexample, a camera could be the sensory component,   |  example, a camera could be the sensory component, \ncapturing images, or a microphone could pick up     |  capturing images, or a microphone could pick up   \nsounds.  Next, we have the **processing unit**.     |  sounds.  Next, we have the **processing unit**.   \nThis is the brain of the robot. It's where all the  |  This is the brain of the robot. It's where all the\ninformation gathered by the sensory component is    |  information gathered by the sensory component is  \nanalyzed and understood. Think of it as a super-    |  analyzed and understood. Think of it as a super-  \nsmart computer that can make decisions based on     |  smart computer that can make decisions based on   \nthe data it receives. It might use algorithms to    |  what it senses. It might use algorithms to figure \nfigure out what it's seeing or hearing and then     |  out what it sees or hears and then decide what    \ndecide what action to take.  Finally, there's the   |  action to take.  Finally, there's the **actuator  \n**actuator component**. This is the robot's         |  component**. This is the robot's muscles. It's    \nmuscles. It's what allows the robot to move and     |  what allows the robot to move and interact with   \ninteract with the world. Motors are a common type   |  the world. Motors are a common type of actuator.  \nof actuator. So, once the processing unit has       |  So, after the brain (processing unit) decides what\ndecided what to do, the actuator component carries  |  to do, the muscles (actuators) carry out the      \nout the action. For instance, if the robot sees a   |  action. For instance, if the robot senses a ball  \nball, its processing unit might decide to move      |  and decides to kick it, the actuator would move   \ntowards it, and then the actuator component would   |  the leg to make contact with the ball.  So, in a  \nkick the ball.  So, in a nutshell, you've got the   |  nutshell, you've got the sensory component to see \nsensory component to perceive, the processing unit  |  and hear, the processing unit to think and decide,\nto think, and the actuator component to act.        |  and the actuator component to move and act. That's\nThat's the basic setup for a simple robotic         |  the basic setup for a simple robotic system!      \nsystem!                                             |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T13:01:04.126664Z",
          "iopub.execute_input": "2024-11-26T13:01:04.127032Z",
          "iopub.status.idle": "2024-11-26T13:01:59.554121Z",
          "shell.execute_reply.started": "2024-11-26T13:01:04.127000Z",
          "shell.execute_reply": "2024-11-26T13:01:59.553142Z"
        },
        "outputId": "a1d8d0c0-7a0f-4619-9fb7-48dee500c1af"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Write a    |  completes the request.  ### Instruction: Write a  \nbrief biography of Marie Curie  ### Input:   ###    |  brief biography of Marie Curie  ### Input:   ###  \nResponse: Marie Curie was a physicist and chemist   |  Response: Marie Curie was a physicist and chemist \nwho conducted pioneering research on                |  who conducted pioneering research on              \nradioactivity, for which she won the Nobel Prize    |  radioactivity, for which she won the Nobel Prize  \nin Physics in 1903 and the Nobel Prize in           |  in Physics in 1903 and the Nobel Prize in         \nChemistry in 1911. The two Nobel Prizes remain the  |  Chemistry in 1911. The two Nobel Prizes remain the\nonly ones ever awarded to a woman. Marie was born   |  only ones ever awarded to a woman. Marie was born \nMaria SkÅ‚odowska in Warsaw, in what was then the    |  Maria SkÅ‚odowska in Warsaw, in what was then the  \nRussian Empire, in November 1867. Her mother,       |  Russian Empire, in November 1867. Her mother,     \nBronislawa, was a teacher, and her father,          |  Bronislawa, was a teacher, and her father,        \nWladyslaw, was a physicist; both were proponents    |  Wladyslaw, was a physicist; both were proponents  \nof women's education, which was rare at the time.   |  of women's education, which was rare at the time. \nDespite the challenges of her Polish and Jewish     |  Despite the challenges of her Polish and Jewish   \nbackground and the oppressive educational and       |  background and the oppressive educational and     \npolitical climates, Marie excelled in her studies.  |  political climates, Marie excelled in her studies.\nShe moved to Paris in 1891 to attend the Sorbonne,  |  She moved to Paris in 1891 to attend the Sorbonne,\nwhere she obtained degrees in physics and           |  where she obtained degrees in physics and         \nmathematics. In 1895, she married fellow scientist  |  mathematics. In 1895, she married fellow scientist\nPierre Curie, and they worked together researching  |  Pierre Curie, and they worked together researching\nradioactivity. After Pierre's untimely death in     |  radioactivity. After Pierre's untimely death in   \n1906, Marie took his place at the Sorbonne and      |  1906, Marie took his place at the Sorbonne and    \neventually became the first woman to teach there.   |  eventually became the first woman to teach there. \nHer dedication to science, despite the societal     |  Her dedication to science, despite the societal   \nbarriers she faced as a woman and a foreigner, set  |  barriers she faced as a woman and a foreigner,    \na precedent for future generations of female        |  earned her a place among the most influential     \nscientists. Marie Curie died in 1934 of aplastic    |  scientists in history. Marie Curie died in 1934 of\nanemia, likely caused by her prolonged exposure to  |  aplastic anemia, likely caused by her prolonged   \nradiation, a tragic consequence of her              |  exposure to radiation, a tragic consequence of her\ngroundbreaking work. Her legacy endures through     |  groundbreaking work.                              \nher discoveries and the numerous institutions and   |                                                    \nawards named in her honor.                          |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}