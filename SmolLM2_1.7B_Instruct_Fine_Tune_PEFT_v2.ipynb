{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/SmolLM2_1.7B_Instruct_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:38:43.674931Z",
          "iopub.execute_input": "2024-11-24T02:38:43.675301Z",
          "iopub.status.idle": "2024-11-24T02:39:17.144982Z",
          "shell.execute_reply.started": "2024-11-24T02:38:43.675261Z",
          "shell.execute_reply": "2024-11-24T02:39:17.143792Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-24T02:39:17.146934Z",
          "iopub.execute_input": "2024-11-24T02:39:17.147787Z",
          "iopub.status.idle": "2024-11-24T02:39:24.459872Z",
          "shell.execute_reply.started": "2024-11-24T02:39:17.147742Z",
          "shell.execute_reply": "2024-11-24T02:39:24.458940Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-24T02:39:24.461205Z",
          "iopub.execute_input": "2024-11-24T02:39:24.461505Z",
          "iopub.status.idle": "2024-11-24T02:39:24.468075Z",
          "shell.execute_reply.started": "2024-11-24T02:39:24.461478Z",
          "shell.execute_reply": "2024-11-24T02:39:24.467271Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'HuggingFaceTB/SmolLM2-1.7B-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:39:24.469157Z",
          "iopub.execute_input": "2024-11-24T02:39:24.469423Z",
          "iopub.status.idle": "2024-11-24T02:39:24.477325Z",
          "shell.execute_reply.started": "2024-11-24T02:39:24.469397Z",
          "shell.execute_reply": "2024-11-24T02:39:24.476612Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:39:24.479218Z",
          "iopub.execute_input": "2024-11-24T02:39:24.479473Z",
          "iopub.status.idle": "2024-11-24T02:39:24.487952Z",
          "shell.execute_reply.started": "2024-11-24T02:39:24.479447Z",
          "shell.execute_reply": "2024-11-24T02:39:24.487360Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:39:24.488750Z",
          "iopub.execute_input": "2024-11-24T02:39:24.488969Z",
          "iopub.status.idle": "2024-11-24T02:40:51.232184Z",
          "shell.execute_reply.started": "2024-11-24T02:39:24.488946Z",
          "shell.execute_reply": "2024-11-24T02:40:51.231357Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:51.233284Z",
          "iopub.execute_input": "2024-11-24T02:40:51.233589Z",
          "iopub.status.idle": "2024-11-24T02:40:51.240341Z",
          "shell.execute_reply.started": "2024-11-24T02:40:51.233536Z",
          "shell.execute_reply": "2024-11-24T02:40:51.239505Z"
        },
        "outputId": "7902f622-b55b-4dba-c92b-a58c1e0a7854"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 906070016\nTrainable parameters : 100763648\nTrainable percentage: 11.12%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:51.241610Z",
          "iopub.execute_input": "2024-11-24T02:40:51.242211Z",
          "iopub.status.idle": "2024-11-24T02:40:52.125316Z",
          "shell.execute_reply.started": "2024-11-24T02:40:51.242171Z",
          "shell.execute_reply": "2024-11-24T02:40:52.124243Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:52.126714Z",
          "iopub.execute_input": "2024-11-24T02:40:52.127102Z",
          "iopub.status.idle": "2024-11-24T02:40:52.131679Z",
          "shell.execute_reply.started": "2024-11-24T02:40:52.127069Z",
          "shell.execute_reply": "2024-11-24T02:40:52.130377Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:52.133203Z",
          "iopub.execute_input": "2024-11-24T02:40:52.133636Z",
          "iopub.status.idle": "2024-11-24T02:40:52.144877Z",
          "shell.execute_reply.started": "2024-11-24T02:40:52.133589Z",
          "shell.execute_reply": "2024-11-24T02:40:52.143840Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:52.146381Z",
          "iopub.execute_input": "2024-11-24T02:40:52.147081Z",
          "iopub.status.idle": "2024-11-24T02:40:53.143502Z",
          "shell.execute_reply.started": "2024-11-24T02:40:52.147032Z",
          "shell.execute_reply": "2024-11-24T02:40:53.142552Z"
        },
        "outputId": "441ff88d-5cb9-44da-bf0e-208113e12d10"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.144754Z",
          "iopub.execute_input": "2024-11-24T02:40:53.145318Z",
          "iopub.status.idle": "2024-11-24T02:40:53.152279Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.145275Z",
          "shell.execute_reply": "2024-11-24T02:40:53.151377Z"
        },
        "id": "eznZQbJJvcHM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.153425Z",
          "iopub.execute_input": "2024-11-24T02:40:53.153774Z",
          "iopub.status.idle": "2024-11-24T02:40:53.180346Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.153746Z",
          "shell.execute_reply": "2024-11-24T02:40:53.179507Z"
        },
        "outputId": "55d640a3-4ec5-497f-88d7-04ac62755451"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.185653Z",
          "iopub.execute_input": "2024-11-24T02:40:53.186311Z",
          "iopub.status.idle": "2024-11-24T02:40:53.192837Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.186246Z",
          "shell.execute_reply": "2024-11-24T02:40:53.191800Z"
        },
        "outputId": "27d97886-c629-4545-dd44-a466ceb9d5f8"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.194067Z",
          "iopub.execute_input": "2024-11-24T02:40:53.194406Z",
          "iopub.status.idle": "2024-11-24T02:40:53.204893Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.194367Z",
          "shell.execute_reply": "2024-11-24T02:40:53.204054Z"
        },
        "outputId": "e647b0b7-97d6-4420-85d6-d32230645de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.205892Z",
          "iopub.execute_input": "2024-11-24T02:40:53.206128Z",
          "iopub.status.idle": "2024-11-24T02:40:53.213424Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.206103Z",
          "shell.execute_reply": "2024-11-24T02:40:53.212624Z"
        },
        "id": "uZl73pLfvcHN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.214485Z",
          "iopub.execute_input": "2024-11-24T02:40:53.214764Z",
          "iopub.status.idle": "2024-11-24T02:40:53.225262Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.214739Z",
          "shell.execute_reply": "2024-11-24T02:40:53.224454Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.226852Z",
          "iopub.execute_input": "2024-11-24T02:40:53.227235Z",
          "iopub.status.idle": "2024-11-24T02:40:53.245912Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.227191Z",
          "shell.execute_reply": "2024-11-24T02:40:53.245032Z"
        },
        "outputId": "ae7a5d01-2b09-4ce0-b85a-cdd27ee5bfae"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.247106Z",
          "iopub.execute_input": "2024-11-24T02:40:53.247460Z",
          "iopub.status.idle": "2024-11-24T02:40:53.253742Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.247420Z",
          "shell.execute_reply": "2024-11-24T02:40:53.252686Z"
        },
        "outputId": "5e98691d-991f-4af7-b8d3-a9f462207efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.254910Z",
          "iopub.execute_input": "2024-11-24T02:40:53.255216Z",
          "iopub.status.idle": "2024-11-24T02:40:53.264984Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.255181Z",
          "shell.execute_reply": "2024-11-24T02:40:53.264126Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:40:53.266137Z",
          "iopub.execute_input": "2024-11-24T02:40:53.266496Z",
          "iopub.status.idle": "2024-11-24T02:41:01.829613Z",
          "shell.execute_reply.started": "2024-11-24T02:40:53.266457Z",
          "shell.execute_reply": "2024-11-24T02:41:01.828775Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.830909Z",
          "iopub.execute_input": "2024-11-24T02:41:01.831617Z",
          "iopub.status.idle": "2024-11-24T02:41:01.837687Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.831553Z",
          "shell.execute_reply": "2024-11-24T02:41:01.836624Z"
        },
        "outputId": "67d211a4-be8a-454d-ec6a-83a797584fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.838796Z",
          "iopub.execute_input": "2024-11-24T02:41:01.839030Z",
          "iopub.status.idle": "2024-11-24T02:41:01.918941Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.839005Z",
          "shell.execute_reply": "2024-11-24T02:41:01.918014Z"
        },
        "outputId": "ac7f6ad4-0afb-4f63-8fcd-8e7cc888a0ae"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.919929Z",
          "iopub.execute_input": "2024-11-24T02:41:01.920215Z",
          "iopub.status.idle": "2024-11-24T02:41:01.928160Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.920188Z",
          "shell.execute_reply": "2024-11-24T02:41:01.927367Z"
        },
        "outputId": "e2395a23-6e85-4e56-b31c-cd5b5fcd42ef"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.929117Z",
          "iopub.execute_input": "2024-11-24T02:41:01.929698Z",
          "iopub.status.idle": "2024-11-24T02:41:01.954358Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.929668Z",
          "shell.execute_reply": "2024-11-24T02:41:01.953614Z"
        },
        "outputId": "0cc51105-447d-4c88-c9f9-1865be095356"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n1  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n2  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n3  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n4  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.955247Z",
          "iopub.execute_input": "2024-11-24T02:41:01.955463Z",
          "iopub.status.idle": "2024-11-24T02:41:01.960689Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.955441Z",
          "shell.execute_reply": "2024-11-24T02:41:01.959864Z"
        },
        "outputId": "dc6dde94-714c-4d67-f570-ae2c7c93117c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and Iâ€”\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.961744Z",
          "iopub.execute_input": "2024-11-24T02:41:01.962004Z",
          "iopub.status.idle": "2024-11-24T02:41:01.971376Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.961979Z",
          "shell.execute_reply": "2024-11-24T02:41:01.970639Z"
        },
        "outputId": "fc73d762-25d3-49ea-a21c-8acdde0cbeaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[19798, 314, 354, 5785, 338, 6601, 253, 3856, 28, 20054, 351, 354, 3007, 338, 2433, 2030, 2468, 30, 9517, 253, 2426, 338, 13674, 32873, 260, 3116, 30, 198, 198, 3757, 20880, 42, 198, 24499, 2404, 260, 1836, 8216, 284, 2669, 624, 1085, 7374, 30, 198, 198, 3757, 18100, 42, 198, 10345, 8364, 11172, 2984, 281, 253, 5724, 3180, 29323, 94, 3528, 22657, 339, 856, 441, 2827, 1062, 76, 94, 3528, 325, 582, 32779, 28, 986, 339, 9318, 76, 94, 3528, 5328, 1187, 582, 347, 1869, 347, 339, 856, 76, 94, 2068, 837, 357, 18178, 281, 260, 656, 19477, 41227, 94, 76, 94, 10039, 2637, 260, 550, 28, 347, 915, 347, 3506, 29323, 94, 3528, 1953, 4012, 260, 1365, 2766, 29323, 94, 8653, 357, 436, 42661, 284, 4146, 5777, 41227, 94, 12908, 347, 327, 338, 260, 7685, 665, 76, 94, 39855, 11742, 601, 2159, 563, 260, 1142, 29323, 94, 504, 8364, 338, 5738, 7582, 2060, 76, 94, 788, 3711, 787, 1833, 761, 5855, 5745, 2632, 23113, 94, 16912, 28, 339, 2049, 260, 808, 327, 1372, 1194, 17, 76, 94, 16075, 6040, 638, 970, 4733, 335, 288, 970, 29323, 94, 57, 4995, 1132, 585, 339, 868, 2042, 1690, 1056, 23113, 94, 76, 94, 57, 3786, 325, 8932, 451, 351, 253, 44452, 76, 94, 4449, 2942, 6399, 284, 6399, 8913, 19199, 94, 10345, 8364, 11172, 2984, 281, 253, 3180, 28, 284, 339, 1265, 76, 94, 57, 2637, 260, 582, 1181, 12581, 411, 29323, 94, 3528, 338, 553, 1135, 511, 260, 3193, 30, 198, 198, 3757, 14212, 42, 198, 504, 1085, 7374, 282, 260, 8216, 314, 260, 2979, 282, 1625, 4975, 284, 260, 1645, 282, 967, 4975, 335, 582, 506, 1029, 30, 378, 10831, 314, 5263, 351, 253, 3062, 826, 827, 9146, 284, 5354, 23046, 260, 582, 1181, 12581, 28, 527, 5354, 6146, 480, 1029, 1786, 30, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.972197Z",
          "iopub.execute_input": "2024-11-24T02:41:01.972464Z",
          "iopub.status.idle": "2024-11-24T02:41:01.981597Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.972438Z",
          "shell.execute_reply": "2024-11-24T02:41:01.980757Z"
        },
        "outputId": "db818a19-7893-4e6a-d779-b3d2ea102e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.982855Z",
          "iopub.execute_input": "2024-11-24T02:41:01.983388Z",
          "iopub.status.idle": "2024-11-24T02:41:01.991146Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.983347Z",
          "shell.execute_reply": "2024-11-24T02:41:01.990358Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:01.991963Z",
          "iopub.execute_input": "2024-11-24T02:41:01.992189Z",
          "iopub.status.idle": "2024-11-24T02:41:02.003595Z",
          "shell.execute_reply.started": "2024-11-24T02:41:01.992167Z",
          "shell.execute_reply": "2024-11-24T02:41:02.002788Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:02.004434Z",
          "iopub.execute_input": "2024-11-24T02:41:02.004673Z",
          "iopub.status.idle": "2024-11-24T02:41:02.013296Z",
          "shell.execute_reply.started": "2024-11-24T02:41:02.004650Z",
          "shell.execute_reply": "2024-11-24T02:41:02.012624Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:02.014240Z",
          "iopub.execute_input": "2024-11-24T02:41:02.014514Z",
          "iopub.status.idle": "2024-11-24T02:41:02.023532Z",
          "shell.execute_reply.started": "2024-11-24T02:41:02.014489Z",
          "shell.execute_reply": "2024-11-24T02:41:02.022837Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:02.024446Z",
          "iopub.execute_input": "2024-11-24T02:41:02.024712Z",
          "iopub.status.idle": "2024-11-24T02:41:03.016545Z",
          "shell.execute_reply.started": "2024-11-24T02:41:02.024687Z",
          "shell.execute_reply": "2024-11-24T02:41:03.015473Z"
        },
        "outputId": "a1699cfe-5fa7-4fb1-b244-30bd7474b94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 72,351,744 || all params: 1,783,728,128 || trainable%: 4.0562\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:03.017874Z",
          "iopub.execute_input": "2024-11-24T02:41:03.018242Z",
          "iopub.status.idle": "2024-11-24T02:41:03.033540Z",
          "shell.execute_reply.started": "2024-11-24T02:41:03.018201Z",
          "shell.execute_reply": "2024-11-24T02:41:03.032486Z"
        },
        "outputId": "5911df10-b05f-4601-a8b3-5de2d7a01ff5"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 2048, padding_idx=2)\n    (layers): ModuleList(\n      (0-23): 24 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:03.034874Z",
          "iopub.execute_input": "2024-11-24T02:41:03.035133Z",
          "iopub.status.idle": "2024-11-24T02:41:03.052998Z",
          "shell.execute_reply.started": "2024-11-24T02:41:03.035107Z",
          "shell.execute_reply": "2024-11-24T02:41:03.052233Z"
        },
        "outputId": "16878de3-35c2-4716-8c55-04bb5f9384f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 978421760\nTrainable parameters : 72351744\nTrainable percentage: 7.39%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:03.054167Z",
          "iopub.execute_input": "2024-11-24T02:41:03.055018Z",
          "iopub.status.idle": "2024-11-24T02:41:03.062631Z",
          "shell.execute_reply.started": "2024-11-24T02:41:03.054977Z",
          "shell.execute_reply": "2024-11-24T02:41:03.061799Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:03.063807Z",
          "iopub.execute_input": "2024-11-24T02:41:03.064070Z",
          "iopub.status.idle": "2024-11-24T02:41:03.106008Z",
          "shell.execute_reply.started": "2024-11-24T02:41:03.064045Z",
          "shell.execute_reply": "2024-11-24T02:41:03.104984Z"
        },
        "outputId": "f7cb87c3-f51c-4f88-cbee-763d572057be"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov24_02-41-03_e085d4847dbc,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:03.106988Z",
          "iopub.execute_input": "2024-11-24T02:41:03.107271Z",
          "iopub.status.idle": "2024-11-24T02:41:04.966350Z",
          "shell.execute_reply.started": "2024-11-24T02:41:03.107241Z",
          "shell.execute_reply": "2024-11-24T02:41:04.965629Z"
        },
        "outputId": "4787477b-cfba-4448-909d-5b05cd823be7"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7eb94def5cf0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T02:41:04.967330Z",
          "iopub.execute_input": "2024-11-24T02:41:04.967651Z",
          "iopub.status.idle": "2024-11-24T03:13:34.868274Z",
          "shell.execute_reply.started": "2024-11-24T02:41:04.967622Z",
          "shell.execute_reply": "2024-11-24T03:13:34.867477Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:13:34.869395Z",
          "iopub.execute_input": "2024-11-24T03:13:34.869698Z",
          "iopub.status.idle": "2024-11-24T03:14:43.748762Z",
          "shell.execute_reply.started": "2024-11-24T03:13:34.869670Z",
          "shell.execute_reply": "2024-11-24T03:14:43.747866Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:43.757444Z",
          "iopub.execute_input": "2024-11-24T03:14:43.757932Z",
          "iopub.status.idle": "2024-11-24T03:14:45.369805Z",
          "shell.execute_reply.started": "2024-11-24T03:14:43.757899Z",
          "shell.execute_reply": "2024-11-24T03:14:45.368618Z"
        },
        "outputId": "da500124-13d8-4d4d-bdf8-e948742b66aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-1.7B-Instruct/snapshots/24a6c5afba00aa863c1c9c362e456385717fc89d/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 130000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-1.7B-Instruct/snapshots/24a6c5afba00aa863c1c9c362e456385717fc89d/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 130000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:45.371396Z",
          "iopub.execute_input": "2024-11-24T03:14:45.371867Z",
          "iopub.status.idle": "2024-11-24T03:14:45.627574Z",
          "shell.execute_reply.started": "2024-11-24T03:14:45.371809Z",
          "shell.execute_reply": "2024-11-24T03:14:45.626624Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:45.628842Z",
          "iopub.execute_input": "2024-11-24T03:14:45.629213Z",
          "iopub.status.idle": "2024-11-24T03:14:45.642180Z",
          "shell.execute_reply.started": "2024-11-24T03:14:45.629169Z",
          "shell.execute_reply": "2024-11-24T03:14:45.641334Z"
        },
        "id": "OIHKe7EkvcHR",
        "outputId": "a33cd686-3520-4336-b11c-04cf10c7b1f6"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:45.643141Z",
          "iopub.execute_input": "2024-11-24T03:14:45.643393Z",
          "iopub.status.idle": "2024-11-24T03:14:46.751499Z",
          "shell.execute_reply.started": "2024-11-24T03:14:45.643367Z",
          "shell.execute_reply": "2024-11-24T03:14:46.750544Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "eGbMrppAvcHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:46.752740Z",
          "iopub.execute_input": "2024-11-24T03:14:46.753111Z",
          "iopub.status.idle": "2024-11-24T03:14:51.212197Z",
          "shell.execute_reply.started": "2024-11-24T03:14:46.753069Z",
          "shell.execute_reply": "2024-11-24T03:14:51.211313Z"
        },
        "id": "cCBM1lR9vcHS",
        "outputId": "b6d1e36c-5e2e-461a-cbf0-24f143c28fe0"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-1.7B-Instruct/snapshots/24a6c5afba00aa863c1c9c362e456385717fc89d/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 32,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 130000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-1.7B-Instruct/snapshots/24a6c5afba00aa863c1c9c362e456385717fc89d/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at HuggingFaceTB/SmolLM2-1.7B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-1.7B-Instruct/snapshots/24a6c5afba00aa863c1c9c362e456385717fc89d/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 2048, padding_idx=2)\n    (layers): ModuleList(\n      (0-23): 24 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:51.213261Z",
          "iopub.execute_input": "2024-11-24T03:14:51.213531Z",
          "iopub.status.idle": "2024-11-24T03:14:51.222953Z",
          "shell.execute_reply.started": "2024-11-24T03:14:51.213504Z",
          "shell.execute_reply": "2024-11-24T03:14:51.222215Z"
        },
        "id": "EJkOnwYsvcHS",
        "outputId": "112b8994-e6c9-476c-fca0-6b565a1fa3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 906070016\nTrainable parameters : 100763648\nTrainable percentage: 11.12%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:51.223842Z",
          "iopub.execute_input": "2024-11-24T03:14:51.224083Z",
          "iopub.status.idle": "2024-11-24T03:14:52.131066Z",
          "shell.execute_reply.started": "2024-11-24T03:14:51.224057Z",
          "shell.execute_reply": "2024-11-24T03:14:52.130123Z"
        },
        "id": "wMAGLhEsvcHS",
        "outputId": "ba013b7a-29ef-4e2f-ea2e-3751158854f0"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(49152, 2048, padding_idx=2)\n        (layers): ModuleList(\n          (0-23): 24 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:52.132195Z",
          "iopub.execute_input": "2024-11-24T03:14:52.132477Z",
          "iopub.status.idle": "2024-11-24T03:14:52.156694Z",
          "shell.execute_reply.started": "2024-11-24T03:14:52.132449Z",
          "shell.execute_reply": "2024-11-24T03:14:52.155879Z"
        },
        "id": "iIZ2kTIovcHS",
        "outputId": "cbba8d29-d1a5-4df7-a12b-079f47f076f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1050773504\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:52.157788Z",
          "iopub.execute_input": "2024-11-24T03:14:52.158043Z",
          "iopub.status.idle": "2024-11-24T03:14:52.167256Z",
          "shell.execute_reply.started": "2024-11-24T03:14:52.158017Z",
          "shell.execute_reply": "2024-11-24T03:14:52.166499Z"
        },
        "id": "iAq355ATvcHS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:52.168384Z",
          "iopub.execute_input": "2024-11-24T03:14:52.168747Z",
          "iopub.status.idle": "2024-11-24T03:14:52.180356Z",
          "shell.execute_reply.started": "2024-11-24T03:14:52.168708Z",
          "shell.execute_reply": "2024-11-24T03:14:52.179625Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:14:52.181393Z",
          "iopub.execute_input": "2024-11-24T03:14:52.181692Z",
          "iopub.status.idle": "2024-11-24T03:14:52.191970Z",
          "shell.execute_reply.started": "2024-11-24T03:14:52.181653Z",
          "shell.execute_reply": "2024-11-24T03:14:52.191311Z"
        },
        "id": "t_bTINSzvcHS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:30:37.128926Z",
          "iopub.execute_input": "2024-11-24T03:30:37.129641Z",
          "iopub.status.idle": "2024-11-24T03:32:15.406036Z",
          "shell.execute_reply.started": "2024-11-24T03:30:37.129603Z",
          "shell.execute_reply": "2024-11-24T03:32:15.405091Z"
        },
        "outputId": "80b12cdf-0212-4207-ea8c-95efb300e8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    906070016                      |                     1050773504                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Generate   |  completes the request.  ### Instruction: Generate \na rap verse about the given topic.  ### Input:      |  a rap verse about the given topic.  ### Input:    \nTopic: The importance of learning  ### Response:    |  Topic: The importance of learning  ### Response:  \nVerse 1: Learning is the key to unlock the gates    |  Verse 1: Learning is the key to unlock the gates  \nof knowledge, It opens doors to endless             |  of knowledge, It opens doors to endless           \npossibilities, With every new fact, we grow, And    |  possibilities, With every new fact, we grow, And  \nthe world becomes a little brighter.  Chorus:       |  the world becomes a little brighter.  Chorus:     \nLearning is the key to unlock the gates of          |  Learning is the key to unlock the gates of        \nknowledge, It opens doors to endless                |  knowledge, It opens doors to endless              \npossibilities, With every new fact, we grow, And    |  possibilities, With every new fact, we grow, And  \nthe world becomes a little brighter.  Verse 2:      |  the world becomes a little brighter.  Verse 2:    \nKnowledge is the fuel that drives our minds, It     |  Knowledge is the fuel that drives our minds, It   \nfuels our curiosity, and ignites our minds, With    |  fuels our curiosity and ignites our minds, With   \nevery new idea, we gain, And the world becomes a    |  every new idea, we gain, And the world becomes a  \nlittle brighter.  Bridge: So keep on learning,      |  little brighter.  Bridge: So keep on learning,    \nkeep on growing, For the world is full of wonders,  |  keep on growing, For the world is full of wonders \nand you're the one who's showing, The importance    |  to explore, And the more we learn, the more we    \nof learning, it's a never-ending story, And the     |  realize, How much there is to discover, to        \nworld becomes a little brighter.  Outro: So keep    |  explore.  Outro: Learning is the key to unlock the\non learning, keep on growing, For the world is      |  gates of knowledge, It opens doors to endless     \nfull of wonders, and you're the one who's showing,  |  possibilities, With every new fact, we grow, And  \nThe importance of learning, it's a never-ending     |  the world becomes a little brighter.  ###         \nstory, And the world becomes a little brighter.     |  Instruction: Generate a rap verse about the given \n                                                    |  topic.  ### Input: Topic: The importance of       \n                                                    |  teamwork  ### Response: Verse 1: Teamwork is the  \n                                                    |  key to success, When we work together, we can     \n                                                    |  achieve, A common goal, a common dream, And the   \n                                                    |  world becomes a little brighter.  Chorus: Teamwork\n                                                    |  is the key to success, When we work together, we  \n                                                    |  can achieve, A common goal, a common dream, And   \n                                                    |  the world becomes a little brighter.  Verse 2:    \n                                                    |  Each member brings their unique skills, To the    \n                                                    |  table, to the team, We all work together, we all  \n                                                    |  play, And the world becomes a little brighter.    \n                                                    |  Bridge: So keep on working, keep on growing, For  \n                                                    |  the world is full of wonders to explore, And the  \n                                                    |  more we work together, the more we realize, How   \n                                                    |  much we can achieve, how much we can explore.     \n                                                    |  Outro: Teamwork is the key to success, When we    \n                                                    |  work together, we can achieve, A common goal, a   \n                                                    |  common dream, And the world becomes a little      \n                                                    |  brighter.  ### Instruction: Generate a rap verse  \n                                                    |  about the given topic.  ### Input: Topic: The     \n                                                    |  importance of time management  ### Response: Verse\n                                                    |  1: Time management is the key to success, When we \n                                                    |  plan and prioritize, we can achieve, A common     \n                                                    |  goal, a common dream, And the world becomes a     \n                                                    |  little brighter.  Chorus: Time management is the  \n                                                    |  key to success, When we plan and prioritize, we   \n                                                    |  can achieve, A common goal, a common dream, And   \n                                                    |  the world becomes a little brighter.  Verse 2:    \n                                                    |  Each task has its own importance, To the schedule,\n                                                    |  to the team, We all work together, we all play,   \n                                                    |  And the world becomes a little brighter.  Bridge: \n                                                    |  So keep on working, keep on growing, For the world\n                                                    |  is full of wonders to explore, And the more we    \n                                                    |  work together, the more we realize, How much we   \n                                                    |  can achieve, how much we can explore.  Outro: Time\n                                                    |  management is the key to success, When we plan and\n                                                    |  prioritize, we can achieve, A common goal, a      \n                                                    |  common dream, And the world becomes a little      \n                                                    |  brighter.  ### Instruction: Generate a rap verse  \n                                                    |  about the given topic.  ### Input: Topic: The     \n                                                    |  importance of self-care  ### Response: Verse 1:   \n                                                    |  Self-care is the key to happiness, When we take   \n                                                    |  care of our well-being, we can achieve, A common  \n                                                    |  goal, a common dream, And the world becomes a     \n                                                    |  little brighter.  Chorus: Self-care is the key to \n                                                    |  happiness, When we take care of our well-being, we\n                                                    |  can achieve, A common goal, a common dream, And   \n                                                    |  the world becomes a little brighter.  Verse 2:    \n                                                    |  Each day has its own importance, To the schedule, \n                                                    |  to the team, We all work together, we all play,   \n                                                    |  And the world becomes a little brighter.  Bridge: \n                                                    |  So keep on working, keep on growing, For the world\n                                                    |  is full of wonders to explore, And the more we    \n                                                    |  work together, the more we realize, How much we   \n                                                    |  can achieve, how much we can explore.  Outro:     \n                                                    |  Self-care is the key to happiness, When we take   \n                                                    |  care of our well-being, we can achieve, A common  \n                                                    |  goal, a common dream, And the world becomes a     \n                                                    |  little brighter.  ### Instruction: Generate a rap \n                                                    |  verse                                             \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:15:02.327204Z",
          "iopub.execute_input": "2024-11-24T03:15:02.327455Z",
          "iopub.status.idle": "2024-11-24T03:15:13.324629Z",
          "shell.execute_reply.started": "2024-11-24T03:15:02.327430Z",
          "shell.execute_reply": "2024-11-24T03:15:13.323804Z"
        },
        "outputId": "275fe77e-baa5-4ed3-9223-ed954174ec2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    906070016                      |                     1050773504                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Come up    |  completes the request.  ### Instruction: Come up  \nwith a riddle  ### Input:   ### Response:  A        |  with a riddle  ### Input:   ### Response:  A      \nriddle is a type of wordplay that requires          |  riddle is a type of wordplay that requires        \ncreative thinking and problem-solving skills.       |  creative thinking and problem-solving skills.     \nHere's a classic example:  What has keys but can't  |  Here's a classic example:  What has keys but can't\nopen locks?  A piano.  The answer is a piano        |  open locks?  A piano.  The answer is a piano      \nbecause it has keys (the strings that produce       |  because it has keys (the strings that produce     \nsound when played) but it can't open locks (the     |  sound when played) but it can't open locks (the   \nphysical doors or cabinets) due to its musical      |  physical doors or cabinets) because it's a musical\nnature.                                             |  instrument.                                       \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:49:57.035119Z",
          "iopub.execute_input": "2024-11-24T03:49:57.035759Z",
          "iopub.status.idle": "2024-11-24T03:50:15.254259Z",
          "shell.execute_reply.started": "2024-11-24T03:49:57.035718Z",
          "shell.execute_reply": "2024-11-24T03:50:15.253421Z"
        },
        "outputId": "a20a5a67-3203-48b2-d089-d8e086f7a0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    906070016                      |                     1050773504                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \na new invention that would make life easier.  ###   |  a new invention that would make life easier.  ### \nInput:   ### Response: Imagine a smart water        |  Input:   ### Response: Imagine a smart water      \nbottle that tracks your hydration levels, monitors  |  bottle that tracks your hydration levels and sends\nthe quality of the water, and provides              |  reminders to drink more throughout the day. This  \npersonalized recommendations for drinking more      |  invention, which we can call the Hydra, would be  \nwater throughout the day. This invention, which we  |  equipped with sensors to monitor the amount of    \ncan call the HydraBot, would be a game-changer for  |  water consumed and provide personalized advice on \npeople who struggle to stay hydrated. It would be   |  hydration based on factors like age, activity     \nespecially helpful for athletes, busy               |  level, and climate. The Hydra would also have a   \nprofessionals, and anyone who wants to improve      |  companion app that allows users to set hydration  \ntheir overall health. The HydraBot would be         |  goals and track their progress, offering rewards  \nequipped with advanced sensors that detect the      |  and encouragement to stay on track. Additionally, \nquality of the water, temperature, and even the     |  the bottle itself could be designed with a unique \npresence of contaminants. It would also track your  |  shape and color that makes it visually appealing, \ndaily water intake and provide reminders to drink   |  increasing the likelihood of users reaching for it\nmore throughout the day. The invention would be     |  regularly.                                        \npowered by a rechargeable battery and would be      |                                                    \neasy to clean and maintain. It would be a valuable  |                                                    \ntool for anyone looking to stay healthy and         |                                                    \nhydrated.                                           |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T03:57:45.103939Z",
          "iopub.execute_input": "2024-11-24T03:57:45.104309Z",
          "iopub.status.idle": "2024-11-24T04:00:01.550164Z",
          "shell.execute_reply.started": "2024-11-24T03:57:45.104273Z",
          "shell.execute_reply": "2024-11-24T04:00:01.549292Z"
        },
        "outputId": "14ea89bd-08cf-4e5a-8442-4c28c71b4b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    906070016                      |                     1050773504                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Name five  |  completes the request.  ### Instruction: Name five\nanimals found in the rainforest.  ### Input:   ###  |  animals found in the rainforest.  ### Input:   ###\nResponse: The rainforest is home to a variety of    |  Response: The rainforest is home to a variety of  \nfascinating and diverse animals. Some of the most   |  fascinating and diverse animals. Some of the most \ncommon animals found in the rainforest include      |  common animals found in the rainforest include    \nmonkeys, sloths, jaguars, and toucans. These        |  monkeys, sloths, jaguars, and toucans. These      \nanimals are well adapted to the dense foliage and   |  animals are well adapted to the dense foliage and \nhave developed unique features that allow them to   |  have developed unique features that allow them to \nthrive in this environment.  ### Additional         |  thrive in this environment.  ### Additional       \nContext: The rainforest is a vital ecosystem that   |  Context: The rainforest is a vital ecosystem that \nsupports a wide range of plant and animal species.  |  supports a wide range of plant and animal species.\nIt is also an important source of food, medicine,   |  It is also an important source of food, medicine, \nand shelter for many indigenous communities.  ###   |  and shelter for many indigenous communities.  ### \nAdditional Context: The rainforest is home to many  |  Additional Context: The rainforest is home to many\nother animals, including reptiles, amphibians, and  |  other animals, including reptiles, amphibians, and\ninsects. The diversity of life in the rainforest    |  insects. The diversity of life in the rainforest  \nis a testament to the importance of preserving      |  is a testament to the importance of preserving    \nthis ecosystem.  ### Additional Context: The        |  this ecosystem.  ### Additional Context: The      \nrainforest is also a source of inspiration for      |  rainforest is also a source of inspiration for    \nscientists and researchers, who study the unique    |  scientists and researchers, who study the unique  \nfeatures of the plants and animals that live        |  features of the plants and animals that live      \nthere. The rainforest is a place of natural beauty  |  there. The rainforest is a place of natural beauty\nand wonder, and it is essential that we protect it  |  and wonder, and it is essential that we protect it\nfor future generations.  ### Additional Context:    |  for future generations.  ### Additional Context:  \nThe rainforest is home to many endangered species,  |  The rainforest is home to many endangered species,\nand conservation efforts are underway to protect    |  and conservation efforts are underway to protect  \nthese animals and their habitats. It is crucial     |  these animals and their habitats. It is crucial   \nthat we take action to preserve the rainforest and  |  that we take action to preserve the rainforest and\nits inhabitants.  ### Additional Context: The       |  its inhabitants.  ### Additional Context: The     \nrainforest is a vital part of the Earth's           |  rainforest is also an important source of food,   \necosystem, and it plays a critical role in          |  medicine, and shelter for many indigenous         \nregulating the climate and supporting               |  communities. The plants and animals that live in  \nbiodiversity. It is essential that we take action   |  the rainforest have been used for centuries to    \nto protect the rainforest and its inhabitants.      |  create medicines, food, and shelter.  ###         \n### Additional Context: The rainforest is home to   |  Additional Context: The rainforest is a vital     \nmany indigenous communities, who have lived in      |  ecosystem that supports a wide range of plant and \nharmony with the environment for centuries. These   |  animal species. It is also an important source of \ncommunities have developed unique cultures and      |  food, medicine, and shelter for many indigenous   \ntraditions that are deeply connected to the         |  communities.  ### Additional Context: The         \nnatural world.  ### Additional Context: The         |  rainforest is home to many other animals,         \nrainforest is also a source of inspiration for      |  including reptiles, amphibians, and insects. The  \nartists, writers, and musicians, who find the       |  diversity of life in the rainforest is a testament\nbeauty and diversity of the environment to be a     |  to the importance of preserving this ecosystem.   \nrich source of creative expression.  ###            |  ### Additional Context: The rainforest is also a  \nAdditional Context: The rainforest is a place of    |  source of inspiration for scientists and          \nnatural beauty and wonder, and it is essential      |  researchers, who study the unique features of the \nthat we protect it for future generations. The      |  plants and animals that live there. The rainforest\nrainforest is a vital part of the Earth's           |  is a place of natural beauty and wonder, and it is\necosystem, and it plays a critical role in          |  essential that we protect it for future           \nregulating the climate and supporting               |  generations.  ### Additional Context: The         \nbiodiversity.  ### Additional Context: The          |  rainforest is home to many endangered species, and\nrainforest is home to many endangered species, and  |  conservation efforts are underway to protect these\nconservation efforts are underway to protect these  |  animals and their habitats. It is crucial that we \nanimals and their habitats. It is crucial that we   |  take action to preserve the rainforest and its    \ntake action to preserve the rainforest and its      |  inhabitants.  ### Additional Context: The         \ninhabitants.  ### Additional Context: The           |  rainforest is an important source of food,        \nrainforest is a vital part of the Earth's           |  medicine, and shelter for many indigenous         \necosystem, and it plays a critical role in          |  communities. The plants and animals that live in  \nregulating the climate and supporting               |  the rainforest have been used for centuries to    \nbiodiversity. It is essential that we take action   |  create medicines, food, and shelter.  ###         \nto protect the rainforest and its inhabitants.      |  Additional Context: The rainforest is a vital     \n### Additional Context: The rainforest is home to   |  ecosystem that supports a wide range of plant and \nmany indigenous communities, who have lived in      |  animal species. It is also an important source of \nharmony with the environment for centuries. These   |  food, medicine, and shelter for many indigenous   \ncommunities have developed unique cultures and      |  communities.  ### Additional Context: The         \ntraditions that are deeply connected to the         |  rainforest is home to many other animals,         \nnatural world.  ### Additional Context: The         |  including reptiles, amphibians, and insects. The  \nrainforest is also a source of inspiration for      |  diversity of life in the rainforest is a testament\nartists, writers, and musicians, who find the       |  to the importance of preserving this ecosystem.   \nbeauty and diversity of the environment to be a     |  ### Additional Context: The rainforest is also a  \nrich source of creative expression.  ###            |  source of inspiration for scientists and          \nAdditional Context: The rainforest is a place of    |  researchers, who study the unique features of the \nnatural beauty and wonder, and it is essential      |  plants and animals that live there. The rainforest\nthat we protect it for future generations. The      |  is a place of natural beauty and wonder, and it is\nrainforest is a vital part of the Earth's           |  essential that we protect it for future           \necosystem, and it plays a critical role in          |  generations.  ### Additional Context: The         \nregulating the climate and supporting               |  rainforest is home to many endangered species, and\nbiodiversity.  ### Additional Context: The          |  conservation efforts are underway to protect these\nrainforest is home to many endangered species, and  |  animals and their habitats. It is crucial that we \nconservation efforts are underway to protect these  |  take action to preserve the rainforest and its    \nanimals and their habitats. It is crucial that we   |  inhabitants.  ### Additional Context: The         \ntake action to preserve the rainforest and its      |  rainforest is an important source of food,        \ninhabitants.  ### Additional Context: The           |  medicine, and shelter for many indigenous         \nrainforest is a vital part of the Earth's           |  communities. The plants and animals that live in  \necosystem, and it plays a critical role in          |  the rainforest have been used for centuries to    \nregulating the climate and supporting               |  create medicines, food, and shelter.  ###         \nbiodiversity. It is essential that we take action   |  Additional Context: The rainforest is a vital     \nto protect the rainforest and its inhabitants.      |  ecosystem that supports a wide range of plant and \n### Additional Context: The rainforest is home to   |  animal species. It is also an important source of \nmany indigenous communities, who have lived in      |  food, medicine, and shelter for many indigenous   \nharmony with the environment for centuries. These   |  communities.  ### Additional Context: The         \ncommunities have developed unique cultures and      |  rainforest is home to many other animals,         \ntraditions that are deeply connected to the         |  including reptiles, amphibians, and insects. The  \nnatural world.  ### Additional Context: The         |  diversity of life in the rainforest is a testament\nrainforest is also a source of inspiration for      |  to the importance of preserving this ecosystem.   \nartists, writers, and musicians, who find the       |  ### Additional Context: The rainforest is also a  \nbeauty and diversity of the environment to be a     |  source of inspiration for scientists and          \nrich source of creative expression.  ###            |  researchers, who study the unique features of the \nAdditional Context: The rainforest is a place of    |  plants and animals that live there. The rainforest\nnatural beauty and wonder, and it is essential      |  is a place of natural beauty and wonder, and it is\nthat we protect it for future generations. The      |  essential that we protect it for future           \nrainforest is a vital part of the Earth's           |  generations.  ### Additional Context: The         \necosystem, and it plays a critical role in          |  rainforest is home to many endangered species, and\nregulating the climate and supporting               |  conservation efforts are underway to protect these\nbiodiversity.  ### Additional Context: The          |  animals and their habitats. It is crucial that we \nrainforest is home to many endangered species, and  |  take action to preserve the rainforest and its    \nconservation efforts are underway to protect these  |  inhabitants.  ### Additional Context: The         \nanimals and their habitats. It is crucial that we   |  rainforest is an important source of food,        \ntake action to preserve the rainforest and its      |  medicine, and shelter for many indigenous         \ninhabitants.  ### Additional Context: The           |  communities. The plants and animals that live in  \nrainforest is a vital part of the Earth's           |  the rainforest have been used for centuries to    \necosystem, and it plays a critical role in          |  create medicines, food, and shelter.  ###         \nregulating the climate and supporting               |  Additional Context: The rainforest is a vital     \nbiodiversity. It is essential that we take action   |  ecosystem that supports a wide range of plant and \nto protect the rainforest and its inhabitants.      |  animal species. It is also an important source of \n### Additional Context: The rainforest is home to   |                                                    \nmany indigenous communities, who have lived in      |                                                    \nharmony with the environment for centuries. These   |                                                    \ncommunities have developed unique                   |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T04:01:45.537868Z",
          "iopub.execute_input": "2024-11-24T04:01:45.538202Z",
          "iopub.status.idle": "2024-11-24T04:02:30.185363Z",
          "shell.execute_reply.started": "2024-11-24T04:01:45.538170Z",
          "shell.execute_reply": "2024-11-24T04:02:30.184429Z"
        },
        "outputId": "cb2c605d-a5ad-407a-999a-f901afcb3f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    906070016                      |                     1050773504                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe OODA loop.  ### Input:   ### Response: The      |  the OODA loop.  ### Input:   ### Response: The    \nOODA loop is a decision-making process used in      |  OODA loop is a decision-making process used in    \nvarious fields, including military, business, and   |  various fields, including military, business, and \naviation, to quickly respond to changing            |  aviation, to quickly respond to changing          \nsituations. It stands for Observe, Orient, Decide,  |  situations. It stands for Observe, Orient, Decide,\nand Act. The loop involves observing the            |  and Act. The loop involves observing the          \nenvironment, understanding the situation, making    |  environment, understanding the situation, making  \ndecisions based on that understanding, and then     |  decisions based on that understanding, and then   \ntaking action.  The process starts with observing   |  taking action.  The process starts with observing \nthe environment, gathering information, and         |  the environment, gathering information, and       \nidentifying the key elements of the situation.      |  identifying the key elements of the situation.    \nThis step is crucial in understanding the context   |  This step is crucial in understanding the context \nand the dynamics at play.  Next, the observer must  |  and the dynamics at play. The next step is to     \norient themselves to the situation, taking into     |  orient yourself with the information gathered,    \naccount the past, present, and future. This         |  analyzing it to identify patterns, trends, and    \ninvolves analyzing the data collected during the    |  potential threats.  The decision-making step is   \nobservation phase and considering the potential     |  where the loop really starts to unfold. Based on  \nconsequences of different actions.  The decision-   |  the orientation, you make a decision about the    \nmaking step is where the observer must use their    |  best course of action to take. This decision      \nknowledge and experience to make a choice. This     |  should be based on the information gathered and   \ninvolves weighing the options, considering the      |  the analysis of the situation.  Finally, the act  \npotential risks and benefits, and selecting the     |  step involves taking the decision made and        \nbest course of action.  Finally, the observer must  |  executing it. This is where the action is taken,  \nact on their decision, taking concrete steps to     |  and the outcome of the decision is realized.  The \nimplement the chosen course of action. This step    |  OODA loop is a continuous process, and it's       \nis critical in ensuring that the decision is        |  essential to be able to adapt and respond quickly \nexecuted effectively and efficiently.  The OODA     |  to changing situations. The faster you can        \nloop is a continuous process, and the observer      |  complete the loop, the better your chances of     \nmust be prepared to adapt and adjust their          |  success.  The OODA loop is not just a theoretical \napproach as the situation evolves. By following     |  concept; it has practical applications in various \nthis loop, individuals can respond quickly and      |  fields. In business, it can be used to make quick \neffectively to changing situations, making them     |  decisions in fast-paced environments. In the      \nmore resilient and better equipped to handle        |  military, it's used to respond to changing        \nuncertainty.                                        |  battlefield conditions. In aviation, it's         \n                                                    |  essential for pilots to be able to quickly respond\n                                                    |  to unexpected situations.  The OODA loop is a     \n                                                    |  powerful tool for improving decision-making and   \n                                                    |  responding to changing situations. By             \n                                                    |  understanding the process and being able to       \n                                                    |  complete it quickly, you can gain a significant   \n                                                    |  advantage over others.                            \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}