{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"!pip install -q --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-14T09:24:13.392761Z","iopub.execute_input":"2024-12-14T09:24:13.393132Z","iopub.status.idle":"2024-12-14T09:25:10.541174Z","shell.execute_reply.started":"2024-12-14T09:24:13.393104Z","shell.execute_reply":"2024-12-14T09:25:10.539919Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.12.2 requires transformers<4.47.0, but you have transformers 4.47.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-12-14T09:25:10.543340Z","iopub.execute_input":"2024-12-14T09:25:10.544160Z","iopub.status.idle":"2024-12-14T09:25:18.555262Z","shell.execute_reply.started":"2024-12-14T09:25:10.544113Z","shell.execute_reply":"2024-12-14T09:25:18.554331Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-12-14T09:25:18.556472Z","iopub.execute_input":"2024-12-14T09:25:18.556756Z","iopub.status.idle":"2024-12-14T09:25:18.563556Z","shell.execute_reply.started":"2024-12-14T09:25:18.556728Z","shell.execute_reply":"2024-12-14T09:25:18.562488Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"model_name = 'unsloth/Llama-3.1-Storm-8B'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-14T09:25:18.565424Z","iopub.execute_input":"2024-12-14T09:25:18.565677Z","iopub.status.idle":"2024-12-14T09:25:18.578314Z","shell.execute_reply.started":"2024-12-14T09:25:18.565653Z","shell.execute_reply":"2024-12-14T09:25:18.577513Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-12-14T09:25:18.579421Z","iopub.execute_input":"2024-12-14T09:25:18.580143Z","iopub.status.idle":"2024-12-14T09:25:18.588591Z","shell.execute_reply.started":"2024-12-14T09:25:18.580103Z","shell.execute_reply":"2024-12-14T09:25:18.587817Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:25:18.589419Z","iopub.execute_input":"2024-12-14T09:25:18.589650Z","iopub.status.idle":"2024-12-14T09:33:18.061020Z","shell.execute_reply.started":"2024-12-14T09:25:18.589627Z","shell.execute_reply":"2024-12-14T09:33:18.060320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/910 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4736105a6bc64f48bc840f2f842f3bb9"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6096214d7791444e89887e4c44babbfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00cab6d638734603b5c49faacef50007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49dcab39459544018ce23b58e2df1b14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3611ce119f7840c99bb55af47df3fb17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c825bae49de4792a16ff48e6be3e176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2c976626a14cc7b13e7a5e08a36b1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a769404a935540e58145b97884cf1211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a196519692f1431db9b6c2b92cc2e9c8"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:18.061983Z","iopub.execute_input":"2024-12-14T09:33:18.062240Z","iopub.status.idle":"2024-12-14T09:33:18.071113Z","shell.execute_reply.started":"2024-12-14T09:33:18.062214Z","shell.execute_reply":"2024-12-14T09:33:18.070321Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4540600320\nTrainable parameters : 1050939392\nTrainable percentage: 23.15%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:18.072135Z","iopub.execute_input":"2024-12-14T09:33:18.072402Z","iopub.status.idle":"2024-12-14T09:33:19.696864Z","shell.execute_reply.started":"2024-12-14T09:33:18.072378Z","shell.execute_reply":"2024-12-14T09:33:19.696156Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465cfc78ffd24a66a92f8ac0bb87112d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a6efaf7b1c14af5a84093a764c1cba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"decd1b3862dd41f9a5048b3c22f0a6cc"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"dataset_name = 'microsoft/orca-math-word-problems-200k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:19.697966Z","iopub.execute_input":"2024-12-14T09:33:19.698292Z","iopub.status.idle":"2024-12-14T09:33:19.702797Z","shell.execute_reply.started":"2024-12-14T09:33:19.698248Z","shell.execute_reply":"2024-12-14T09:33:19.701785Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 384","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:19.705605Z","iopub.execute_input":"2024-12-14T09:33:19.706143Z","iopub.status.idle":"2024-12-14T09:33:19.715526Z","shell.execute_reply.started":"2024-12-14T09:33:19.706114Z","shell.execute_reply":"2024-12-14T09:33:19.714745Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:19.716496Z","iopub.execute_input":"2024-12-14T09:33:19.716789Z","iopub.status.idle":"2024-12-14T09:33:21.667600Z","shell.execute_reply.started":"2024-12-14T09:33:19.716764Z","shell.execute_reply":"2024-12-14T09:33:21.666669Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answer'],\n    num_rows: 200035\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:21.668820Z","iopub.execute_input":"2024-12-14T09:33:21.669208Z","iopub.status.idle":"2024-12-14T09:33:21.676598Z","shell.execute_reply.started":"2024-12-14T09:33:21.669170Z","shell.execute_reply":"2024-12-14T09:33:21.675745Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:21.677638Z","iopub.execute_input":"2024-12-14T09:33:21.677895Z","iopub.status.idle":"2024-12-14T09:33:22.125700Z","shell.execute_reply.started":"2024-12-14T09:33:21.677870Z","shell.execute_reply":"2024-12-14T09:33:22.124784Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.126648Z","iopub.execute_input":"2024-12-14T09:33:22.126918Z","iopub.status.idle":"2024-12-14T09:33:22.132283Z","shell.execute_reply.started":"2024-12-14T09:33:22.126892Z","shell.execute_reply":"2024-12-14T09:33:22.131419Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.133263Z","iopub.execute_input":"2024-12-14T09:33:22.133546Z","iopub.status.idle":"2024-12-14T09:33:22.144060Z","shell.execute_reply.started":"2024-12-14T09:33:22.133521Z","shell.execute_reply":"2024-12-14T09:33:22.143353Z"}},"outputs":[{"name":"stdout","text":"['question', 'answer']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.144981Z","iopub.execute_input":"2024-12-14T09:33:22.145191Z","iopub.status.idle":"2024-12-14T09:33:22.154191Z","shell.execute_reply.started":"2024-12-14T09:33:22.145170Z","shell.execute_reply":"2024-12-14T09:33:22.153549Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  input = examples['question']\n  output = examples['answer']\n  \n  text = prompt_format.format(input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.155324Z","iopub.execute_input":"2024-12-14T09:33:22.155887Z","iopub.status.idle":"2024-12-14T09:33:22.165577Z","shell.execute_reply.started":"2024-12-14T09:33:22.155859Z","shell.execute_reply":"2024-12-14T09:33:22.164808Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.166543Z","iopub.execute_input":"2024-12-14T09:33:22.166780Z","iopub.status.idle":"2024-12-14T09:33:22.225561Z","shell.execute_reply.started":"2024-12-14T09:33:22.166757Z","shell.execute_reply":"2024-12-14T09:33:22.224817Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.226524Z","iopub.execute_input":"2024-12-14T09:33:22.226861Z","iopub.status.idle":"2024-12-14T09:33:22.232053Z","shell.execute_reply.started":"2024-12-14T09:33:22.226822Z","shell.execute_reply":"2024-12-14T09:33:22.231150Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|eot_id|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.233027Z","iopub.execute_input":"2024-12-14T09:33:22.233255Z","iopub.status.idle":"2024-12-14T09:33:22.243395Z","shell.execute_reply.started":"2024-12-14T09:33:22.233233Z","shell.execute_reply":"2024-12-14T09:33:22.242804Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:22.244471Z","iopub.execute_input":"2024-12-14T09:33:22.244719Z","iopub.status.idle":"2024-12-14T09:33:30.854753Z","shell.execute_reply.started":"2024-12-14T09:33:22.244694Z","shell.execute_reply":"2024-12-14T09:33:30.853819Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf3d7318cc1a4299b6022532a87a6f06"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.855877Z","iopub.execute_input":"2024-12-14T09:33:30.856119Z","iopub.status.idle":"2024-12-14T09:33:30.861441Z","shell.execute_reply.started":"2024-12-14T09:33:30.856096Z","shell.execute_reply":"2024-12-14T09:33:30.860535Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|eot_id|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.862618Z","iopub.execute_input":"2024-12-14T09:33:30.862950Z","iopub.status.idle":"2024-12-14T09:33:30.933466Z","shell.execute_reply.started":"2024-12-14T09:33:30.862913Z","shell.execute_reply":"2024-12-14T09:33:30.932684Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.934476Z","iopub.execute_input":"2024-12-14T09:33:30.934751Z","iopub.status.idle":"2024-12-14T09:33:30.942151Z","shell.execute_reply.started":"2024-12-14T09:33:30.934727Z","shell.execute_reply":"2024-12-14T09:33:30.941184Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.943161Z","iopub.execute_input":"2024-12-14T09:33:30.943422Z","iopub.status.idle":"2024-12-14T09:33:30.966647Z","shell.execute_reply.started":"2024-12-14T09:33:30.943395Z","shell.execute_reply":"2024-12-14T09:33:30.965848Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [128000, 14711, 16225, 512, 3947, 374, 264, 14...   \n1  [128000, 14711, 16225, 512, 644, 264, 2466, 38...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128000, 14711, 16225, 512, 3947, 374, 264, 52...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 14...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[128000, 14711, 16225, 512, 644, 264, 2466, 38...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 52...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.967583Z","iopub.execute_input":"2024-12-14T09:33:30.967826Z","iopub.status.idle":"2024-12-14T09:33:30.972686Z","shell.execute_reply.started":"2024-12-14T09:33:30.967802Z","shell.execute_reply":"2024-12-14T09:33:30.971799Z"}},"outputs":[{"name":"stdout","text":"### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|eot_id|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.973802Z","iopub.execute_input":"2024-12-14T09:33:30.974593Z","iopub.status.idle":"2024-12-14T09:33:30.982709Z","shell.execute_reply.started":"2024-12-14T09:33:30.974555Z","shell.execute_reply":"2024-12-14T09:33:30.981981Z"}},"outputs":[{"name":"stdout","text":"[128000, 14711, 16225, 512, 3947, 374, 264, 1403, 49442, 5933, 1396, 6832, 22781, 2035, 374, 220, 18, 13, 6914, 362, 323, 426, 387, 279, 75862, 315, 420, 1396, 555, 220, 605, 323, 279, 27410, 315, 13096, 555, 220, 605, 11, 15947, 13, 1442, 426, 56016, 555, 220, 605, 5636, 362, 374, 220, 24, 2753, 1109, 362, 56016, 555, 220, 605, 5636, 426, 11, 1148, 374, 279, 1176, 1396, 5380, 14711, 22559, 512, 10267, 596, 79164, 279, 1403, 49442, 1396, 439, 18240, 58419, 1144, 705, 1405, 18240, 1630, 1144, 8, 374, 279, 16099, 304, 279, 22781, 2035, 323, 18240, 816, 1144, 8, 374, 279, 16099, 304, 279, 6305, 2035, 13, 8876, 279, 22781, 2035, 374, 220, 18, 11, 584, 617, 18240, 1630, 284, 220, 18, 1144, 3677, 11439, 311, 279, 3575, 11, 18240, 362, 1144, 8, 374, 279, 75862, 315, 279, 1396, 555, 220, 605, 11, 323, 18240, 426, 1144, 8, 374, 279, 27410, 315, 279, 13096, 555, 220, 605, 13, 15636, 11, 18240, 362, 284, 1630, 284, 220, 18, 1144, 8, 323, 18240, 426, 284, 816, 1144, 3677, 791, 3575, 5415, 430, 18240, 426, 1144, 15487, 220, 605, 489, 362, 1144, 8, 374, 220, 24, 2753, 1109, 18240, 362, 1144, 15487, 220, 605, 489, 426, 1144, 570, 1115, 649, 387, 5439, 439, 459, 24524, 1473, 79145, 426, 1144, 15487, 220, 605, 489, 362, 284, 362, 1144, 15487, 220, 605, 489, 426, 482, 220, 24, 1144, 2595, 3214, 3781, 10831, 18240, 362, 1144, 8, 323, 18240, 426, 1144, 8, 449, 18240, 220, 18, 1144, 8, 323, 18240, 816, 1144, 705, 15947, 11, 584, 636, 1473, 79145, 816, 1144, 15487, 220, 605, 489, 220, 18, 284, 220, 18, 1144, 15487, 220, 605, 489, 816, 482, 220, 24, 1144, 2595, 50, 6517, 7922, 279, 24524, 1473, 79145, 220, 605, 56, 489, 220, 18, 284, 220, 966, 489, 816, 482, 220, 24, 1144, 2595, 79145, 220, 605, 56, 489, 220, 18, 284, 816, 489, 220, 1691, 1144, 2595, 3214, 2193, 18240, 816, 1144, 8, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 489, 220, 18, 284, 220, 1691, 1144, 2595, 3214, 2193, 220, 18, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 284, 220, 972, 1144, 2595, 12792, 579, 2225, 11314, 555, 220, 24, 1473, 79145, 816, 284, 220, 17, 1144, 2595, 4516, 279, 6305, 2035, 16099, 374]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.988170Z","iopub.execute_input":"2024-12-14T09:33:30.988526Z","iopub.status.idle":"2024-12-14T09:33:30.994187Z","shell.execute_reply.started":"2024-12-14T09:33:30.988500Z","shell.execute_reply":"2024-12-14T09:33:30.993331Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:30.995126Z","iopub.execute_input":"2024-12-14T09:33:30.995795Z","iopub.status.idle":"2024-12-14T09:33:31.004445Z","shell.execute_reply.started":"2024-12-14T09:33:30.995756Z","shell.execute_reply":"2024-12-14T09:33:31.003718Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:31.005242Z","iopub.execute_input":"2024-12-14T09:33:31.005490Z","iopub.status.idle":"2024-12-14T09:33:31.014960Z","shell.execute_reply.started":"2024-12-14T09:33:31.005468Z","shell.execute_reply":"2024-12-14T09:33:31.014324Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:31.015835Z","iopub.execute_input":"2024-12-14T09:33:31.016092Z","iopub.status.idle":"2024-12-14T09:33:31.025392Z","shell.execute_reply.started":"2024-12-14T09:33:31.016069Z","shell.execute_reply":"2024-12-14T09:33:31.024784Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 32\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n\n#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:31.026364Z","iopub.execute_input":"2024-12-14T09:33:31.026889Z","iopub.status.idle":"2024-12-14T09:33:31.036556Z","shell.execute_reply.started":"2024-12-14T09:33:31.026862Z","shell.execute_reply":"2024-12-14T09:33:31.035646Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:31.037477Z","iopub.execute_input":"2024-12-14T09:33:31.037756Z","iopub.status.idle":"2024-12-14T09:33:32.378199Z","shell.execute_reply.started":"2024-12-14T09:33:31.037730Z","shell.execute_reply":"2024-12-14T09:33:32.377322Z"}},"outputs":[{"name":"stdout","text":"trainable params: 83,886,080 || all params: 8,114,147,328 || trainable%: 1.0338\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:32.379743Z","iopub.execute_input":"2024-12-14T09:33:32.380120Z","iopub.status.idle":"2024-12-14T09:33:32.396086Z","shell.execute_reply.started":"2024-12-14T09:33:32.380080Z","shell.execute_reply":"2024-12-14T09:33:32.395079Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4624486400\nTrainable parameters : 83886080\nTrainable percentage: 1.81%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:32.397074Z","iopub.execute_input":"2024-12-14T09:33:32.397416Z","iopub.status.idle":"2024-12-14T09:33:32.410779Z","shell.execute_reply.started":"2024-12-14T09:33:32.397378Z","shell.execute_reply":"2024-12-14T09:33:32.409786Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 1\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:32.411882Z","iopub.execute_input":"2024-12-14T09:33:32.412205Z","iopub.status.idle":"2024-12-14T09:33:32.461025Z","shell.execute_reply.started":"2024-12-14T09:33:32.412168Z","shell.execute_reply":"2024-12-14T09:33:32.460167Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec14_09-33-32_9bb16ce33c9a,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:32.461926Z","iopub.execute_input":"2024-12-14T09:33:32.462235Z","iopub.status.idle":"2024-12-14T09:33:34.285227Z","shell.execute_reply.started":"2024-12-14T09:33:32.462201Z","shell.execute_reply":"2024-12-14T09:33:34.284511Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7e4d8016bcd0>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T09:33:34.286193Z","iopub.execute_input":"2024-12-14T09:33:34.286789Z","iopub.status.idle":"2024-12-14T10:40:40.281069Z","shell.execute_reply.started":"2024-12-14T09:33:34.286759Z","shell.execute_reply":"2024-12-14T10:40:40.280343Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 1\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 83,886,080\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241214_093335-1mx5grvj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/1mx5grvj' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/1mx5grvj' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/1mx5grvj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:06:52, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.894900</td>\n      <td>0.854091</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.813000</td>\n      <td>0.738494</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.729300</td>\n      <td>0.685429</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.713300</td>\n      <td>0.667226</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.677700</td>\n      <td>0.655866</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.656300</td>\n      <td>0.647647</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.667100</td>\n      <td>0.643100</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.701800</td>\n      <td>0.640452</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.662900</td>\n      <td>0.639005</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.651200</td>\n      <td>0.638745</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.7167433500289917, metrics={'train_runtime': 4025.5365, 'train_samples_per_second': 0.199, 'train_steps_per_second': 0.05, 'total_flos': 1.41423148007424e+16, 'train_loss': 0.7167433500289917, 'epoch': 0.08888888888888889})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:40:40.282455Z","iopub.execute_input":"2024-12-14T10:40:40.282823Z","iopub.status.idle":"2024-12-14T10:44:00.853441Z","shell.execute_reply.started":"2024-12-14T10:40:40.282783Z","shell.execute_reply":"2024-12-14T10:44:00.852636Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:16]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.6387450695037842, 'eval_runtime': 200.5583, 'eval_samples_per_second': 0.997, 'eval_steps_per_second': 0.249, 'epoch': 0.08888888888888889}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:44:00.854551Z","iopub.execute_input":"2024-12-14T10:44:00.854829Z","iopub.status.idle":"2024-12-14T10:44:03.364768Z","shell.execute_reply.started":"2024-12-14T10:44:00.854802Z","shell.execute_reply":"2024-12-14T10:44:03.364025Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"akjindal53244/Llama-3.1-Storm-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"akjindal53244/Llama-3.1-Storm-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:44:03.365959Z","iopub.execute_input":"2024-12-14T10:44:03.366325Z","iopub.status.idle":"2024-12-14T10:44:03.509578Z","shell.execute_reply.started":"2024-12-14T10:44:03.366264Z","shell.execute_reply":"2024-12-14T10:44:03.508625Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:44:03.510618Z","iopub.execute_input":"2024-12-14T10:44:03.510891Z","iopub.status.idle":"2024-12-14T10:44:03.523444Z","shell.execute_reply.started":"2024-12-14T10:44:03.510860Z","shell.execute_reply":"2024-12-14T10:44:03.522634Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:44:03.524206Z","iopub.execute_input":"2024-12-14T10:44:03.524534Z","iopub.status.idle":"2024-12-14T10:44:04.876057Z","shell.execute_reply.started":"2024-12-14T10:44:03.524490Z","shell.execute_reply":"2024-12-14T10:44:04.875076Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:44:04.877267Z","iopub.execute_input":"2024-12-14T10:44:04.877629Z","iopub.status.idle":"2024-12-14T10:45:28.423558Z","shell.execute_reply.started":"2024-12-14T10:44:04.877592Z","shell.execute_reply":"2024-12-14T10:45:28.422736Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"unsloth/Llama-3.1-Storm-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/model.safetensors.index.json\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ]\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96afcaaeea69499aa6d6e476713c652b"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/Llama-3.1-Storm-8B.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Storm-8B/snapshots/c188a08c7c76efb020e557647470d0f448ffe883/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.424736Z","iopub.execute_input":"2024-12-14T10:45:28.425006Z","iopub.status.idle":"2024-12-14T10:45:28.435229Z","shell.execute_reply.started":"2024-12-14T10:45:28.424980Z","shell.execute_reply":"2024-12-14T10:45:28.434345Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4540600320\nTrainable parameters : 1050939392\nTrainable percentage: 23.15%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.436433Z","iopub.execute_input":"2024-12-14T10:45:28.436785Z","iopub.status.idle":"2024-12-14T10:45:28.467896Z","shell.execute_reply.started":"2024-12-14T10:45:28.436747Z","shell.execute_reply":"2024-12-14T10:45:28.467087Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.468869Z","iopub.execute_input":"2024-12-14T10:45:28.469104Z","iopub.status.idle":"2024-12-14T10:45:28.497654Z","shell.execute_reply.started":"2024-12-14T10:45:28.469080Z","shell.execute_reply":"2024-12-14T10:45:28.496749Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4708372480\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.498775Z","iopub.execute_input":"2024-12-14T10:45:28.499307Z","iopub.status.idle":"2024-12-14T10:45:28.508332Z","shell.execute_reply.started":"2024-12-14T10:45:28.499267Z","shell.execute_reply":"2024-12-14T10:45:28.507586Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.509191Z","iopub.execute_input":"2024-12-14T10:45:28.509481Z","iopub.status.idle":"2024-12-14T10:45:28.519016Z","shell.execute_reply.started":"2024-12-14T10:45:28.509457Z","shell.execute_reply":"2024-12-14T10:45:28.518311Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.520137Z","iopub.execute_input":"2024-12-14T10:45:28.520909Z","iopub.status.idle":"2024-12-14T10:45:28.529612Z","shell.execute_reply.started":"2024-12-14T10:45:28.520868Z","shell.execute_reply":"2024-12-14T10:45:28.528805Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:45:28.530506Z","iopub.execute_input":"2024-12-14T10:45:28.530787Z","iopub.status.idle":"2024-12-14T10:47:32.548463Z","shell.execute_reply.started":"2024-12-14T10:45:28.530762Z","shell.execute_reply":"2024-12-14T10:47:32.547521Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\n### Question: What is the volume in cubic           |  ### Question: What is the volume in cubic         \ncentimeters (cm3) of a cube with a surface area of  |  centimeters (cm3) of a cube with a surface area of\n150 square centimeters (cm2)? ### Answer: To find   |  150 square centimeters (cm2)? ### Answer: To find \nthe volume of a cube when given the surface area,   |  the volume of a cube when given the surface area, \nwe need to understand the formulas for both the     |  we can use the formula for the surface area of a  \nsurface area and volume of a cube. The surface      |  cube, which is \\(6a^2\\), where \\(a\\) is the length\narea (SA) of a cube is given by the formula: \\[ SA  |  of a side of the cube. Given that the surface area\n= 6s^2 \\] where \\( s \\) is the length of a side of  |  is 150 cm2, we can set up the equation: \\[6a^2 =  \nthe cube. The volume (V) of a cube is given by the  |  150\\] To solve for \\(a\\), we divide both sides by \nformula: \\[ V = s^3 \\] Given that the surface area  |  6: \\[a^2 = \\frac{150}{6}\\] \\[a^2 = 25\\] Taking the\nis 150 cm², we can set up the equation: \\[ 150 =    |  square root of both sides gives us: \\[a = 5\\] Now \n6s^2 \\] To find \\( s \\), we divide both sides by    |  that we know the length of a side of the cube is 5\n6: \\[ 25 = s^2 \\] Taking the square root of both    |  cm, we can find the volume using the formula for  \nsides gives us: \\[ s = 5 \\, \\text{cm} \\] Now that   |  the volume of a cube, which is \\(a^3\\): \\[V =     \nwe know the length of a side is 5 cm, we can find   |  a^3\\] \\[V = 5^3\\] \\[V = 125\\] Therefore, the      \nthe volume: \\[ V = s^3 = 5^3 = 125 \\, \\text{cm}^3   |  volume of the cube is 125 cubic centimeters (cm3).\n\\] Therefore, the volume of the cube is 125 cubic   |  This solution assumes that the surface area given \ncentimeters.                                        |  is for a single face of the cube, which is not    \n                                                    |  explicitly stated in the question. However, the   \n                                                    |  provided solution is correct under the assumption \n                                                    |  that the surface area given is for the entire     \n                                                    |  cube. If the surface area given is for a single   \n                                                    |  face, the calculation would be different.   In the\n                                                    |  context of the question, it seems more likely that\n                                                    |  the surface area given is for the entire cube, as \n                                                    |  the question asks for the volume of the cube. If  \n                                                    |  the surface area given is for a single face, the  \n                                                    |  question would need to be clarified or rephrased  \n                                                    |  for the solution to be accurate.   Given the      \n                                                    |  information and the context, the provided solution\n                                                    |  is correct. However, it's crucial to clarify the  \n                                                    |  assumption about the surface area being for the   \n                                                    |  entire cube or a single face to ensure the        \n                                                    |  accuracy of the solution.   The final answer is:  \n                                                    |  $\\boxed{125}$ ### Question: What is the volume in \n                                                    |  cubic centimeters (cm3) of a cube with a surface  \n                                                    |  area of 150 square centimeters (cm2)? ### Answer: \n                                                    |  To find the volume of a cube when given the       \n                                                    |  surface area, we can use the formula for the      \n                                                    |  surface area of a cube, which is \\(6a^2\\), where  \n                                                    |  \\(a\\) is the length of a side of the cube. Given  \n                                                    |  that the surface area is 150 cm2, we can set up   \n                                                    |  the equation: \\[6a^2 = 150\\] To solve for \\(a\\),  \n                                                    |  we divide both sides by 6: \\[a^2 = \\frac{150}{6}\\]\n                                                    |  \\[a^2 = 25\\] Taking the square root of both sides \n                                                    |  gives us: \\[a = 5\\] Now that we know the length of\n                                                    |  a side of the cube is 5 cm, we can find the volume\n                                                    |  using the formula for the volume of a cube, which \n                                                    |  is \\(a^3\\): \\[V = a^3\\] \\[V = 5^3\\] \\[V = 125\\]   \n                                                    |  Therefore, the volume of the cube is 125 cubic    \n                                                    |  centimeters (cm3).   This solution assumes that   \n                                                    |  the surface area given is for a single face of the\n                                                    |  cube, which is not explicitly stated in the       \n                                                    |  question. However, the provided solution is       \n                                                    |  correct under the assumption that the surface area\n                                                    |  given is for the entire cube. If the surface area \n                                                    |  given is for a single face, the calculation would \n                                                    |  be different.   In the context of the question, it\n                                                    |  seems more likely that the surface area given is  \n                                                    |  for the entire cube, as the question asks for the \n                                                    |  volume of the cube. If the surface area given is  \n                                                    |  for a single face, the question would need to be  \n                                                    |  clarified or rephrased for the solution to be     \n                                                    |  accurate.   Given the information and the context,\n                                                    |  the provided solution is correct. However, it's   \n                                                    |  crucial to clarify the assumption about the       \n                                                    |  surface area being for the entire cube or a single\n                                                    |  face to ensure the accuracy of the solution.   The\n                                                    |  final answer is: $\\boxed{125}$ ### Question: What \n                                                    |  is the volume in cubic centimeters (cm3) of a cube\n                                                    |  with a surface area of 150 square centimeters     \n                                                    |  (cm2)? ### Answer: To find the volume of a cube   \n                                                    |  when given the surface area, we can use the       \n                                                    |  formula for the surface area of a cube, which is  \n                                                    |  \\(6a^2\\), where \\(a\\) is the length of a side of  \n                                                    |  the cube. Given that the surface area is 150 cm2, \n                                                    |  we can set up the equation: \\[6a^2 = 150\\] To     \n                                                    |  solve for \\(a\\), we divide both sides by 6: \\[a^2 \n                                                    |  = \\frac{150}{6}\\] \\[a^2 = 25\\] Taking the square  \n                                                    |  root of both sides gives us: \\[a = 5\\] Now that we\n                                                    |  know the length of a side of the cube is 5 cm, we \n                                                    |  can find the volume using the formula for the     \n                                                    |  volume of a cube                                  \n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T10:56:38.444396Z","iopub.execute_input":"2024-12-14T10:56:38.445137Z","iopub.status.idle":"2024-12-14T10:58:20.625056Z","shell.execute_reply.started":"2024-12-14T10:56:38.445106Z","shell.execute_reply":"2024-12-14T10:58:20.624227Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\n### Question: There is the expression 691-6A7=4.    |  ### Question: There is the expression 691-6A7=4.  \nFind the number that goes into A ### Answer: To     |  Find the number that goes into A ### Answer: To   \nsolve this expression, we need to follow the order  |  solve this expression, we need to follow the order\nof operations (PEMDAS/BODMAS), which means we       |  of operations (PEMDAS/BODMAS), which means we     \nperform the subtraction first and then the          |  perform the subtraction first and then the        \ndivision. However, the expression given is not a    |  division. However, the expression given is not a  \nstandard mathematical expression but rather a       |  standard mathematical expression but rather a     \npuzzle or a riddle. It seems to be asking for a     |  puzzle or a riddle. It seems to be asking for a   \nvalue of A that makes the expression true.  Let's   |  value of A that makes the expression true.  Let's \nbreak down the expression:  691 - 6A7 = 4  We can   |  break down the expression:  691 - 6A7 = 4  We can \nrewrite this expression as:  691 - 600 - 70 + A7 =  |  rewrite this expression as:  691 - 600 - 70 - 7A =\n4  Now, let's simplify it:  31 - 70 + A7 = 4  -39   |  4  Now, let's simplify it:  31 - 7A = 4  To       \n+ A7 = 4  To make the equation true, we need to     |  isolate A, we'll move 31 to the other side:  -7A =\nadd 39 to both sides:  A7 = 43  Now, we need to     |  4 - 31  -7A = -27  Now, divide both sides by -7:  \nfind the value of A that makes A7 equal to 43.      |  A = -27 / -7  A = 3  So, the value of A that makes\nSince A is a single digit, we can try different     |  the expression true is 3. However, this is a      \nvalues of A to find the correct one:  A = 1, A7 =   |  mathematical solution, and the question seems to  \n17 (not equal to 43) A = 2, A7 = 27 (not equal to   |  be asking for a more abstract or puzzle-like      \n43) A = 3, A7 = 37 (not equal to 43) A = 4, A7 =    |  answer. If we interpret the question as looking   \n47 (not equal to 43) A = 5, A7 = 57 (not equal to   |  for a number that fits the expression in a more   \n43) A = 6, A7 = 67 (not equal to 43) A = 7, A7 =    |  creative or puzzle-like sense, we might consider  \n77 (not equal to 43) A = 8, A7 = 87 (not equal to   |  the expression as a riddle or a play on words.  In\n43) A = 9, A7 = 97 (not equal to 43)  However, if   |  this case, the expression could be seen as a      \nwe consider the expression as a whole number, we    |  clever way of representing a subtraction problem, \ncan see that the expression is not solvable with a  |  where the numbers are rearranged to create a      \nsingle digit A. The expression seems to be          |  clever puzzle. The answer, in this case, would    \nincorrect or incomplete.  If we assume that the     |  still be 3, but it would be a more abstract or    \nexpression is meant to be a simple subtraction or   |  creative solution.  If you could provide more     \naddition problem, we can try to find a value of A   |  context or clarify the nature of the question, I'd\nthat makes the expression true:  691 - 6A7 = 4  We  |  be happy to provide a more tailored answer.       \ncan rewrite this expression as:  691 - 600 - 70 +   |  However, based on the information provided, the   \nA7 = 4  Now, let's simplify it:  31 - 70 + A7 = 4   |  value of A that makes the expression true is 3.   \n-39 + A7 = 4  To make the equation true, we need    |                                                    \nto add 39 to both sides:  A7 = 43  Since A is a     |                                                    \nsingle digit, we can try different values of A to   |                                                    \nfind the correct one:  A = 1, A7 = 17 (not equal    |                                                    \nto 43) A = 2, A7 = 27 (not equal to 43) A = 3, A7   |                                                    \n= 37 (not equal to 43) A = 4, A7 = 47 (not equal    |                                                    \nto 43) A = 5, A7 = 57 (not equal to 43) A = 6, A7   |                                                    \n= 67 (not equal to 43) A = 7, A7 = 77 (not equal    |                                                    \nto 43) A = 8, A7 = 87 (not equal to 43) A = 9, A7   |                                                    \n= 97 (not equal to 43)  However, if we consider     |                                                    \nthe expression as a whole number, we can see that   |                                                    \nthe expression is not solvable with a single digit  |                                                    \nA. The expression seems to be incorrect or          |                                                    \nincomplete.  If we assume that the expression is    |                                                    \nmeant to be a simple subtraction or addition        |                                                    \nproblem, we can try to find a value of A that       |                                                    \nmakes the expression true:  691 - 6A7 = 4  We can   |                                                    \nrewrite this expression as:  691 - 600 - 70 + A7 =  |                                                    \n4  Now, let's simplify it:  31 - 70 + A7 = 4  -39   |                                                    \n+ A7 = 4  To make the equation true, we need to     |                                                    \nadd 39 to both sides:  A7 = 43  Since A is a        |                                                    \nsingle digit, we can try different values of A to   |                                                    \nfind the correct one:  A = 1, A7 = 17 (not equal    |                                                    \nto 43) A = 2, A7 = 27 (not equal to 43) A = 3, A7   |                                                    \n= 37 (not equal to 43) A = 4, A7 = 47 (not equal    |                                                    \nto 43) A = 5, A7 = 57 (not equal to 43) A = 6, A7   |                                                    \n= 67 (not equal to 43) A = 7, A7 = 77 (not equal    |                                                    \nto 43) A = 8, A7 = 87 (not equal to 43) A = 9, A7   |                                                    \n= 97 (not equal to 43)  However, if we consider     |                                                    \nthe expression as a whole number, we can see that   |                                                    \nthe expression is not solvable with a single digit  |                                                    \nA. The expression seems to                          |                                                    \n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T12:26:30.750579Z","iopub.execute_input":"2024-12-14T12:26:30.751334Z","iopub.status.idle":"2024-12-14T12:29:24.416179Z","shell.execute_reply.started":"2024-12-14T12:26:30.751294Z","shell.execute_reply":"2024-12-14T12:29:24.415331Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\n### Question: A cleaning company produces two       |  ### Question: A cleaning company produces two     \nsanitizer sprays. One spray kills 50% of germs,     |  sanitizer sprays. One spray kills 50% of germs,   \nand another spray kills 25% of germs. However, a    |  and another spray kills 25% of germs. However, a  \ncertain percentage of the germs they kill are the   |  certain percentage of the germs they kill are the \nsame ones. After using both sanitizer sprays        |  same ones. After using both sanitizer sprays      \ntogether, 30% of germs would be left. What          |  together, 30% of germs would be left. What        \npercentage of germs do both sprays kill in common?  |  percentage of germs do both sprays kill in common?\n### Answer: Let's denote the percentage of germs    |  ### Answer: Let's denote the percentage of germs  \nkilled by the first spray as A and the second       |  killed by the first spray as A and the second     \nspray as B. We know that A = 50% and B = 25%. We    |  spray as B. We know that A = 50% and B = 25%. We  \nalso know that after using both sprays together,    |  also know that after using both sprays together,  \n30% of germs would be left. This means that the     |  30% of germs would be left. This means that the   \ntotal percentage of germs killed by both sprays is  |  total percentage of germs killed by both sprays is\n100% - 30% = 70%. However, since the first spray    |  100% - 30% = 70%. However, since the first spray  \nkills 50% of germs and the second spray kills 25%   |  kills 50% of germs and the second spray kills 25% \nof germs, the total percentage of germs killed by   |  of germs, the total percentage of germs killed by \nboth sprays, without considering the overlap, is    |  both sprays is A + B - (the percentage of germs   \n50% + 25% = 75%. This means that the percentage of  |  killed in common). Therefore, we can set up the   \ngerms killed by both sprays in common is 75% - 70%  |  equation A + B - (the percentage of germs killed  \n= 5%. Therefore, both sprays kill 5% of germs in    |  in common) = 70%. Substituting A = 50% and B =    \ncommon. ### Explanation: To solve this problem, we  |  25%, we get 50% + 25% - (the percentage of germs  \nneed to use the principle of inclusion-exclusion.   |  killed in common) = 70%. Simplifying the equation,\nThe principle of inclusion-exclusion states that    |  we get 75% - (the percentage of germs killed in   \nfor two sets A and B, the size of the union of the  |  common) = 70%. Subtracting 75% from both sides, we\ntwo sets is equal to the sum of their sizes minus   |  get -(the percentage of germs killed in common) = \nthe size of their intersection. In this case, the   |  -5%. Multiplying both sides by -1, we get the     \nsets A and B represent the germs killed by the      |  percentage of germs killed in common = 5%.        \nfirst and second sprays, respectively. The size of  |  Therefore, both sprays kill 5% of germs in common.\nthe union of the two sets represents the total      |  The answer is 5%.### Step 1: Define the problem   \npercentage of germs killed by both sprays, which    |  and the variables. We are given two sanitizer     \nis 70%. The sizes of the sets A and B represent     |  sprays, one killing 50% of germs and the other    \nthe percentages of germs killed by the first and    |  killing 25% of germs. We need to find the         \nsecond sprays, which are 50% and 25%,               |  percentage of germs that both sprays kill in      \nrespectively. The size of the intersection of the   |  common, given that after using both sprays        \ntwo sets represents the percentage of germs killed  |  together, 30% of germs would be left.  ### Step 2:\nby both sprays in common, which we need to find.    |  Set up the equation to solve for the percentage of\n### Code: ```python # Define the percentages of     |  germs killed in common. Let's denote the          \ngerms killed by the first and second sprays A = 50  |  percentage of germs killed in common as x. We know\nB = 25  # Calculate the total percentage of germs   |  that the first spray kills 50% of germs (A = 50%) \nkilled by both sprays total_killed = A + B  #       |  and the second spray kills 25% of germs (B = 25%).\nCalculate the percentage of germs killed by both    |  The total percentage of germs killed by both      \nsprays in common common_killed = total_killed - 70  |  sprays is 100% - 30% = 70%. However, since the    \nprint(common_killed) ``` ### Output: ``` 5          |  first spray kills 50% of germs and the second     \n```python # Define the percentages of germs killed  |  spray kills 25% of germs, the total percentage of \nby the first and second sprays A = 50 B = 25  #     |  germs killed by both sprays is A + B - x.         \nCalculate the total percentage of germs killed by   |  Therefore, we can set up the equation A + B - x = \nboth sprays total_killed = A + B  # Calculate the   |  70%.  ### Step 3: Substitute the given values into\npercentage of germs killed by both sprays in        |  the equation and solve for x. Substituting A = 50%\ncommon common_killed = total_killed - 70            |  and B = 25% into the equation, we get 50% + 25% - \nprint(common_killed) ``` ### Output: ``` 5          |  x = 70%. Simplifying the equation, we get 75% - x \n```python # Define the percentages of germs killed  |  = 70%. Subtracting 75% from both sides, we get -x \nby the first and second sprays A = 50 B = 25  #     |  = -5%. Multiplying both sides by -1, we get x =   \nCalculate the total percentage of germs killed by   |  5%.  The final answer is: $\\boxed{5}$### Step 1:  \nboth sprays total_killed = A + B  # Calculate the   |  Define the problem and the variables. We are given\npercentage of germs killed by both sprays in        |  two sanitizer sprays, one killing 50% of germs and\ncommon common_killed = total_killed - 70            |  the other killing 25% of germs. We need to find   \nprint(common_killed) ``` ### Output: ``` 5          |  the percentage of germs that both sprays kill in  \n```python # Define the percentages of germs killed  |  common, given that after using both sprays        \nby the first and second sprays A = 50 B = 25  #     |  together, 30% of germs would be left.  ### Step 2:\nCalculate the total percentage of germs killed by   |  Set up the equation to solve for the percentage of\nboth sprays total_killed = A + B  # Calculate the   |  germs killed in common. Let's denote the          \npercentage of germs killed by both sprays in        |  percentage of germs killed in common as x. We know\ncommon common_killed = total_killed - 70            |  that the first spray kills 50% of germs (A = 50%) \nprint(common_killed) ``` ### Output: ``` 5          |  and the second spray kills 25% of germs (B = 25%).\n```python # Define the percentages of germs killed  |  The total percentage of germs killed by both      \nby the first and second sprays A = 50 B = 25  #     |  sprays is 100% - 30% = 70%. However, since the    \nCalculate the total percentage of germs killed by   |  first spray kills 50% of germs and the second     \nboth sprays total_killed = A + B  # Calculate the   |  spray kills 25% of germs, the total percentage of \npercentage of germs killed by both sprays in        |  germs killed by both sprays is A + B - x.         \ncommon common_killed = total_killed - 70            |  Therefore, we can set up the equation A + B - x = \nprint(common_killed) ``` ### Output: ``` 5          |  70%.  ### Step 3: Substitute the given values into\n```python # Define the percentages of germs killed  |  the equation and solve for x. Substituting A = 50%\nby the first and second sprays A = 50 B = 25  #     |  and B = 25% into the equation, we get 50% + 25% - \nCalculate the total percentage of germs killed by   |  x = 70%. Simplifying the equation, we get 75% - x \nboth sprays total_killed = A + B  # Calculate the   |  = 70%. Subtracting 75% from both sides, we get -x \npercentage of germs killed by both sprays in        |  = -5%. Multiplying both sides by -1, we get x =   \ncommon common_killed = total_killed - 70            |  5%.  The final answer is: $\\boxed{5}$### Step 1:  \nprint(common_killed) ``` ### Output: ``` 5          |  Define the problem and the variables. We are given\n```python # Define the percentages of germs killed  |  two sanitizer sprays, one killing 50% of germs and\nby the first and second sprays A = 50 B = 25  #     |  the other killing 25% of germs. We need to find   \nCalculate the total percentage of germs killed by   |  the percentage of germs that both sprays kill in  \nboth sprays total_killed = A + B  # Calculate the   |  common, given that after                          \npercentage of germs killed by both sprays in        |                                                    \ncommon common_killed = total_killed - 70            |                                                    \nprint(common_killed) ``` ### Output: ``` 5          |                                                    \n```python # Define the percentages of germs killed  |                                                    \nby the first and second sprays A = 50 B = 25  #     |                                                    \nCalculate the total                                 |                                                    \n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T12:51:55.165473Z","iopub.execute_input":"2024-12-14T12:51:55.166169Z","iopub.status.idle":"2024-12-14T12:54:48.772036Z","shell.execute_reply.started":"2024-12-14T12:51:55.166132Z","shell.execute_reply":"2024-12-14T12:54:48.771070Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\n### Question: There are 5 numbers, 3.4, 7/2, 1.7,   |  ### Question: There are 5 numbers, 3.4, 7/2, 1.7, \n27/10, 2.9. What is the smallest number including   |  27/10, 2.9. What is the smallest number including \nthe decimal point? ### Answer: To find the          |  the decimal point? ### Answer: The smallest number\nsmallest number, we need to compare the numbers     |  is 3.4. ### Step 1: Convert all numbers to decimal\ngiven. Since the numbers are mixed (some are        |  form for comparison. First, we convert all the    \ndecimals and some are fractions), we can convert    |  given numbers into decimal form to make comparison\nall of them to decimals to make the comparison      |  easier. The numbers are 3.4, 3.5, 1.7, 2.7, and   \neasier. 3.4 = 3.4 7/2 = 3.5 1.7 = 1.7 27/10 = 2.7   |  2.9.  ### Step 2: Compare the decimal numbers.    \n2.9 = 2.9 Now, we can see that the smallest number  |  Now, we compare these decimal numbers to find the \nis 2.7. Therefore, the answer is 27/10.   ###       |  smallest one. Starting from the left, we compare  \nCode: ```python def find_smallest_number():         |  the whole numbers and then the decimal parts if   \n\"\"\"     This function finds the smallest number     |  the whole numbers are equal.  ### Step 3:         \namong the given numbers.          Parameters:       |  Determine the smallest number. Among the given    \nNone          Returns:     The smallest number as   |  numbers, 1.7 is the smallest when considering only\na float.     \"\"\"     numbers = [3.4, 7/2, 1.7,      |  the whole number part. However, when looking at   \n27/10, 2.9]     smallest_number = min(numbers)      |  the decimal part as well, 1.7 is indeed smaller   \nreturn smallest_number  # Test the function         |  than 3.4, but since we are asked for the smallest \nprint(find_smallest_number()) ```  ###              |  number including the decimal point among the given\nExplanation: The code defines a function            |  options, we need to compare all options correctly.\n`find_smallest_number()` that takes no arguments    |  ### Step 4: Correct the comparison. Upon reviewing\nand returns the smallest number among the given     |  the comparison, it's clear that the correct       \nnumbers. The function uses the built-in `min()`     |  smallest number among the given options is indeed \nfunction in Python to find the smallest number in   |  1.7, not 3.4 as initially concluded in the answer.\nthe list. The result is then printed to the         |  The correct sequence from smallest to largest is  \nconsole.  ### Example Use Case: To find the         |  1.7, 2.7, 2.9, 3.4, and 3.5.  The final answer is:\nsmallest number among the given numbers, we can     |  $\\boxed{1.7}$ ### Step 1: Convert all numbers to  \ncall the function `find_smallest_number()` and      |  decimal form for comparison. First, we convert all\nprint the result. The output will be the smallest   |  the given numbers into decimal form to make       \nnumber, which is 27/10 or 2.7.   ### Note: The      |  comparison easier. The numbers are 3.4, 3.5, 1.7, \ncode assumes that the input numbers are already     |  2.7, and 2.9.  ### Step 2: Compare the decimal    \nprovided as a list. If the numbers are provided in  |  numbers. Now, we compare these decimal numbers to \na different format, the code may need to be         |  find the smallest one. Starting from the left, we \nmodified accordingly. Additionally, the code does   |  compare the whole numbers and then the decimal    \nnot handle cases where the input list is empty or   |  parts if the whole numbers are equal.  ### Step 3:\ncontains non-numeric values. Depending on the       |  Determine the smallest number. Among the given    \nrequirements, the code may need to be modified to   |  numbers, 1.7 is the smallest when considering only\nhandle these cases.   ### Step-by-Step Solution:    |  the whole number part. However, when looking at   \n1. Define a function `find_smallest_number()` that  |  the decimal part as well, 1.7 is indeed smaller   \ntakes no arguments. 2. Create a list `numbers`      |  than 3.4, but since we are asked for the smallest \ncontaining the given numbers. 3. Use the `min()`    |  number including the decimal point among the given\nfunction to find the smallest number in the list.   |  options, we need to compare all options correctly.\n4. Return the smallest number. 5. Call the          |  ### Step 4: Correct the comparison. Upon reviewing\nfunction and print the result.   ### Step-by-Step   |  the comparison, it's clear that the correct       \nExplanation: 1. The function                        |  smallest number among the given options is indeed \n`find_smallest_number()` is defined to find the     |  1.7, not 3.4 as initially concluded in the answer.\nsmallest number among the given numbers. 2. A list  |  The correct sequence from smallest to largest is  \n`numbers` is created containing the given numbers:  |  1.7, 2.7, 2.9, 3.4, and 3.5.  The final answer is:\n3.4, 7/2, 1.7, 27/10, 2.9. 3. The `min()` function  |  $\\boxed{1.7}$ ### Step 1: Convert all numbers to  \nis used to find the smallest number in the list.    |  decimal form for comparison. First, we convert all\nThe `min()` function returns the smallest item in   |  the given numbers into decimal form to make       \nan iterable or the smallest of two or more          |  comparison easier. The numbers are 3.4, 3.5, 1.7, \narguments. 4. The smallest number is returned by    |  2.7, and 2.9.  ### Step 2: Compare the decimal    \nthe function. 5. The function is called and the     |  numbers. Now, we compare these decimal numbers to \nresult is printed to the console.   ### Step-by-    |  find the smallest one. Starting from the left, we \nStep Code: ```python def find_smallest_number():    |  compare the whole numbers and then the decimal    \nnumbers = [3.4, 7/2, 1.7, 27/10, 2.9]               |  parts if the whole numbers are equal.  ### Step 3:\nsmallest_number = min(numbers)     return           |  Determine the smallest number. Among the given    \nsmallest_number  smallest_number =                  |  numbers, 1.7 is the smallest when considering only\nfind_smallest_number() print(smallest_number) ```   |  the whole number part. However, when looking at   \n### Step-by-Step Output: The output of the code     |  the decimal part as well, 1.7 is indeed smaller   \nwill be the smallest number among the given         |  than 3.4, but since we are asked for the smallest \nnumbers, which is 27/10 or 2.7.   ### Step-by-Step  |  number including the decimal point among the given\nError Handling: If the input list is empty or       |  options, we need to compare all options correctly.\ncontains non-numeric values, the code may raise an  |  ### Step 4: Correct the comparison. Upon reviewing\nerror. Depending on the requirements, the code may  |  the comparison, it's clear that the correct       \nneed to be modified to handle these cases.   ###    |  smallest number among the given options is indeed \nStep-by-Step Debugging: To debug the code, we can   |  1.7, not 3.4 as initially concluded in the answer.\nadd print statements to display the values of       |  The correct sequence from smallest to largest is  \nvariables at different points in the code. We can   |  1.7, 2.7, 2.9, 3.4, and 3.5.  The final answer is:\nalso use a debugger to step through the code and    |  $\\boxed{1.7}$ ### Step 1: Convert all numbers to  \nexamine the values of variables.   ### Step-by-     |  decimal form for comparison. First, we convert all\nStep Testing: To test the code, we can use test     |  the given numbers into decimal form to make       \ncases to verify that the function returns the       |  comparison easier. The numbers are 3.4, 3.5, 1.7, \ncorrect result for different input values. We can   |  2.7, and 2.9.  ### Step 2: Compare the decimal    \nalso use a testing framework to write and run       |  numbers. Now, we compare these decimal numbers to \ntests for the code.   ### Step-by-Step              |  find the smallest one. Starting from the left, we \nRefactoring: To refactor the code, we can simplify  |  compare the whole numbers and then the decimal    \nthe code by removing unnecessary variables or       |  parts if the whole numbers are equal.  ### Step 3:\nfunctions. We can also improve the code by using    |  Determine the smallest number. Among the given    \nmore efficient algorithms or data structures.       |  numbers, 1.7 is the smallest when considering only\n### Step-by-Step Optimization: To optimize the      |  the whole number part. However, when looking at   \ncode, we can use more efficient algorithms or data  |  the decimal part as well, 1.7 is indeed smaller   \nstructures. We can also use caching or memoization  |  than 3.4, but since we are asked for the smallest \nto reduce the number of computations.   ### Step-   |  number including the decimal point among the given\nby-Step Security: To ensure the security of the     |  options, we need to compare all options correctly.\ncode, we can validate user input to prevent         |  ### Step 4: Correct                               \nmalicious data from being processed. We can also    |                                                    \nuse secure coding practices to prevent common       |                                                    \nsecurity vulnerabilities.   ### Step-by-Step        |                                                    \nPerformance: To improve the performance of the      |                                                    \ncode, we can use parallel processing or             |                                                    \nmultithreading to take advantage of multiple CPU    |                                                    \ncores. We can also use caching or memoization to    |                                                    \nreduce the number of computations.   ### Step       |                                                    \n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T13:21:21.223062Z","iopub.execute_input":"2024-12-14T13:21:21.223946Z","iopub.status.idle":"2024-12-14T13:22:57.751963Z","shell.execute_reply.started":"2024-12-14T13:21:21.223906Z","shell.execute_reply":"2024-12-14T13:22:57.750952Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4540600320                     |                     4708372480                    \n================================================== | ==================================================\n### Question: When 14 is divided by 3, the          |  ### Question: When 14 is divided by 3, the        \nquotient is A and the remainder is 2. Find A. ###   |  quotient is A and the remainder is 2. Find A. ### \nAnswer: ## Step 1: Recall the definition of         |  Answer: ## Step 1: Recall the definition of       \nquotient and remainder When a number is divided by  |  quotient and remainder When a number is divided by\nanother number, the quotient is the result of the   |  another number, the quotient is the result of the \ndivision, and the remainder is what is left over.   |  division, and the remainder is what is left over. \nIn this case, we are given that when 14 is divided  |  In this case, we are given that when 14 is divided\nby 3, the quotient is A and the remainder is 2.     |  by 3, the remainder is 2.  ## Step 2: Understand  \n## Step 2: Write down the division equation We can  |  the relationship between dividend, divisor,       \nrepresent the division of 14 by 3 as an equation:   |  quotient, and remainder The relationship between  \n14 = 3A + 2, where A is the quotient.  ## Step 3:   |  the dividend (the number being divided), the      \nSolve the equation for A To find the value of A,    |  divisor (the number by which we are dividing), the\nwe need to isolate A on one side of the equation.   |  quotient, and the remainder is given by the       \nFirst, subtract 2 from both sides of the equation:  |  formula: dividend = quotient * divisor +          \n14 - 2 = 3A. This simplifies to 12 = 3A.  ## Step   |  remainder.  ## Step 3: Apply the relationship to  \n4: Divide both sides by 3 to find A Now, divide     |  the given problem Given that the dividend is 14,  \nboth sides of the equation by 3 to solve for A: A   |  the divisor is 3, and the remainder is 2, we can  \n= 12 / 3.  ## Step 5: Calculate the value of A      |  plug these values into the formula to find the    \nPerform the division to find the value of A: A =    |  quotient (A). So, 14 = A * 3 + 2.  ## Step 4:     \n4.  The final answer is: $\\boxed{4}$ ### Question:  |  Solve for A To find A, we need to isolate it on   \nWhen 14 is divided by 3, the quotient is A and the  |  one side of the equation. First, subtract 2 from  \nremainder is 2. Find A. ### Answer: ## Step 1:      |  both sides of the equation: 14 - 2 = A * 3 + 2 -  \nRecall the definition of quotient and remainder     |  2, which simplifies to 12 = A * 3.  ## Step 5:    \nWhen a number is divided by another number, the     |  Continue solving for A Now, divide both sides of  \nquotient is the result of the division, and the     |  the equation by 3 to solve for A: 12 / 3 = A * 3 /\nremainder is what is left over. In this case, we    |  3, which simplifies to 4 = A.  The final answer   \nare given that when 14 is divided by 3, the         |  is: $\\boxed{4}$                                   \nquotient is A and the remainder is 2.  ## Step 2:   |                                                    \nWrite down the division equation We can represent   |                                                    \nthe division of 14 by 3 as an equation: 14 = 3A +   |                                                    \n2, where A is the quotient.  ## Step 3: Solve the   |                                                    \nequation for A To find the value of A, we need to   |                                                    \nisolate A on one side of the equation. First,       |                                                    \nsubtract 2 from both sides of the equation: 14 - 2  |                                                    \n= 3A. This simplifies to 12 = 3A.  ## Step 4:       |                                                    \nDivide both sides by 3 to find A Now, divide both   |                                                    \nsides of the equation by 3 to solve for A: A = 12   |                                                    \n/ 3.  ## Step 5: Calculate the value of A Perform   |                                                    \nthe division to find the value of A: A = 4.  The    |                                                    \nfinal answer is: $\\boxed{4}$ ### Question: When 14  |                                                    \nis divided by 3, the quotient is A and the          |                                                    \nremainder is 2. Find A. ### Answer: ## Step 1:      |                                                    \nRecall the definition of quotient and remainder     |                                                    \nWhen a number is divided by another number, the     |                                                    \nquotient is the result of the division, and the     |                                                    \nremainder is what is left over. In this case, we    |                                                    \nare given that when 14 is divided by 3, the         |                                                    \nquotient is A and the remainder is 2.  ## Step 2:   |                                                    \nWrite down the division equation We can represent   |                                                    \nthe division of 14 by 3 as an equation: 14 = 3A +   |                                                    \n2, where A is the quotient.  ## Step 3: Solve the   |                                                    \nequation for A To find the value of A, we need to   |                                                    \nisolate A on one side of the equation. First,       |                                                    \nsubtract 2 from both sides of the equation: 14 - 2  |                                                    \n= 3A. This simplifies to 12 = 3A.  ## Step 4:       |                                                    \nDivide both sides by 3 to find A Now, divide both   |                                                    \nsides of the equation by 3 to solve for A: A = 12   |                                                    \n/ 3.  ## Step 5: Calculate the value of A Perform   |                                                    \nthe division to find the value of A: A = 4.  The    |                                                    \nfinal answer is: $\\boxed{4}$ ### Question: When 14  |                                                    \nis divided by 3, the quotient is A and the          |                                                    \nremainder is 2. Find A. ### Answer: ## Step 1:      |                                                    \nRecall the definition of quotient and remainder     |                                                    \nWhen a number is divided by another number, the     |                                                    \nquotient is the result of the division, and the     |                                                    \nremainder is what is left over. In this case, we    |                                                    \nare given that when 14 is divided by 3, the         |                                                    \nquotient is A and the remainder is 2.  ## Step 2:   |                                                    \nWrite down the division equation We can represent   |                                                    \nthe division of 14 by 3 as an equation: 14 = 3A +   |                                                    \n2, where A is the quotient.  ## Step 3: Solve the   |                                                    \nequation for A To find the value of A, we need to   |                                                    \nisolate A on one side of the equation. First,       |                                                    \nsubtract 2 from both sides of the equation: 14 - 2  |                                                    \n= 3A. This simplifies to 12 = 3A.  ## Step 4:       |                                                    \nDivide both sides by 3 to find A Now, divide both   |                                                    \nsides                                               |                                                    \n","output_type":"stream"}],"execution_count":66}]}