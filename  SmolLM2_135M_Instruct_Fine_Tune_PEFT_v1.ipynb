{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/%20SmolLM2_135M_Instruct_Fine_Tune_PEFT_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:28:50.821437Z",
          "iopub.execute_input": "2024-11-17T01:28:50.821844Z",
          "iopub.status.idle": "2024-11-17T01:29:37.348400Z",
          "shell.execute_reply.started": "2024-11-17T01:28:50.821794Z",
          "shell.execute_reply": "2024-11-17T01:29:37.347304Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:37.350700Z",
          "iopub.execute_input": "2024-11-17T01:29:37.351047Z",
          "iopub.status.idle": "2024-11-17T01:29:45.683031Z",
          "shell.execute_reply.started": "2024-11-17T01:29:37.350999Z",
          "shell.execute_reply": "2024-11-17T01:29:45.682084Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:45.684447Z",
          "iopub.execute_input": "2024-11-17T01:29:45.684937Z",
          "iopub.status.idle": "2024-11-17T01:29:45.692586Z",
          "shell.execute_reply.started": "2024-11-17T01:29:45.684883Z",
          "shell.execute_reply": "2024-11-17T01:29:45.691392Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'HuggingFaceTB/SmolLM2-135M-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:45.693839Z",
          "iopub.execute_input": "2024-11-17T01:29:45.694176Z",
          "iopub.status.idle": "2024-11-17T01:29:45.701871Z",
          "shell.execute_reply.started": "2024-11-17T01:29:45.694144Z",
          "shell.execute_reply": "2024-11-17T01:29:45.700916Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:45.705189Z",
          "iopub.execute_input": "2024-11-17T01:29:45.705485Z",
          "iopub.status.idle": "2024-11-17T01:29:45.712911Z",
          "shell.execute_reply.started": "2024-11-17T01:29:45.705455Z",
          "shell.execute_reply": "2024-11-17T01:29:45.711927Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:45.713936Z",
          "iopub.execute_input": "2024-11-17T01:29:45.714262Z",
          "iopub.status.idle": "2024-11-17T01:29:54.793252Z",
          "shell.execute_reply.started": "2024-11-17T01:29:45.714231Z",
          "shell.execute_reply": "2024-11-17T01:29:54.792339Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:54.794496Z",
          "iopub.execute_input": "2024-11-17T01:29:54.794809Z",
          "iopub.status.idle": "2024-11-17T01:29:54.804630Z",
          "shell.execute_reply.started": "2024-11-17T01:29:54.794776Z",
          "shell.execute_reply": "2024-11-17T01:29:54.803765Z"
        },
        "outputId": "a3589c46-3b26-4a38-9980-9580a3faafed"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 81430848\nTrainable parameters : 28346688\nTrainable percentage: 34.81%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:54.805782Z",
          "iopub.execute_input": "2024-11-17T01:29:54.806098Z",
          "iopub.status.idle": "2024-11-17T01:29:56.150740Z",
          "shell.execute_reply.started": "2024-11-17T01:29:54.806065Z",
          "shell.execute_reply": "2024-11-17T01:29:56.149645Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'mlabonne/FineTome-100k'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:56.152156Z",
          "iopub.execute_input": "2024-11-17T01:29:56.152574Z",
          "iopub.status.idle": "2024-11-17T01:29:56.157546Z",
          "shell.execute_reply.started": "2024-11-17T01:29:56.152528Z",
          "shell.execute_reply": "2024-11-17T01:29:56.156530Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 1024"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:56.158620Z",
          "iopub.execute_input": "2024-11-17T01:29:56.158907Z",
          "iopub.status.idle": "2024-11-17T01:29:56.168432Z",
          "shell.execute_reply.started": "2024-11-17T01:29:56.158875Z",
          "shell.execute_reply": "2024-11-17T01:29:56.167569Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:56.169511Z",
          "iopub.execute_input": "2024-11-17T01:29:56.169829Z",
          "iopub.status.idle": "2024-11-17T01:29:57.705874Z",
          "shell.execute_reply.started": "2024-11-17T01:29:56.169797Z",
          "shell.execute_reply": "2024-11-17T01:29:57.704920Z"
        },
        "outputId": "6399fa4d-f888-46ba-fe15-4ed90e4a3498"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.707320Z",
          "iopub.execute_input": "2024-11-17T01:29:57.708208Z",
          "iopub.status.idle": "2024-11-17T01:29:57.715658Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.708144Z",
          "shell.execute_reply": "2024-11-17T01:29:57.714681Z"
        },
        "id": "aHk7eoWDUNX0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.717097Z",
          "iopub.execute_input": "2024-11-17T01:29:57.717584Z",
          "iopub.status.idle": "2024-11-17T01:29:57.745920Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.717539Z",
          "shell.execute_reply": "2024-11-17T01:29:57.745058Z"
        },
        "outputId": "da48267f-2a92-443b-c8e2-31a047236098"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.750205Z",
          "iopub.execute_input": "2024-11-17T01:29:57.750529Z",
          "iopub.status.idle": "2024-11-17T01:29:57.757142Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.750485Z",
          "shell.execute_reply": "2024-11-17T01:29:57.756088Z"
        },
        "outputId": "753eb7d9-9c7a-4a85-e470-b101212c1cd5"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.758240Z",
          "iopub.execute_input": "2024-11-17T01:29:57.758544Z",
          "iopub.status.idle": "2024-11-17T01:29:57.765680Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.758486Z",
          "shell.execute_reply": "2024-11-17T01:29:57.764625Z"
        },
        "outputId": "581c767e-a800-46a1-812b-603f936ea25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['conversations', 'source', 'score']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_conversations(example):\n",
        "  role_map = {\n",
        "    'human' : 'user',\n",
        "    'gpt' : 'assistant'\n",
        "  }\n",
        "\n",
        "  transformed_conversations = [\n",
        "    {\n",
        "      'role' : role_map.get(turn['from'], turn['from']),\n",
        "      'content' : turn['value']\n",
        "    }\n",
        "    for turn in example['conversations']\n",
        "  ]\n",
        "  return {'conversations': transformed_conversations}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.767992Z",
          "iopub.execute_input": "2024-11-17T01:29:57.768391Z",
          "iopub.status.idle": "2024-11-17T01:29:57.775424Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.768348Z",
          "shell.execute_reply": "2024-11-17T01:29:57.774525Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.776698Z",
          "iopub.execute_input": "2024-11-17T01:29:57.777454Z",
          "iopub.status.idle": "2024-11-17T01:29:57.789940Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.777410Z",
          "shell.execute_reply": "2024-11-17T01:29:57.789051Z"
        },
        "outputId": "0e9dd325-a29a-4c44-9c9b-edbf9dd50809"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['conversations'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['conversations'])"
      ],
      "metadata": {
        "id": "cZya4tPEWUc9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.791112Z",
          "iopub.execute_input": "2024-11-17T01:29:57.791394Z",
          "iopub.status.idle": "2024-11-17T01:29:57.796956Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.791364Z",
          "shell.execute_reply": "2024-11-17T01:29:57.796054Z"
        },
        "outputId": "9febc2fc-bfd0-42d5-9fa8-f3a13e010e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def format_conversation(example):\n",
        "  for entry in example['conversations']:\n",
        "    role = entry['role']\n",
        "    content = entry['content']\n",
        "\n",
        "    if role == 'user':\n",
        "      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "    elif role == 'assistant':\n",
        "      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "\n",
        "  return {'prompt': formatted_text}"
      ],
      "metadata": {
        "id": "3bmXGueQWWzt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.798136Z",
          "iopub.execute_input": "2024-11-17T01:29:57.798496Z",
          "iopub.status.idle": "2024-11-17T01:29:57.805739Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.798454Z",
          "shell.execute_reply": "2024-11-17T01:29:57.804975Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = formatted_dataset.map(\n",
        "  format_conversation,\n",
        "  remove_columns = list(formatted_dataset.features.keys())\n",
        ")\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "Z6sSaCr5eaL7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.806977Z",
          "iopub.execute_input": "2024-11-17T01:29:57.807302Z",
          "iopub.status.idle": "2024-11-17T01:29:57.820531Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.807258Z",
          "shell.execute_reply": "2024-11-17T01:29:57.819564Z"
        },
        "outputId": "2ac6bcc5-c832-4597-e2fc-55dc56b5d88a"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.822706Z",
          "iopub.execute_input": "2024-11-17T01:29:57.823183Z",
          "iopub.status.idle": "2024-11-17T01:29:57.827972Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.823140Z",
          "shell.execute_reply": "2024-11-17T01:29:57.827002Z"
        },
        "outputId": "9a3cbe6c-e22b-46fc-f770-335ab3be6d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.829113Z",
          "iopub.execute_input": "2024-11-17T01:29:57.829434Z",
          "iopub.status.idle": "2024-11-17T01:29:57.836981Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.829401Z",
          "shell.execute_reply": "2024-11-17T01:29:57.836060Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:29:57.838072Z",
          "iopub.execute_input": "2024-11-17T01:29:57.838374Z",
          "iopub.status.idle": "2024-11-17T01:30:07.848159Z",
          "shell.execute_reply.started": "2024-11-17T01:29:57.838339Z",
          "shell.execute_reply": "2024-11-17T01:30:07.847216Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:07.849377Z",
          "iopub.execute_input": "2024-11-17T01:30:07.849691Z",
          "iopub.status.idle": "2024-11-17T01:30:07.856270Z",
          "shell.execute_reply.started": "2024-11-17T01:30:07.849658Z",
          "shell.execute_reply": "2024-11-17T01:30:07.855305Z"
        },
        "outputId": "a58f0967-62ee-42ed-e383-601c1a00fbdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:07.857822Z",
          "iopub.execute_input": "2024-11-17T01:30:07.858145Z",
          "iopub.status.idle": "2024-11-17T01:30:08.112638Z",
          "shell.execute_reply.started": "2024-11-17T01:30:07.858113Z",
          "shell.execute_reply": "2024-11-17T01:30:08.111706Z"
        },
        "outputId": "cfa55ad1-fa36-4699-d078-cf195dfced48"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.113701Z",
          "iopub.execute_input": "2024-11-17T01:30:08.113991Z",
          "iopub.status.idle": "2024-11-17T01:30:08.120150Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.113961Z",
          "shell.execute_reply": "2024-11-17T01:30:08.119152Z"
        },
        "outputId": "090c593e-9576-41d4-95cf-1480a83abc01"
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.121576Z",
          "iopub.execute_input": "2024-11-17T01:30:08.121874Z",
          "iopub.status.idle": "2024-11-17T01:30:08.150554Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.121843Z",
          "shell.execute_reply": "2024-11-17T01:30:08.149588Z"
        },
        "outputId": "ebc1e95b-16d2-4695-957f-9d24f16c4b22"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n\n                                           input_ids  \\\n0  [44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...   \n1  [44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...   \n2  [44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...   \n3  [44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...   \n4  [44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.151587Z",
          "iopub.execute_input": "2024-11-17T01:30:08.151869Z",
          "iopub.status.idle": "2024-11-17T01:30:08.158166Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.151838Z",
          "shell.execute_reply": "2024-11-17T01:30:08.157229Z"
        },
        "outputId": "cb222c03-7a8e-4891-ee36-821aaf9b08f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nHow do you graph the inequality #x > -4#?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo graph the inequality #x > -4#, follow these steps:\n\n1. Start by plotting the boundary line: Draw a vertical line at #x = -4# on the X-axis. This line divides the X-axis into two halves.\n\n2. Identify the direction of the inequality: Since the inequality is #x > -4#, it indicates that we are looking for all values of #x# that are greater than -4.\n\n3. Shade the appropriate region: Shade the entire region to the right of the line at #x = -4#. This shaded area represents all the points whose X-coordinate is greater than -4.\n\n4. Include a dashed line: Since the inequality is \"greater than\" (#>,# not \"#≥#\"), draw the line at #x = -4# as a dashed line, indicating that the points on the line itself are not included in the solution.\n\nThe graph consists of the entire half-plane to the right of the dashed vertical line at #x = -4#, excluding the line itself.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.159726Z",
          "iopub.execute_input": "2024-11-17T01:30:08.160142Z",
          "iopub.status.idle": "2024-11-17T01:30:08.168918Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.160100Z",
          "shell.execute_reply": "2024-11-17T01:30:08.168066Z"
        },
        "outputId": "db246de2-1c5a-4793-b9b5-36e51e7ef8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[44, 108, 3738, 79, 12476, 79, 311, 108, 46, 4093, 44, 108, 486, 79, 12476, 79, 311, 108, 46, 198, 198, 2020, 536, 346, 3670, 260, 9724, 907, 104, 2986, 731, 36, 19, 47, 198, 44, 108, 85, 320, 79, 311, 108, 21198, 108, 3738, 79, 12476, 79, 311, 108, 46, 520, 9531, 44, 108, 486, 79, 12476, 79, 311, 108, 46, 198, 198, 2068, 3670, 260, 9724, 907, 104, 2986, 731, 36, 19, 28, 1066, 623, 3301, 42, 1116, 33, 30, 7734, 411, 27566, 260, 10651, 1761, 42, 10602, 253, 8681, 1761, 418, 907, 104, 446, 731, 36, 19, 335, 260, 2273, 29, 7814, 30, 669, 1761, 20751, 260, 2273, 29, 7814, 618, 827, 32386, 30, 1116, 34, 30, 12716, 260, 4376, 282, 260, 9724, 42, 4311, 260, 9724, 314, 907, 104, 2986, 731, 36, 19, 28, 357, 6773, 338, 392, 359, 3012, 327, 511, 2396, 282, 907, 104, 19, 338, 359, 2852, 670, 731, 36, 30, 1116, 35, 30, 1541, 903, 260, 3350, 2695, 42, 1541, 903, 260, 2415, 2695, 288, 260, 1048, 282, 260, 1761, 418, 907, 104, 446, 731, 36, 19, 30, 669, 32416, 1557, 4669, 511, 260, 2876, 3449, 2273, 29, 38263, 314, 2852, 670, 731, 36, 30, 1116, 36, 30, 26852, 253, 44613, 1761, 42, 4311, 260, 9724, 314, 476, 41773, 670, 18, 38078, 18128, 19, 441, 28096, 40533, 115, 19, 6872, 2634, 260, 1761, 418, 907, 104, 446, 731, 36, 19, 347, 253, 44613, 1761, 28, 10487, 338, 260, 2876, 335, 260, 1761, 2581, 359, 441, 3249, 281, 260, 3564, 30, 198, 198, 504, 3670, 5956, 282, 260, 2415, 2745, 29, 12758, 288, 260, 1048, 282, 260, 44613, 8681, 1761, 418, 907, 104, 446, 731, 36, 19, 28, 26827, 260, 1761, 2581, 30, 198, 44, 108, 85, 320, 79, 311, 108, 46, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.169982Z",
          "iopub.execute_input": "2024-11-17T01:30:08.170320Z",
          "iopub.status.idle": "2024-11-17T01:30:08.180086Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.170289Z",
          "shell.execute_reply": "2024-11-17T01:30:08.179206Z"
        },
        "outputId": "e960c44f-277c-46b1-b69c-8de8e39870fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.181116Z",
          "iopub.execute_input": "2024-11-17T01:30:08.181403Z",
          "iopub.status.idle": "2024-11-17T01:30:08.188141Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.181374Z",
          "shell.execute_reply": "2024-11-17T01:30:08.187334Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.189238Z",
          "iopub.execute_input": "2024-11-17T01:30:08.189525Z",
          "iopub.status.idle": "2024-11-17T01:30:08.197528Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.189492Z",
          "shell.execute_reply": "2024-11-17T01:30:08.196676Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.198452Z",
          "iopub.execute_input": "2024-11-17T01:30:08.198739Z",
          "iopub.status.idle": "2024-11-17T01:30:08.207186Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.198708Z",
          "shell.execute_reply": "2024-11-17T01:30:08.206391Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.208159Z",
          "iopub.execute_input": "2024-11-17T01:30:08.208458Z",
          "iopub.status.idle": "2024-11-17T01:30:08.216498Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.208419Z",
          "shell.execute_reply": "2024-11-17T01:30:08.215644Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.218755Z",
          "iopub.execute_input": "2024-11-17T01:30:08.219102Z",
          "iopub.status.idle": "2024-11-17T01:30:08.757223Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.219060Z",
          "shell.execute_reply": "2024-11-17T01:30:08.755836Z"
        },
        "outputId": "557c4078-ce2d-4ed7-c1f4-924174b38b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 19,537,920 || all params: 154,052,928 || trainable%: 12.6826\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.758826Z",
          "iopub.execute_input": "2024-11-17T01:30:08.759262Z",
          "iopub.status.idle": "2024-11-17T01:30:08.784801Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.759201Z",
          "shell.execute_reply": "2024-11-17T01:30:08.783907Z"
        },
        "outputId": "54b00220-0ec1-433f-8b2b-d4786c6e385d"
      },
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n    (layers): ModuleList(\n      (0-29): 30 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((576,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.785921Z",
          "iopub.execute_input": "2024-11-17T01:30:08.786309Z",
          "iopub.status.idle": "2024-11-17T01:30:08.869145Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.786264Z",
          "shell.execute_reply": "2024-11-17T01:30:08.866997Z"
        },
        "outputId": "b021fb22-6d93-45eb-ee43-0a6c59737389"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 100968768\nTrainable parameters : 19537920\nTrainable percentage: 19.35%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.870751Z",
          "iopub.execute_input": "2024-11-17T01:30:08.871894Z",
          "iopub.status.idle": "2024-11-17T01:30:08.971299Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.871849Z",
          "shell.execute_reply": "2024-11-17T01:30:08.969739Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:08.972599Z",
          "iopub.execute_input": "2024-11-17T01:30:08.973317Z",
          "iopub.status.idle": "2024-11-17T01:30:09.060118Z",
          "shell.execute_reply.started": "2024-11-17T01:30:08.973271Z",
          "shell.execute_reply": "2024-11-17T01:30:09.059180Z"
        },
        "outputId": "b220b8c5-616b-4a4d-8c26-f300a6117bbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov17_01-30-09_84769eed1484,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:09.061450Z",
          "iopub.execute_input": "2024-11-17T01:30:09.061830Z",
          "iopub.status.idle": "2024-11-17T01:30:10.237379Z",
          "shell.execute_reply.started": "2024-11-17T01:30:09.061787Z",
          "shell.execute_reply": "2024-11-17T01:30:10.236466Z"
        },
        "outputId": "0c59d461-512e-486b-c8e7-55e00828a78e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7f724c5a2920>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:30:10.249270Z",
          "iopub.execute_input": "2024-11-17T01:30:10.249555Z",
          "iopub.status.idle": "2024-11-17T01:44:27.635919Z",
          "shell.execute_reply.started": "2024-11-17T01:30:10.249524Z",
          "shell.execute_reply": "2024-11-17T01:44:27.635060Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:27.637073Z",
          "iopub.execute_input": "2024-11-17T01:44:27.637369Z",
          "iopub.status.idle": "2024-11-17T01:44:47.396474Z",
          "shell.execute_reply.started": "2024-11-17T01:44:27.637336Z",
          "shell.execute_reply": "2024-11-17T01:44:47.395530Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:47.397810Z",
          "iopub.execute_input": "2024-11-17T01:44:47.398147Z",
          "iopub.status.idle": "2024-11-17T01:44:48.468100Z",
          "shell.execute_reply.started": "2024-11-17T01:44:47.398113Z",
          "shell.execute_reply": "2024-11-17T01:44:48.467022Z"
        },
        "outputId": "d5e082cc-0102-48b0-8389-547f3385727f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/5a33ba103645800d7b3790c4448546c1b73efc71/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/5a33ba103645800d7b3790c4448546c1b73efc71/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:48.469374Z",
          "iopub.execute_input": "2024-11-17T01:44:48.469683Z",
          "iopub.status.idle": "2024-11-17T01:44:48.731532Z",
          "shell.execute_reply.started": "2024-11-17T01:44:48.469650Z",
          "shell.execute_reply": "2024-11-17T01:44:48.730502Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:48.732791Z",
          "iopub.execute_input": "2024-11-17T01:44:48.733137Z",
          "iopub.status.idle": "2024-11-17T01:44:48.742790Z",
          "shell.execute_reply.started": "2024-11-17T01:44:48.733103Z",
          "shell.execute_reply": "2024-11-17T01:44:48.741920Z"
        },
        "id": "fqrZxlXMUNX7",
        "outputId": "97ca85e6-cd22-46a9-bba6-5f75315ebc8c"
      },
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:48.744001Z",
          "iopub.execute_input": "2024-11-17T01:44:48.744598Z",
          "iopub.status.idle": "2024-11-17T01:44:49.403521Z",
          "shell.execute_reply.started": "2024-11-17T01:44:48.744554Z",
          "shell.execute_reply": "2024-11-17T01:44:49.402522Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "C4MEuI8vUNX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:49.404910Z",
          "iopub.execute_input": "2024-11-17T01:44:49.405307Z",
          "iopub.status.idle": "2024-11-17T01:44:50.882315Z",
          "shell.execute_reply.started": "2024-11-17T01:44:49.405263Z",
          "shell.execute_reply": "2024-11-17T01:44:50.881375Z"
        },
        "id": "RFyGeci7UNX7",
        "outputId": "fa6d8d22-9899-4432-f512-bb4ceb3fc3fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/5a33ba103645800d7b3790c4448546c1b73efc71/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-135M-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/5a33ba103645800d7b3790c4448546c1b73efc71/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/5a33ba103645800d7b3790c4448546c1b73efc71/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n    (layers): ModuleList(\n      (0-29): 30 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (k_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (v_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (o_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (up_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (down_proj): Linear4bit(in_features=1536, out_features=576, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((576,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.883506Z",
          "iopub.execute_input": "2024-11-17T01:44:50.883808Z",
          "iopub.status.idle": "2024-11-17T01:44:50.896136Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.883776Z",
          "shell.execute_reply": "2024-11-17T01:44:50.895152Z"
        },
        "id": "gadaDfunUNX7",
        "outputId": "3b62fe45-965d-42a4-b491-2ca698d1cd50"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 81430848\nTrainable parameters : 28346688\nTrainable percentage: 34.81%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.899005Z",
          "iopub.execute_input": "2024-11-17T01:44:50.899431Z",
          "iopub.status.idle": "2024-11-17T01:44:50.930515Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.899387Z",
          "shell.execute_reply": "2024-11-17T01:44:50.929674Z"
        },
        "id": "JzDHIYH_UNX7",
        "outputId": "e0d12277-6ca7-415a-e8cb-c26f89d0993d"
      },
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(49152, 576, padding_idx=2)\n        (layers): ModuleList(\n          (0-29): 30 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=192, bias=False)\n                  (default): Linear(in_features=64, out_features=192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=192, bias=False)\n                  (default): Linear(in_features=64, out_features=192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((576,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.931592Z",
          "iopub.execute_input": "2024-11-17T01:44:50.931879Z",
          "iopub.status.idle": "2024-11-17T01:44:50.963656Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.931847Z",
          "shell.execute_reply": "2024-11-17T01:44:50.962781Z"
        },
        "id": "ZiYzByZgUNX7",
        "outputId": "a405d7dd-be0e-4583-8971-125f9a458a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 120506688\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.964830Z",
          "iopub.execute_input": "2024-11-17T01:44:50.965199Z",
          "iopub.status.idle": "2024-11-17T01:44:50.972800Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.965155Z",
          "shell.execute_reply": "2024-11-17T01:44:50.971953Z"
        },
        "id": "vL0LZNNaUNX8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.974039Z",
          "iopub.execute_input": "2024-11-17T01:44:50.974404Z",
          "iopub.status.idle": "2024-11-17T01:44:50.982694Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.974362Z",
          "shell.execute_reply": "2024-11-17T01:44:50.981833Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:44:50.983922Z",
          "iopub.execute_input": "2024-11-17T01:44:50.984251Z",
          "iopub.status.idle": "2024-11-17T01:44:50.992111Z",
          "shell.execute_reply.started": "2024-11-17T01:44:50.984209Z",
          "shell.execute_reply": "2024-11-17T01:44:50.991380Z"
        },
        "id": "YCvjiXcaUNX8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:59:33.643954Z",
          "iopub.execute_input": "2024-11-17T01:59:33.644888Z",
          "iopub.status.idle": "2024-11-17T02:02:52.485990Z",
          "shell.execute_reply.started": "2024-11-17T01:59:33.644846Z",
          "shell.execute_reply": "2024-11-17T02:02:52.485023Z"
        },
        "outputId": "999764ed-96b4-48b7-9ca3-2ec91788fe3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\n<|im_start|>system You are a helpful AI assistant   |  <|im_start|>system You are a helpful AI assistant \nnamed SmolLM, trained by Hugging Face<|im_end|>     |  named SmolLM, trained by Hugging Face<|im_end|>   \n<|im_start|>human Describe how airplanes maintain   |  <|im_start|>human Describe how airplanes maintain \naltitude.<|im_end|> <|im_start|>assistant           |  altitude.<|im_end|> <|im_start|>assistant         \nAirplanes maintain altitude through a combination   |  Airplanes maintain altitude through a combination \nof techniques that involve the use of lift,         |  of techniques that involve the use of lift,       \nthrust, and control systems. Here's a simplified    |  thrust, and control systems. Here's a simplified  \nexplanation of how they achieve this:  When an      |  explanation of how they achieve this:  When an    \nairplane is at a certain altitude, the engines are  |  airplane is at a certain altitude, the engines are\nused to produce a force that counteracts the force  |  used to produce a force that counteracts the force\nof gravity. This force is created by the engines'   |  of gravity. This force is created by the engines' \nexhaust gases, which are expelled from the engines  |  exhaust gases, which are expelled from the engines\nat a certain rate. The exhaust gases are created    |  at a certain rate. The exhaust gases are composed \nby the engines' combustion process, where the fuel  |  of a mixture of gases, including oxygen and       \nis burned in the engines' cylinders.  The engines   |  nitrogen, which are mixed with a mixture of gases,\nproduce a force that counteracts the force of       |  including oxygen and carbon dioxide, which are    \ngravity, which is created by the exhaust gases.     |  mixed with a mixture of gases, including oxygen   \nThis force is created by the engines' exhaust       |  and carbon dioxide, which are mixed with a mixture\ngases, which are expelled from the engines at a     |  of gases, including oxygen and carbon dioxide,    \ncertain rate. The exhaust gases are created by the  |  which are mixed with a mixture of gases, including\nengines' combustion process, where the fuel is      |  oxygen and carbon dioxide, which are mixed with a \nburned in the engines' cylinders.  When the         |  mixture of gases, including oxygen and carbon     \nengines are at a certain altitude, the exhaust      |  dioxide, which are mixed with a mixture of gases, \ngases are used to produce a force that counteracts  |  including oxygen and carbon dioxide, which are    \nthe force of gravity. This force is created by the  |  mixed with a mixture of gases, including oxygen   \nexhaust gases, which are expelled from the engines  |  and carbon dioxide, which are mixed with a mixture\nat a certain rate. The exhaust gases are created    |  of gases, including oxygen and carbon dioxide,    \nby the engines' combustion process, where the fuel  |  which are mixed with a mixture of gases, including\nis burned in the engines' cylinders.  The exhaust   |  oxygen and carbon dioxide, which are mixed with a \ngases are created by the engines' combustion        |  mixture of gases, including oxygen and carbon     \nprocess, where the fuel is burned in the engines'   |  dioxide, which are mixed with a mixture of gases, \ncylinders. This exhaust gases are created by the    |  including oxygen and carbon dioxide, which are    \nengines' combustion process, where the fuel is      |  mixed with a mixture of gases, including oxygen   \nburned in the engines' cylinders. When the exhaust  |  and carbon dioxide, which are mixed with a mixture\ngases are used to produce a force that counteracts  |  of gases, including oxygen and carbon dioxide,    \nthe force of gravity, the engines are used to       |  which are mixed with a mixture of gases, including\nproduce a force that counteracts the force of       |  oxygen and carbon dioxide, which are mixed with a \ngravity.  When the engines are at a certain         |  mixture of gases, including oxygen and carbon     \naltitude, the exhaust gases are used to produce a   |  dioxide, which are mixed with a mixture of gases, \nforce that counteracts the force of gravity. This   |  including oxygen and carbon dioxide, which are    \nforce is created by the exhaust gases, which are    |  mixed with a mixture of gases, including oxygen   \nexpelled from the engines at a certain rate. The    |  and carbon dioxide, which are mixed with a mixture\nexhaust gases are created by the engines'           |  of gases, including oxygen and carbon dioxide,    \ncombustion process, where the fuel is burned in     |  which are mixed with a mixture of gases, including\nthe engines' cylinders.  When the engines are at a  |  oxygen and carbon dioxide, which are mixed with a \ncertain altitude, the exhaust gases are used to     |  mixture of gases, including oxygen and carbon     \nproduce a force that counteracts the force of       |  dioxide, which are mixed with a mixture of gases, \ngravity. This force is created by the exhaust       |  including oxygen and carbon dioxide, which are    \ngases, which are expelled from the engines at a     |  mixed with a mixture of gases, including oxygen   \ncertain rate. The exhaust gases are created by the  |  and carbon dioxide, which are mixed with a mixture\nengines' combustion process, where the fuel is      |  of gases, including oxygen and carbon dioxide,    \nburned in the engines' cylinders.  When the         |  which are mixed with a mixture of gases, including\nengines are at a certain altitude, the exhaust      |  oxygen and carbon dioxide, which are mixed with a \ngases are used to produce a force that counteracts  |  mixture of gases, including oxygen and carbon     \nthe force of gravity. This force is created by the  |  dioxide, which are mixed with a mixture of gases, \nexhaust gases, which are expelled from the engines  |  including oxygen and carbon dioxide, which are    \nat a certain rate. The exhaust gases are created    |  mixed with a mixture of gases, including oxygen   \nby the engines' combustion process, where the fuel  |  and carbon dioxide, which are mixed with a mixture\nis burned in the engines' cylinders.  When the      |  of gases, including oxygen and carbon dioxide,    \nengines are at a certain altitude, the exhaust      |  which are mixed with a mixture of gases, including\ngases are used to produce a force that counteracts  |  oxygen and carbon dioxide, which are mixed with a \nthe force of gravity. This force is created by the  |  mixture of gases, including oxygen and carbon     \nexhaust gases, which are expelled from the engines  |  dioxide, which are mixed with a mixture of gases, \nat a certain rate. The exhaust gases are created    |  including oxygen and carbon dioxide, which are    \nby the engines' combustion process, where the fuel  |  mixed with a mixture of gases, including oxygen   \nis burned in the engines' cylinders.  When the      |  and carbon dioxide, which are mixed with a mixture\nengines are at a certain altitude, the exhaust      |  of gases, including oxygen and carbon dioxide,    \ngases are used to produce a force that counteracts  |  which are mixed with a mixture of gases, including\nthe force of gravity. This force is created by the  |  oxygen and carbon dioxide, which are mixed with a \nexhaust gases, which are expelled from the engines  |  mixture of gases, including oxygen and carbon     \nat a certain rate. The exhaust gases are created    |  dioxide, which are mixed with a mixture of gases, \nby the engines' combustion process, where the fuel  |  including oxygen and carbon dioxide, which are    \nis burned in the engines' cylinders.  When the      |  mixed with a mixture of gases, including oxygen   \nengines are at a certain altitude, the exhaust      |  and carbon dioxide, which are mixed with a mixture\ngases are used to produce a force that counteracts  |  of gases, including oxygen and carbon dioxide,    \nthe force of gravity. This force is created by the  |  which are mixed with a mixture of gases, including\nexhaust gases, which are expelled from the engines  |  oxygen and carbon dioxide, which are mixed with a \nat a certain rate. The exhaust gases are created    |  mixture of gases, including oxygen and carbon     \nby the engines' combustion process, where the fuel  |  dioxide, which are mixed with a mixture of gases, \nis burned in the engines' cylinders.  When the      |  including oxygen and carbon dioxide, which are    \nengines are at a certain altitude, the exhaust      |  mixed with a mixture of gases, including oxygen   \ngases are used to produce a force that counteracts  |  and carbon dioxide, which are mixed with a mixture\nthe force of gravity. This force is created by the  |  of gases, including oxygen and carbon dioxide,    \nexhaust gases, which are expelled from the engines  |  which are mixed with a mixture of gases, including\nat a certain rate. The exhaust gases are created    |  oxygen and carbon dioxide, which are mixed with a \nby the engines' combustion process, where the fuel  |  mixture of gases, including oxygen and carbon     \nis burned in the engines' cylinders.  When the      |  dioxide, which are mixed with a mixture of gases, \nengines are at a certain altitude, the exhaust      |  including oxygen and carbon dioxide, which are    \ngases are used to produce a force that counteracts  |  mixed with a mixture of gases, including oxygen   \nthe force of gravity. This force is created by the  |  and carbon dioxide, which are mixed with a mixture\nexhaust gases, which are expelled from the engines  |  of gases, including oxygen and carbon dioxide,    \nat a certain rate. The exhaust gases are created    |  which are mixed with a mixture of gases, including\nby the engines' combustion process, where the fuel  |  oxygen and carbon dioxide, which are mixed with a \nis burned in the engines' cylinders.  When the      |  mixture of gases, including oxygen and carbon     \nengines are at a certain altitude, the exhaust      |  dioxide, which are mixed with a mixture of gases, \ngases are used to produce a force that counteracts  |  including oxygen and carbon dioxide, which are    \nthe force of gravity. This force is created by the  |  mixed with a mixture of gases, including oxygen   \nexhaust gases, which are expelled from the engines  |  and carbon dioxide, which are mixed with a mixture\nat a certain rate. The exhaust gases are created    |  of gases, including oxygen and carbon dioxide,    \nby the engines' combustion process, where the fuel  |  which are mixed with a mixture of gases, including\nis burned in the engines' cylinders.  When the      |  oxygen and carbon dioxide, which are mixed with a \nengines are at a certain altitude, the exhaust      |  mixture of gases, including oxygen and carbon     \ngases are used to produce a force that counteracts  |  dioxide, which are mixed with a mixture of gases, \nthe force of gravity. This force is created by the  |  including oxygen and carbon dioxide, which are    \nexhaust gases, which are expelled from the engines  |  mixed with a mixture of gases, including oxygen   \nat a certain rate. The exhaust gases are created    |  and carbon dioxide, which are mixed with a mixture\nby the engines' combustion process                  |  of gases, including oxygen and carbon dioxide,    \n                                                    |  which are mixed with a mixture of gases, including\n                                                    |  oxygen and carbon dioxide, which are mixed with a \n                                                    |  mixture of gases, including oxygen and carbon     \n                                                    |  dioxide, which are mixed with a mixture of gases, \n                                                    |  including oxygen and carbon dioxide, which are    \n                                                    |  mixed with a mixture of gases, including oxygen   \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T02:03:18.092191Z",
          "iopub.execute_input": "2024-11-17T02:03:18.093085Z",
          "iopub.status.idle": "2024-11-17T02:06:37.163539Z",
          "shell.execute_reply.started": "2024-11-17T02:03:18.093043Z",
          "shell.execute_reply": "2024-11-17T02:06:37.161553Z"
        },
        "outputId": "f2743a04-ee7e-4301-aeea-68f5619b3320"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\n<|im_start|>system You are a helpful AI assistant   |  <|im_start|>system You are a helpful AI assistant \nnamed SmolLM, trained by Hugging Face<|im_end|>     |  named SmolLM, trained by Hugging Face<|im_end|>   \n<|im_start|>human Explain how the order of          |  <|im_start|>human Explain how the order of        \noperations in BIDMAS ensures consistency in         |  operations in BIDMAS ensures consistency in       \nmathematical calculations.<|im_end|>                |  mathematical calculations.<|im_end|>              \n<|im_start|>assistant In BIDMAS, the order of       |  <|im_start|>assistant In BIDMAS, the order of     \noperations is crucial for ensuring consistency in   |  operations is crucial for ensuring consistency in \nmathematical calculations. Here's how it works:     |  mathematical calculations. Here's how it works:   \n1. First, we perform the multiplication operation   |  1. First, we perform the multiplication operation \non the first operand (e.g., 2 * 3). This operation  |  on the first operand (e.g., 2 * 3). This operation\nis followed by the addition operation on the        |  is followed by the addition operation on the      \nsecond operand (e.g., 4 + 3).  2. Next, we perform  |  second operand (e.g., 3 + 2).  2. Next, we perform\nthe multiplication operation on the second operand  |  the multiplication operation on the second operand\n(e.g., 4 * 3). This operation is followed by the    |  (e.g., 3 * 2). This operation is followed by the  \naddition operation on the third operand (e.g., 5 +  |  addition operation on the third operand (e.g., 4 +\n3).  3. Finally, we perform the multiplication      |  2).  3. Finally, we perform the multiplication    \noperation on the third operand (e.g., 5 * 3). This  |  operation on the third operand (e.g., 4 * 2). This\noperation is followed by the subtraction operation  |  operation is followed by the subtraction operation\non the fourth operand (e.g., 4 - 3).  4. We repeat  |  on the fourth operand (e.g., 1 - 2).  4. We repeat\nthis process for each operation, starting from the  |  this process for each operation, starting from the\nlast operation (e.g., 5 - 3). This operation is     |  last operation (e.g., 1 - 2). This operation is   \nfollowed by the subtraction operation on the        |  followed by the division operation on the fourth  \nfourth operand (e.g., 4 - 3).  5. We repeat this    |  operand (e.g., 1 / 2).  5. Finally, we perform the\nprocess for each operation, starting from the last  |  division operation on the fourth operand (e.g., 1 \noperation (e.g., 4 - 3). This operation is          |  / 2). This operation is followed by the           \nfollowed by the addition operation on the fourth    |  multiplication operation on the fifth operand     \noperand (e.g., 5 - 3).  6. We repeat this process   |  (e.g., 2).  6. We repeat this process for each    \nfor each operation, starting from the last          |  operation, starting from the last operation (e.g.,\noperation (e.g., 4 - 3). This operation is          |  2 * 2). This operation is followed by the division\nfollowed by the subtraction operation on the        |  operation on the sixth operand (e.g., 2 / 2).  7. \nfourth operand (e.g., 4 - 3).  7. We repeat this    |  We repeat this process for each operation,        \nprocess for each operation, starting from the last  |  starting from the last operation (e.g., 2 / 2).   \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the multiplication  \nfollowed by the multiplication operation on the     |  operation on the seventh operand (e.g., 4 / 2).   \nfourth operand (e.g., 5 - 3).  8. We repeat this    |  8. We repeat this process for each operation,     \nprocess for each operation, starting from the last  |  starting from the last operation (e.g., 4 / 2).   \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the division        \nfollowed by the division operation on the fourth    |  operation on the eighth operand (e.g., 4 / 2).  9.\noperand (e.g., 5 - 3).  9. We repeat this process   |  We repeat this process for each operation,        \nfor each operation, starting from the last          |  starting from the last operation (e.g., 4 / 2).   \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the multiplication  \nfollowed by the multiplication operation on the     |  operation on the ninth operand (e.g., 16 / 2).    \nfourth operand (e.g., 5 - 3).  10. We repeat this   |  10. We repeat this process for each operation,    \nprocess for each operation, starting from the last  |  starting from the last operation (e.g., 16 / 2).  \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the division        \nfollowed by the division operation on the fourth    |  operation on the tenth operand (e.g., 16 / 2).    \noperand (e.g., 5 - 3).  11. We repeat this process  |  11. We repeat this process for each operation,    \nfor each operation, starting from the last          |  starting from the last operation (e.g., 16 / 2).  \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the multiplication  \nfollowed by the multiplication operation on the     |  operation on the eleventh operand (e.g., 16 / 2). \nfourth operand (e.g., 5 - 3).  12. We repeat this   |  12. We repeat this process for each operation,    \nprocess for each operation, starting from the last  |  starting from the last operation (e.g., 16 / 2).  \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the division        \nfollowed by the division operation on the fourth    |  operation on the twelfth operand (e.g., 16 / 2).  \noperand (e.g., 5 - 3).  13. We repeat this process  |  13. We repeat this process for each operation,    \nfor each operation, starting from the last          |  starting from the last operation (e.g., 16 / 2).  \noperation (e.g., 4 - 3). This operation is          |  This operation is followed by the multiplication  \nfollowed by the multiplication operation on the     |  operation on the thirteenth operand (e.g., 16 /   \nfourth operand (e.g., 5 - 3).  14. We repeat this   |  2).  14. We repeat this process for each          \nprocess for each operation, starting from the last  |  operation, starting from the last operation (e.g.,\noperation (e.g., 4 - 3). This operation is          |  16 / 2). This operation is followed by the        \nfollowed by the division operation on the fourth    |  division operation on the fourteenth operand      \noperand (e.g., 5 - 3).  15. We repeat this process  |  (e.g., 16 / 2).  15. We repeat this process for   \nfor each operation, starting from the last          |  each operation, starting from the last operation  \noperation (e.g., 4 - 3). This operation is          |  (e.g., 16 / 2). This operation is followed by the \nfollowed by the multiplication operation on the     |  multiplication operation on the sixteenth operand \nfourth operand (e.g., 5 - 3).  16. We repeat this   |  (e.g., 16 / 2).  16. We repeat this process for   \nprocess for each operation, starting from the last  |  each operation, starting from the last operation  \noperation (e.g., 4 - 3). This operation is          |  (e.g., 16 / 2). This operation is followed by the \nfollowed by the division operation on the fourth    |  division operation on the sixteenth operand (e.g.,\noperand (e.g., 5 - 3).  17. We repeat this process  |  16 / 2).  17. We repeat this process for each     \nfor each operation, starting from the last          |  operation, starting from the last operation (e.g.,\noperation (e.g., 4 - 3). This operation is          |  16 / 2). This operation is followed by the        \nfollowed by the multiplication operation on the     |  multiplication operation on the seventeenth       \nfourth operand (e.g., 5 - 3).  18. We repeat this   |  operand (e.g., 16 / 2).  18. We repeat this       \nprocess for each operation, starting from the last  |  process for each operation, starting from the last\noperation (e.g., 4 - 3). This operation is          |  operation (e.g., 16 / 2). This operation is       \nfollowed by the division operation on the fourth    |  followed by the division operation on the         \noperand (e.g., 5 - 3).  19. We repeat this process  |  seventeenth operand (e.g., 16 / 2).  19. We repeat\nfor each operation, starting from the last          |  this process for each operation, starting from the\noperation (e.g., 4 - 3). This operation is          |  last operation (e.g., 16 / 2). This operation is  \nfollowed by the multiplication operation on the     |  followed by the multiplication operation on the   \nfourth operand (e.g., 5 - 3).  20. We repeat this   |  eighteenth operand (e.g., 16 / 2).  20. We repeat \nprocess for each operation, starting from the last  |  this                                              \noperation (e.g., 4                                  |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T02:06:57.637284Z",
          "iopub.execute_input": "2024-11-17T02:06:57.638319Z",
          "iopub.status.idle": "2024-11-17T02:10:16.940392Z",
          "shell.execute_reply.started": "2024-11-17T02:06:57.638264Z",
          "shell.execute_reply": "2024-11-17T02:10:16.939202Z"
        },
        "outputId": "bbb7ee0a-9baf-4031-ed0e-ea11067a3388"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\n<|im_start|>system You are a helpful AI assistant   |  <|im_start|>system You are a helpful AI assistant \nnamed SmolLM, trained by Hugging Face<|im_end|>     |  named SmolLM, trained by Hugging Face<|im_end|>   \n<|im_start|>human How do viral infections affect    |  <|im_start|>human How do viral infections affect  \nvulnerable populations such as infants, elderly     |  vulnerable populations such as infants, elderly   \nand immunocompromised individuals, and what are     |  and immunocompromised individuals, and what are   \nthe most effective strategies for preventing and    |  the most effective strategies for preventing and  \ntreating these infections?<|im_end|>                |  treating these infections?<|im_end|>              \n<|im_start|>assistant As a helpful AI assistant     |  <|im_start|>assistant As a helpful AI assistant   \nnamed SmolLM, I'm here to help you understand and   |  named SmolLM, I'm here to help you understand and \naddress the challenges faced by vulnerable          |  address the challenges faced by vulnerable        \npopulations such as infants, elderly, and           |  populations such as infants, elderly, and         \nimmunocompromised individuals. Here's a detailed    |  immunocompromised individuals. Here's a detailed  \nexplanation of how viral infections affect these    |  explanation of how viral infections affect these  \ngroups:  1. **Viral infections**: These infections  |  groups:  1. **Viral infections**: These infections\nare caused by viruses that can affect the health    |  are caused by viruses that can affect the health  \nof these groups. Some common examples include:      |  of these groups. Some common examples include:    \n* **Enteroviruses**: These viruses are common in    |  * **Enteroviruses**: These viruses are common in  \nthe environment and can cause a range of            |  the environment and can cause a range of          \ninfections, including:         * **Sneezing and     |  infections, including:         * **Sneezing and   \nrunny nose**: These can cause a range of symptoms,  |  runny nose**: These can affect infants and elderly\nincluding:         * **Runny nose**: These can      |  individuals, and can lead to complications if left\ncause a range of symptoms, including:         *     |  untreated.         * **Strep throat**: This is a  \n**Sneezing**: These can cause a range of symptoms,  |  common infection in the environment and can affect\nincluding:         * **Runny nose**: These can      |  infants and elderly individuals, and can lead to  \ncause a range of symptoms, including:         *     |  complications if left untreated.         * **Viral\n**Sneezing**: These can cause a range of symptoms,  |  pneumonia**: This is a common infection in the    \nincluding:         * **Runny nose**: These can      |  environment and can affect infants and elderly    \ncause a range of symptoms, including:         *     |  individuals, and can lead to complications if left\n**Sneezing**: These can cause a range of symptoms,  |  untreated. 2. **Viral infections in               \nincluding:         * **Runny nose**: These can      |  immunocompromised individuals**: These infections \ncause a range of symptoms, including:         *     |  can affect the health of these groups. Some       \n**Sneezing**: These can cause a range of symptoms,  |  examples include:         * **Viral pneumonia**:  \nincluding:         * **Runny nose**: These can      |  This is a common infection in the environment and \ncause a range of symptoms, including:         *     |  can affect infants and elderly individuals, and   \n**Sneezing**: These can cause a range of symptoms,  |  can lead to complications if left untreated.      \nincluding:         * **Runny nose**: These can      |  * **Viral meningitis**: This is a common infection\ncause a range of symptoms, including:         *     |  in the environment and can affect infants and     \n**Sneezing**: These can cause a range of symptoms,  |  elderly individuals, and can lead to complications\nincluding:         * **Runny nose**: These can      |  if left untreated.         * **Viral sepsis**:    \ncause a range of symptoms, including:         *     |  This is a common infection in the environment and \n**Sneezing**: These can cause a range of symptoms,  |  can affect infants and elderly individuals, and   \nincluding:         * **Runny nose**: These can      |  can lead to complications if left untreated. 3.   \ncause a range of symptoms, including:         *     |  **Viral infections in the elderly**: These        \n**Sneezing**: These can cause a range of symptoms,  |  infections can affect the health of these groups. \nincluding:         * **Runny nose**: These can      |  Some examples include:         * **Viral          \ncause a range of symptoms, including:         *     |  pneumonia**: This is a common infection in the    \n**Sneezing**: These can cause a range of symptoms,  |  environment and can affect infants and elderly    \nincluding:         * **Runny nose**: These can      |  individuals, and can lead to complications if left\ncause a range of symptoms, including:         *     |  untreated.         * **Viral sepsis**: This is a  \n**Sneezing**: These can cause a range of symptoms,  |  common infection in the environment and can affect\nincluding:         * **Runny nose**: These can      |  infants and elderly individuals, and can lead to  \ncause a range of symptoms, including:         *     |  complications if left untreated.         * **Viral\n**Sneezing**: These can cause a range of symptoms,  |  meningitis**: This is a common infection in the   \nincluding:         * **Runny nose**: These can      |  environment and can affect infants and elderly    \ncause a range of symptoms, including:         *     |  individuals, and can lead to complications if left\n**Sneezing**: These can cause a range of symptoms,  |  untreated. 4. **Viral infections in the           \nincluding:         * **Runny nose**: These can      |  environment**: These infections can affect the    \ncause a range of symptoms, including:         *     |  health of these groups. Some examples include:    \n**Sneezing**: These can cause a range of symptoms,  |  * **Viral pneumonia**: This is a common infection \nincluding:         * **Runny nose**: These can      |  in the environment and can affect infants and     \ncause a range of symptoms, including:         *     |  elderly individuals, and can lead to complications\n**Sneezing**: These can cause a range of symptoms,  |  if left untreated.         * **Viral sepsis**:    \nincluding:         * **Runny nose**: These can      |  This is a common infection in the environment and \ncause a range of symptoms, including:         *     |  can affect infants and elderly individuals, and   \n**Sneezing**: These can cause a range of symptoms,  |  can lead to complications if left untreated. 5.   \nincluding:         * **Runny nose**: These can      |  **Viral infections in the elderly**: These        \ncause a range of symptoms, including:         *     |  infections can affect the health of these groups. \n**Sneezing**: These can cause a range of symptoms,  |  Some examples include:         * **Viral          \nincluding:         * **Runny nose**: These can      |  pneumonia**: This is a common infection in the    \ncause a range of symptoms, including:         *     |  environment and can affect infants and elderly    \n**Sneezing**: These can cause a range of symptoms,  |  individuals, and can lead to complications if left\nincluding:         * **Runny nose**: These can      |  untreated.         * **Viral sepsis**: This is a  \ncause a range of symptoms, including:         *     |  common infection in the environment and can affect\n**Sneezing**: These can cause a range of symptoms,  |  infants and elderly individuals, and can lead to  \nincluding:         * **Runny nose**: These can      |  complications if left untreated. 6. **Viral       \ncause a range of symptoms, including:         *     |  infections in the environment and the elderly**:  \n**Sneezing**: These can cause a range of symptoms,  |  These infections can affect the health of these   \nincluding:         * **Runny nose**: These can      |  groups. Some examples include:         * **Viral  \ncause a range of symptoms, including:         *     |  pneumonia**: This is a common infection in the    \n**Sneezing**: These can cause a range of symptoms,  |  environment and can affect infants and elderly    \nincluding:         * **Runny nose**: These can      |  individuals, and can lead to complications if left\ncause a range of symptoms, including:         *     |  untreated.         * **Viral sepsis**: This is a  \n**Sneezing**: These can cause a range of symptoms,  |  common infection in the environment and can affect\nincluding:         * **Runny nose**: These can      |  infants and elderly individuals, and can lead to  \ncause a range of symptoms, including:         *     |  complications if left untreated.         * **Viral\n**Sneezing**: These can cause a range of symptoms,  |  meningitis**: This is a common infection in the   \nincluding:         * **Runny nose**: These can      |  environment and can affect infants and elderly    \ncause a range of symptoms, including:         *     |  individuals, and can lead to complications if left\n**Sneezing**: These can cause a range of symptoms,  |  untreated.  Understanding these infections can    \nincluding:         * **Runny nose**: These can      |  help us develop effective strategies to prevent   \ncause a range of symptoms, including:         *     |  and treat these infections in vulnerable          \n**Sneezing**: These can cause a range of symptoms,  |  populations. This includes:  * **Proper hygiene**:\nincluding:         * **Runny nose**: These can      |  Ensuring that we wash our hands frequently and    \ncause a range of symptoms, including:         *     |  thoroughly to prevent the spread of viruses. *    \n**Sneezing**: These can cause a range of symptoms,  |  **Proper use of personal protective equipment**:  \nincluding:                                          |  Ensuring that we use personal protective equipment\n                                                    |  to prevent the spread of viruses. * **Proper use  \n                                                    |  of personal protective equipment**: Ensuring that \n                                                    |  we use personal protective equipment to prevent   \n                                                    |  the spread of viruses. * **Proper use of personal \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper use of personal     \n                                                    |  protective equipment**: Ensuring that we use      \n                                                    |  personal protective equipment to prevent the      \n                                                    |  spread of viruses. * **Proper                     \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T01:52:29.103864Z",
          "iopub.execute_input": "2024-11-17T01:52:29.104178Z",
          "iopub.status.idle": "2024-11-17T01:55:46.119060Z",
          "shell.execute_reply.started": "2024-11-17T01:52:29.104145Z",
          "shell.execute_reply": "2024-11-17T01:55:46.118152Z"
        },
        "outputId": "b321856b-ee21-45c4-9a76-9704def2a25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\n<|im_start|>system You are a helpful AI assistant   |  <|im_start|>system You are a helpful AI assistant \nnamed SmolLM, trained by Hugging Face<|im_end|>     |  named SmolLM, trained by Hugging Face<|im_end|>   \n<|im_start|>human What were the social and          |  <|im_start|>human What were the social and        \neconomic impacts of the Industrial Revolution in    |  economic impacts of the Industrial Revolution in  \n19th century England?<|im_end|>                     |  19th century England?<|im_end|>                   \n<|im_start|>assistant The Industrial Revolution in  |  <|im_start|>assistant The Industrial Revolution in\n19th century England had a profound impact on the   |  19th century England had a profound impact on the \nsocial and economic landscape of the time. It led   |  social and economic landscape of the time. It led \nto significant changes in the way people lived,     |  to significant changes in the way people lived,   \nworked, and interacted with one another. The        |  worked, and interacted with one another. The      \nIndustrial Revolution was driven by the need to     |  Industrial Revolution was driven by the need to   \nincrease productivity and efficiency in the         |  increase productivity and efficiency in the       \nproduction of goods and services, which in turn     |  production of goods and services, which in turn   \nled to the rise of new industries such as           |  led to the rise of new industries such as         \ntextiles, manufacturing, and the railroad.  The     |  textiles, manufacturing, and the railroad.  The   \nIndustrial Revolution had a profound impact on the  |  Industrial Revolution had a profound impact on the\nsocial and economic landscape of the time. It led   |  social and economic landscape of the time. It led \nto significant changes in the way people lived,     |  to the creation of new industries such as         \nworked, and interacted with one another. The        |  textiles, manufacturing, and the railroad, which  \nIndustrial Revolution had a profound impact on the  |  in turn led to the rise of new industries such as \nway people lived, worked, and interacted with one   |  the telephone, telegraph, and telephone lines,    \nanother. It led to the rise of new industries such  |  which were used to connect people to one another. \nas textiles, manufacturing, and the railroad.  The  |  The Industrial Revolution also led to the rise of \nIndustrial Revolution had a profound impact on the  |  new industries such as the telephone, telegraph,  \nway people lived, worked, and interacted with one   |  and telephone lines, which were used to connect   \nanother. It led to significant changes in the way   |  people to one another. This led to the rise of new\npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another.  The Industrial Revolution also   \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another. This  \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another.  The  \nanother. It led to significant changes in the way   |  Industrial Revolution also led to the rise of new \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another. This led to the rise of new       \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another.  The Industrial Revolution also   \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another. This  \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another.  The  \npeople lived, worked, and interacted with one       |  Industrial Revolution also led to the rise of new \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another. This led to the rise of new       \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another.  The Industrial Revolution also   \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another. This  \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another.  The  \nanother. It led to significant changes in the way   |  Industrial Revolution also led to the rise of new \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another. This led to the rise of new       \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another.  The Industrial Revolution also   \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another. This  \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another.  The  \npeople lived, worked, and interacted with one       |  Industrial Revolution also led to the rise of new \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another. This led to the rise of new       \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another.  The Industrial Revolution also   \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another. This  \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another.  The  \nanother. It led to significant changes in the way   |  Industrial Revolution also led to the rise of new \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another. This led to the rise of new       \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another.  The Industrial Revolution also   \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines, which  \npeople lived, worked, and interacted with one       |  were used to connect people to one another. This  \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another.  The  \npeople lived, worked, and interacted with one       |  Industrial Revolution also led to the rise of new \nanother. It led to significant changes in the way   |  industries such as the telephone, telegraph, and  \npeople lived, worked, and interacted with one       |  telephone lines, which were used to connect people\nanother. It led to significant changes in the way   |  to one another. This led to the rise of new       \npeople lived, worked, and interacted with one       |  industries such as the telephone, telegraph, and  \nanother. It led to significant changes in the way   |  telephone lines, which were used to connect people\npeople lived, worked, and interacted with one       |  to one another.  The Industrial Revolution also   \nanother. It led to significant changes in the way   |  led to the rise of new industries such as the     \npeople lived, worked, and interacted with one       |  telephone, telegraph, and telephone lines, which  \nanother. It led to significant changes in the way   |  were used to connect people to one another. This  \npeople lived, worked, and interacted with one       |  led to the rise of new industries such as the     \nanother. It led to significant changes in the way   |  telephone, telegraph, and telephone lines,        \npeople lived, worked, and interacted with one       |                                                    \nanother. It led to significant                      |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-17T02:24:18.337567Z",
          "iopub.execute_input": "2024-11-17T02:24:18.337979Z",
          "iopub.status.idle": "2024-11-17T02:27:36.988059Z",
          "shell.execute_reply.started": "2024-11-17T02:24:18.337939Z",
          "shell.execute_reply": "2024-11-17T02:27:36.987090Z"
        },
        "outputId": "deffe1b5-0716-4bf9-e815-a5683b0b13c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\n<|im_start|>system You are a helpful AI assistant   |  <|im_start|>system You are a helpful AI assistant \nnamed SmolLM, trained by Hugging Face<|im_end|>     |  named SmolLM, trained by Hugging Face<|im_end|>   \n<|im_start|>human How can I calculate the           |  <|im_start|>human How can I calculate the         \nhypotenuse of a right-angled triangle using         |  hypotenuse of a right-angled triangle using       \nPython?<|im_end|> <|im_start|>assistant You can     |  Python?<|im_end|> <|im_start|>assistant You can   \ncalculate the hypotenuse of a right-angled          |  calculate the hypotenuse of a right-angled        \ntriangle using Python by following these steps:     |  triangle using Python by following these steps:   \n```python import math  def hypotenuse(a, b):     #  |  ```python def hypotenuse(a, b):     \"\"\"Calculate  \nCalculate the hypotenuse using the Pythagorean      |  the hypotenuse of a right-angled triangle using   \ntheorem     if a == b:         return math.sqrt(a)  |  the Pythagorean theorem.\"\"\"     if a == b:        \n# If a is not equal to b, return 0     elif a ==    |  return 0     elif a == b:         return 1        \nb:         return 0     # If a is not equal to b,   |  else:         raise ValueError(\"Both inputs must  \nreturn None     elif a == b:         return         |  be equal.\")  # Example usage: a = 5 b = 3 c =     \nmath.inf()     # If a is equal to b, return the     |  hypotenuse(a, b) print(c)  # Output: 6  #         \nhypotenuse     elif a == b:         return          |  Alternative method: a = 5 b = 3 c = hypotenuse(a, \nmath.inf()     # If a is equal to b, return the     |  b) print(c)  # Output: 6  # Explanation: # Both   \nhypotenuse     elif a == b:         return          |  inputs must be equal. # Both inputs must be equal.\nmath.inf()     # If a is equal to b, return None    |  # Both inputs must be equal. # Both inputs must be\nelif a == b:         return None     # If a is      |  equal. # Both inputs must be equal. # Both inputs \nequal to b, return the hypotenuse     elif a == b:  |  must be equal. # Both inputs must be equal. # Both\nreturn None     # If a is equal to b, return the    |  inputs must be equal. # Both inputs must be equal.\nhypotenuse     elif a == b:         return None     |  # Both inputs must be equal. # Both inputs must be\n# If a is equal to b, return the hypotenuse         |  equal. # Both inputs must be equal. # Both inputs \nelif a == b:         return None     # If a is      |  must be equal. # Both inputs must be equal. # Both\nequal to b, return the hypotenuse     elif a == b:  |  inputs must be equal. # Both inputs must be equal.\nreturn None     # If a is equal to b, return the    |  # Both inputs must be equal. # Both inputs must be\nhypotenuse     elif a == b:         return None     |  equal. # Both inputs must be equal. # Both inputs \n# If a is equal to b, return the hypotenuse         |  must be equal. # Both inputs must be equal. # Both\nelif a == b:         return None     # If a is      |  inputs must be equal. # Both inputs must be equal.\nequal to b, return the hypotenuse     elif a == b:  |  # Both inputs must be equal. # Both inputs must be\nreturn None     # If a is equal to b, return the    |  equal. # Both inputs must be equal. # Both inputs \nhypotenuse     elif a == b:         return None     |  must be equal. # Both inputs must be equal. # Both\n# If a is equal to b, return the hypotenuse         |  inputs must be equal. # Both inputs must be equal.\nelif a == b:         return None     # If a is      |  # Both inputs must be equal. # Both inputs must be\nequal to b, return the hypotenuse     elif a == b:  |  equal. # Both inputs must be equal. # Both inputs \nreturn None     # If a is equal to b, return the    |  must be equal. # Both inputs must be equal. # Both\nhypotenuse     elif a == b:         return None     |  inputs must be equal. # Both inputs must be equal.\n# If a is equal to b, return the hypotenuse         |  # Both inputs must be equal. # Both inputs must be\nelif a == b:         return None     # If a is      |  equal. # Both inputs must be equal. # Both inputs \nequal to b, return the hypotenuse     elif a == b:  |  must be equal. # Both inputs must be equal. # Both\nreturn None     # If a is equal to b, return the    |  inputs must be equal. # Both inputs must be equal.\nhypotenuse     elif a == b:         return None     |  # Both inputs must be equal. # Both inputs must be\n# If a is equal to b, return the hypotenuse         |  equal. # Both inputs must be equal. # Both inputs \nelif a == b:         return None     # If a is      |  must be equal. # Both inputs must be equal. # Both\nequal to b, return the hypotenuse     elif a == b:  |  inputs must be equal. # Both inputs must be equal.\nreturn None     # If a is equal to b, return the    |  # Both inputs must be equal. # Both inputs must be\nhypotenuse     elif a == b:         return None     |  equal. # Both inputs must be equal. # Both inputs \n# If a is equal to b, return the hypotenuse         |  must be equal. # Both inputs must be equal. # Both\nelif a == b:         return None     # If a is      |  inputs must be equal. # Both inputs must be equal.\nequal to b, return the hypotenuse     elif a == b:  |  # Both inputs must be equal. # Both inputs must be\nreturn None     # If a is equal to b, return the    |  equal. # Both inputs must be equal. # Both inputs \nhypotenuse     elif a == b:         return None     |  must be equal. # Both inputs must be equal. # Both\n# If a is equal to b, return the hypotenuse         |  inputs must be equal. # Both inputs must be equal.\nelif a == b:         return None     # If a is      |  # Both inputs must be equal. # Both inputs must be\nequal to b, return the hypotenuse     elif a == b:  |  equal. # Both inputs must be equal. # Both inputs \nreturn None     # If a is equal to b, return the    |  must be equal. # Both inputs must be equal. # Both\nhypotenuse     elif a == b:         return None     |  inputs must be equal. # Both inputs must be equal.\n# If a is equal to b, return the hypotenuse         |  # Both inputs must be equal. # Both inputs must be\nelif a == b:         return None     # If a is      |  equal. # Both inputs must be equal. # Both inputs \nequal to b, return the hypotenuse     elif a == b:  |  must be equal. # Both inputs must be equal. # Both\nreturn None     # If a is equal to b, return the    |  inputs must be equal. # Both inputs must be equal.\nhypotenuse     elif a == b:         return None     |  # Both inputs must be equal. # Both inputs must be\n# If a is equal to b, return the hypotenuse         |  equal. # Both inputs must be equal. # Both inputs \nelif a == b:         return None     # If a is      |  must be equal. # Both inputs must be equal. # Both\nequal to b, return the hypotenuse     elif a == b:  |  inputs must be equal. # Both inputs must be equal.\nreturn None     # If a is equal to b, return the    |  # Both inputs must be equal. # Both inputs must be\nhypotenuse     elif a == b:         return None     |  equal. # Both inputs must be equal. # Both inputs \n# If a is equal to b, return the hypotenuse         |  must be equal. # Both inputs must be equal. # Both\nelif a == b:         return None     # If a is      |  inputs must be equal. # Both inputs must be equal.\nequal to b, return the hypotenuse     elif a == b:  |  # Both inputs must be equal. # Both inputs must be\nreturn None     # If a is equal to b, return the    |  equal. # Both inputs must be equal. # Both inputs \nhypotenuse     elif a == b:         return None     |  must be equal. # Both inputs must be equal. # Both\n# If a is equal to b, return the hypotenuse         |  inputs must be equal. # Both inputs must be equal.\nelif a == b:         return None     # If a is      |  # Both inputs must be equal. # Both inputs must be\nequal to b, return the hypotenuse     elif a == b:  |  equal. # Both inputs must be equal. # Both inputs \nreturn None     # If a is equal to b, return the    |  must be equal. # Both inputs must be equal. # Both\nhypotenuse     elif a == b:         return None     |  inputs must be equal. # Both inputs must be equal.\n# If a is equal to b, return the hypotenuse         |  #                                                 \nelif a == b:         return None     # If a is      |                                                    \nequal to b, return the hypotenuse                   |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}