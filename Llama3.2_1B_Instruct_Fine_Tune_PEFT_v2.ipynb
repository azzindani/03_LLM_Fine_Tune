{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Llama3.2_1B_Instruct_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:15.384885Z",
          "iopub.execute_input": "2024-11-24T13:05:15.385744Z",
          "iopub.status.idle": "2024-11-24T13:05:48.653052Z",
          "shell.execute_reply.started": "2024-11-24T13:05:15.385695Z",
          "shell.execute_reply": "2024-11-24T13:05:48.651869Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:48.655047Z",
          "iopub.execute_input": "2024-11-24T13:05:48.655382Z",
          "iopub.status.idle": "2024-11-24T13:05:55.849945Z",
          "shell.execute_reply.started": "2024-11-24T13:05:48.655345Z",
          "shell.execute_reply": "2024-11-24T13:05:55.849059Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:55.851122Z",
          "iopub.execute_input": "2024-11-24T13:05:55.851412Z",
          "iopub.status.idle": "2024-11-24T13:05:55.858097Z",
          "shell.execute_reply.started": "2024-11-24T13:05:55.851384Z",
          "shell.execute_reply": "2024-11-24T13:05:55.857258Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'unsloth/Llama-3.2-1B-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:55.860378Z",
          "iopub.execute_input": "2024-11-24T13:05:55.860659Z",
          "iopub.status.idle": "2024-11-24T13:05:55.877347Z",
          "shell.execute_reply.started": "2024-11-24T13:05:55.860634Z",
          "shell.execute_reply": "2024-11-24T13:05:55.876437Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:55.878522Z",
          "iopub.execute_input": "2024-11-24T13:05:55.878780Z",
          "iopub.status.idle": "2024-11-24T13:05:55.887173Z",
          "shell.execute_reply.started": "2024-11-24T13:05:55.878756Z",
          "shell.execute_reply": "2024-11-24T13:05:55.886399Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:05:55.888185Z",
          "iopub.execute_input": "2024-11-24T13:05:55.888489Z",
          "iopub.status.idle": "2024-11-24T13:06:59.591921Z",
          "shell.execute_reply.started": "2024-11-24T13:05:55.888464Z",
          "shell.execute_reply": "2024-11-24T13:06:59.590973Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:06:59.592977Z",
          "iopub.execute_input": "2024-11-24T13:06:59.593248Z",
          "iopub.status.idle": "2024-11-24T13:06:59.599982Z",
          "shell.execute_reply.started": "2024-11-24T13:06:59.593223Z",
          "shell.execute_reply": "2024-11-24T13:06:59.599048Z"
        },
        "outputId": "c68dc92a-2abb-402b-964c-28d2aa9f79ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 749275136\nTrainable parameters : 262735872\nTrainable percentage: 35.07%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:06:59.601190Z",
          "iopub.execute_input": "2024-11-24T13:06:59.601452Z",
          "iopub.status.idle": "2024-11-24T13:07:02.198619Z",
          "shell.execute_reply.started": "2024-11-24T13:06:59.601426Z",
          "shell.execute_reply": "2024-11-24T13:07:02.197834Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:02.199768Z",
          "iopub.execute_input": "2024-11-24T13:07:02.200165Z",
          "iopub.status.idle": "2024-11-24T13:07:02.204391Z",
          "shell.execute_reply.started": "2024-11-24T13:07:02.200128Z",
          "shell.execute_reply": "2024-11-24T13:07:02.203459Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:02.206973Z",
          "iopub.execute_input": "2024-11-24T13:07:02.207252Z",
          "iopub.status.idle": "2024-11-24T13:07:02.217928Z",
          "shell.execute_reply.started": "2024-11-24T13:07:02.207228Z",
          "shell.execute_reply": "2024-11-24T13:07:02.217197Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:02.218866Z",
          "iopub.execute_input": "2024-11-24T13:07:02.219135Z",
          "iopub.status.idle": "2024-11-24T13:07:05.355207Z",
          "shell.execute_reply.started": "2024-11-24T13:07:02.219111Z",
          "shell.execute_reply": "2024-11-24T13:07:05.354332Z"
        },
        "outputId": "49d7723e-0074-4554-8bd5-bcd300d98472"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.356460Z",
          "iopub.execute_input": "2024-11-24T13:07:05.357163Z",
          "iopub.status.idle": "2024-11-24T13:07:05.364077Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.357118Z",
          "shell.execute_reply": "2024-11-24T13:07:05.363173Z"
        },
        "id": "Mip7IhMRYhsf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.365234Z",
          "iopub.execute_input": "2024-11-24T13:07:05.365527Z",
          "iopub.status.idle": "2024-11-24T13:07:05.385779Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.365501Z",
          "shell.execute_reply": "2024-11-24T13:07:05.385038Z"
        },
        "outputId": "b7306da7-42b6-4673-9ea6-60a91bb24dea"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.386623Z",
          "iopub.execute_input": "2024-11-24T13:07:05.386853Z",
          "iopub.status.idle": "2024-11-24T13:07:05.392503Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.386829Z",
          "shell.execute_reply": "2024-11-24T13:07:05.391552Z"
        },
        "outputId": "9ba64c2c-2b17-4364-983f-693424dc4214"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.393543Z",
          "iopub.execute_input": "2024-11-24T13:07:05.393839Z",
          "iopub.status.idle": "2024-11-24T13:07:05.401120Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.393814Z",
          "shell.execute_reply": "2024-11-24T13:07:05.400342Z"
        },
        "outputId": "f1fc74a5-790d-4603-a2f5-93087291313f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.402071Z",
          "iopub.execute_input": "2024-11-24T13:07:05.402326Z",
          "iopub.status.idle": "2024-11-24T13:07:05.410571Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.402304Z",
          "shell.execute_reply": "2024-11-24T13:07:05.409802Z"
        },
        "id": "mqddl97qYhsg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.411471Z",
          "iopub.execute_input": "2024-11-24T13:07:05.411750Z",
          "iopub.status.idle": "2024-11-24T13:07:05.418280Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.411709Z",
          "shell.execute_reply": "2024-11-24T13:07:05.417469Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.419120Z",
          "iopub.execute_input": "2024-11-24T13:07:05.419375Z",
          "iopub.status.idle": "2024-11-24T13:07:05.430800Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.419336Z",
          "shell.execute_reply": "2024-11-24T13:07:05.429882Z"
        },
        "outputId": "d4757585-718e-4c28-9c85-1a8a154da7e2"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.431717Z",
          "iopub.execute_input": "2024-11-24T13:07:05.432051Z",
          "iopub.status.idle": "2024-11-24T13:07:05.437204Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.432017Z",
          "shell.execute_reply": "2024-11-24T13:07:05.436248Z"
        },
        "outputId": "0bf6d19e-7214-4bb9-c0c1-7ea2f890b2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.438284Z",
          "iopub.execute_input": "2024-11-24T13:07:05.439090Z",
          "iopub.status.idle": "2024-11-24T13:07:05.446036Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.439061Z",
          "shell.execute_reply": "2024-11-24T13:07:05.445267Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:05.447031Z",
          "iopub.execute_input": "2024-11-24T13:07:05.447268Z",
          "iopub.status.idle": "2024-11-24T13:07:14.167545Z",
          "shell.execute_reply.started": "2024-11-24T13:07:05.447246Z",
          "shell.execute_reply": "2024-11-24T13:07:14.166505Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.168747Z",
          "iopub.execute_input": "2024-11-24T13:07:14.169125Z",
          "iopub.status.idle": "2024-11-24T13:07:14.175222Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.169087Z",
          "shell.execute_reply": "2024-11-24T13:07:14.174252Z"
        },
        "outputId": "0b46768f-b221-411d-b9f3-92089b6e04ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.176337Z",
          "iopub.execute_input": "2024-11-24T13:07:14.176676Z",
          "iopub.status.idle": "2024-11-24T13:07:14.253454Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.176639Z",
          "shell.execute_reply": "2024-11-24T13:07:14.252581Z"
        },
        "outputId": "53baea54-20cc-46e0-abdb-1b76c6b7ceb9"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.254739Z",
          "iopub.execute_input": "2024-11-24T13:07:14.255050Z",
          "iopub.status.idle": "2024-11-24T13:07:14.260836Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.254993Z",
          "shell.execute_reply": "2024-11-24T13:07:14.259732Z"
        },
        "outputId": "6f7d6660-e36d-45df-cef6-f88564188c99"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.262251Z",
          "iopub.execute_input": "2024-11-24T13:07:14.262648Z",
          "iopub.status.idle": "2024-11-24T13:07:14.285754Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.262610Z",
          "shell.execute_reply": "2024-11-24T13:07:14.284975Z"
        },
        "outputId": "ee88f0f1-18e1-400a-b4a9-8cba5f14a635"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [128004, 128004, 128004, 128004, 128004, 12800...   \n1  [128004, 128004, 128004, 128004, 128004, 12800...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128004, 128004, 128004, 128004, 128004, 12800...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.286731Z",
          "iopub.execute_input": "2024-11-24T13:07:14.287089Z",
          "iopub.status.idle": "2024-11-24T13:07:14.292709Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.287045Z",
          "shell.execute_reply": "2024-11-24T13:07:14.291834Z"
        },
        "outputId": "44075364-d41d-49a9-9364-cecdf6ea2920"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.293683Z",
          "iopub.execute_input": "2024-11-24T13:07:14.293921Z",
          "iopub.status.idle": "2024-11-24T13:07:14.303362Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.293893Z",
          "shell.execute_reply": "2024-11-24T13:07:14.302470Z"
        },
        "outputId": "4f06abbc-25ba-44ee-dff5-1154254185fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128000, 39314, 374, 459, 7754, 430, 16964, 264, 3465, 11, 35526, 449, 459, 1988, 430, 5825, 4726, 2317, 13, 9842, 264, 2077, 430, 36001, 45695, 279, 1715, 382, 14711, 30151, 512, 2127, 56956, 279, 2728, 33894, 323, 10765, 1202, 1925, 7057, 382, 14711, 5688, 512, 11874, 19795, 37441, 3640, 304, 264, 14071, 7732, 27362, 77, 3112, 14931, 358, 1436, 539, 5944, 2225, 1734, 3112, 387, 832, 63865, 11, 1317, 358, 14980, 1734, 3112, 7111, 1523, 832, 439, 3117, 439, 358, 1436, 1734, 1271, 1405, 433, 30280, 304, 279, 1234, 74189, 18364, 77, 1734, 12487, 3952, 279, 1023, 11, 439, 1120, 439, 6762, 27362, 77, 3112, 3515, 8530, 279, 2731, 3802, 27362, 77, 18433, 433, 574, 16763, 88, 323, 4934, 10051, 18364, 77, 27831, 439, 369, 430, 279, 12579, 1070, 1734, 56568, 24634, 1124, 2216, 922, 279, 1890, 27362, 89330, 19795, 430, 6693, 18813, 11203, 1734, 644, 11141, 912, 3094, 1047, 8348, 11025, 3776, 7255, 77, 12174, 11, 358, 2163, 279, 1176, 369, 2500, 1938, 15114, 77, 29174, 14392, 1268, 1648, 11767, 389, 311, 1648, 27362, 77, 40, 93762, 422, 358, 1288, 3596, 2586, 1203, 7255, 77, 1734, 40, 4985, 387, 11890, 420, 449, 264, 31238, 1734, 50982, 61752, 17051, 323, 17051, 16472, 7338, 77, 11874, 19795, 37441, 3640, 304, 264, 7732, 11, 323, 358, 2345, 59, 77, 40, 3952, 279, 832, 2753, 31796, 555, 27362, 77, 3112, 430, 706, 1903, 682, 279, 6811, 382, 14711, 6075, 512, 791, 1925, 7057, 315, 279, 33894, 374, 279, 12939, 315, 3339, 11709, 323, 279, 5536, 315, 1884, 11709, 389, 832, 596, 2324, 13, 578, 19114, 374, 17011, 449, 264, 5597, 1990, 1403, 13006, 323, 13967, 41011, 279, 832, 2753, 31796, 11, 902, 13967, 21483, 872, 2324, 3217, 13, 128009]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.309357Z",
          "iopub.execute_input": "2024-11-24T13:07:14.309633Z",
          "iopub.status.idle": "2024-11-24T13:07:14.315593Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.309608Z",
          "shell.execute_reply": "2024-11-24T13:07:14.314714Z"
        },
        "outputId": "5bacff4e-17aa-4b0c-f0e4-c7591a137683"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.316649Z",
          "iopub.execute_input": "2024-11-24T13:07:14.316900Z",
          "iopub.status.idle": "2024-11-24T13:07:14.324372Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.316877Z",
          "shell.execute_reply": "2024-11-24T13:07:14.323564Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.325500Z",
          "iopub.execute_input": "2024-11-24T13:07:14.325877Z",
          "iopub.status.idle": "2024-11-24T13:07:14.336805Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.325842Z",
          "shell.execute_reply": "2024-11-24T13:07:14.335919Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.337798Z",
          "iopub.execute_input": "2024-11-24T13:07:14.338106Z",
          "iopub.status.idle": "2024-11-24T13:07:14.348594Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.338081Z",
          "shell.execute_reply": "2024-11-24T13:07:14.347783Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.349628Z",
          "iopub.execute_input": "2024-11-24T13:07:14.349898Z",
          "iopub.status.idle": "2024-11-24T13:07:14.358336Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.349854Z",
          "shell.execute_reply": "2024-11-24T13:07:14.357461Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.359438Z",
          "iopub.execute_input": "2024-11-24T13:07:14.360237Z",
          "iopub.status.idle": "2024-11-24T13:07:14.974145Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.360209Z",
          "shell.execute_reply": "2024-11-24T13:07:14.973227Z"
        },
        "outputId": "9c1ae8dc-b784-42df-d5b8-991b0bb79bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 45,088,768 || all params: 1,280,903,168 || trainable%: 3.5201\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.975381Z",
          "iopub.execute_input": "2024-11-24T13:07:14.975772Z",
          "iopub.status.idle": "2024-11-24T13:07:14.986508Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.975730Z",
          "shell.execute_reply": "2024-11-24T13:07:14.985755Z"
        },
        "outputId": "27bfcc3c-ee04-413b-ba93-1f75b6ba00c1"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=512, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=512, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:14.987621Z",
          "iopub.execute_input": "2024-11-24T13:07:14.987922Z",
          "iopub.status.idle": "2024-11-24T13:07:15.002355Z",
          "shell.execute_reply.started": "2024-11-24T13:07:14.987897Z",
          "shell.execute_reply": "2024-11-24T13:07:15.001433Z"
        },
        "outputId": "56b1a2de-e1a5-4211-967f-97b81cae377c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 794363904\nTrainable parameters : 45088768\nTrainable percentage: 5.68%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:15.003347Z",
          "iopub.execute_input": "2024-11-24T13:07:15.003709Z",
          "iopub.status.idle": "2024-11-24T13:07:15.010626Z",
          "shell.execute_reply.started": "2024-11-24T13:07:15.003667Z",
          "shell.execute_reply": "2024-11-24T13:07:15.009762Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:15.011567Z",
          "iopub.execute_input": "2024-11-24T13:07:15.011825Z",
          "iopub.status.idle": "2024-11-24T13:07:15.049136Z",
          "shell.execute_reply.started": "2024-11-24T13:07:15.011800Z",
          "shell.execute_reply": "2024-11-24T13:07:15.048270Z"
        },
        "outputId": "cc686847-b9b3-4a15-b319-c8c651e33d7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov24_13-07-15_6a1f1d21b7e6,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:15.050302Z",
          "iopub.execute_input": "2024-11-24T13:07:15.050653Z",
          "iopub.status.idle": "2024-11-24T13:07:16.156776Z",
          "shell.execute_reply.started": "2024-11-24T13:07:15.050627Z",
          "shell.execute_reply": "2024-11-24T13:07:16.155976Z"
        },
        "outputId": "0e072c1a-7c93-4141-9273-712365a4eaac"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x78c02e380d30>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:07:16.157811Z",
          "iopub.execute_input": "2024-11-24T13:07:16.158131Z",
          "iopub.status.idle": "2024-11-24T13:30:12.591771Z",
          "shell.execute_reply.started": "2024-11-24T13:07:16.158104Z",
          "shell.execute_reply": "2024-11-24T13:30:12.590891Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:30:12.593114Z",
          "iopub.execute_input": "2024-11-24T13:30:12.593404Z",
          "iopub.status.idle": "2024-11-24T13:31:01.258266Z",
          "shell.execute_reply.started": "2024-11-24T13:30:12.593377Z",
          "shell.execute_reply": "2024-11-24T13:31:01.257374Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:01.259222Z",
          "iopub.execute_input": "2024-11-24T13:31:01.259462Z",
          "iopub.status.idle": "2024-11-24T13:31:03.365779Z",
          "shell.execute_reply.started": "2024-11-24T13:31:01.259438Z",
          "shell.execute_reply": "2024-11-24T13:31:03.364745Z"
        },
        "outputId": "00652e85-686c-415f-cc36-2de85da397eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-1B-Instruct/snapshots/50ea995812f20bf680a17a02cfbc4f90ff4d9c0e/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-1B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 16,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-1B-Instruct/snapshots/50ea995812f20bf680a17a02cfbc4f90ff4d9c0e/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-1B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 16,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:03.366848Z",
          "iopub.execute_input": "2024-11-24T13:31:03.367134Z",
          "iopub.status.idle": "2024-11-24T13:31:03.640699Z",
          "shell.execute_reply.started": "2024-11-24T13:31:03.367107Z",
          "shell.execute_reply": "2024-11-24T13:31:03.639816Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:03.641803Z",
          "iopub.execute_input": "2024-11-24T13:31:03.642118Z",
          "iopub.status.idle": "2024-11-24T13:31:03.652139Z",
          "shell.execute_reply.started": "2024-11-24T13:31:03.642092Z",
          "shell.execute_reply": "2024-11-24T13:31:03.651313Z"
        },
        "id": "qbJ3WO8XYhsk",
        "outputId": "b431b1aa-ba79-4706-f6aa-08e06cc1b71c"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:03.653064Z",
          "iopub.execute_input": "2024-11-24T13:31:03.653349Z",
          "iopub.status.idle": "2024-11-24T13:31:04.388827Z",
          "shell.execute_reply.started": "2024-11-24T13:31:03.653323Z",
          "shell.execute_reply": "2024-11-24T13:31:04.388056Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "uOfUErvoYhsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:04.390060Z",
          "iopub.execute_input": "2024-11-24T13:31:04.390633Z",
          "iopub.status.idle": "2024-11-24T13:31:08.070653Z",
          "shell.execute_reply.started": "2024-11-24T13:31:04.390585Z",
          "shell.execute_reply": "2024-11-24T13:31:08.069890Z"
        },
        "id": "zozPbuzQYhsk",
        "outputId": "e2f836c9-6a18-4308-e986-9d0e01c8b8de"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-1B-Instruct/snapshots/50ea995812f20bf680a17a02cfbc4f90ff4d9c0e/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"unsloth/Llama-3.2-1B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 16,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-1B-Instruct/snapshots/50ea995812f20bf680a17a02cfbc4f90ff4d9c0e/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ]\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/Llama-3.2-1B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-1B-Instruct/snapshots/50ea995812f20bf680a17a02cfbc4f90ff4d9c0e/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 2048)\n    (layers): ModuleList(\n      (0-15): 16 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.071746Z",
          "iopub.execute_input": "2024-11-24T13:31:08.072109Z",
          "iopub.status.idle": "2024-11-24T13:31:08.081213Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.072069Z",
          "shell.execute_reply": "2024-11-24T13:31:08.080476Z"
        },
        "id": "rVeV_NXPYhsk",
        "outputId": "2b5462ba-ee66-4849-e221-ab3958aa96ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 749275136\nTrainable parameters : 262735872\nTrainable percentage: 35.07%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.082091Z",
          "iopub.execute_input": "2024-11-24T13:31:08.082314Z",
          "iopub.status.idle": "2024-11-24T13:31:08.851793Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.082291Z",
          "shell.execute_reply": "2024-11-24T13:31:08.850876Z"
        },
        "id": "1oZhudMvYhsk",
        "outputId": "4dd66651-8918-4dda-dfbf-99451e719ee6"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 2048)\n        (layers): ModuleList(\n          (0-15): 16 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=512, bias=False)\n                  (default): Linear(in_features=64, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=512, bias=False)\n                  (default): Linear(in_features=64, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.852898Z",
          "iopub.execute_input": "2024-11-24T13:31:08.853231Z",
          "iopub.status.idle": "2024-11-24T13:31:08.869911Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.853202Z",
          "shell.execute_reply": "2024-11-24T13:31:08.869174Z"
        },
        "id": "X9nK5d5LYhsk",
        "outputId": "f3721072-4b29-4e48-95e2-c987f63ec7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 839452672\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.871072Z",
          "iopub.execute_input": "2024-11-24T13:31:08.871413Z",
          "iopub.status.idle": "2024-11-24T13:31:08.879750Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.871375Z",
          "shell.execute_reply": "2024-11-24T13:31:08.879136Z"
        },
        "id": "6N5DRBmnYhsl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.880797Z",
          "iopub.execute_input": "2024-11-24T13:31:08.881081Z",
          "iopub.status.idle": "2024-11-24T13:31:08.890055Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.881055Z",
          "shell.execute_reply": "2024-11-24T13:31:08.889164Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.891189Z",
          "iopub.execute_input": "2024-11-24T13:31:08.891524Z",
          "iopub.status.idle": "2024-11-24T13:31:08.901440Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.891486Z",
          "shell.execute_reply": "2024-11-24T13:31:08.900675Z"
        },
        "id": "lTyI5VVLYhsl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:08.902456Z",
          "iopub.execute_input": "2024-11-24T13:31:08.902802Z",
          "iopub.status.idle": "2024-11-24T13:31:27.404267Z",
          "shell.execute_reply.started": "2024-11-24T13:31:08.902766Z",
          "shell.execute_reply": "2024-11-24T13:31:27.403393Z"
        },
        "outputId": "5ca03e28-ece9-41de-d92a-3d89e388a4c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    749275136                      |                     839452672                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Classify   |  completes the request.  ### Instruction: Classify \nthe following news report into three categories:    |  the following news report into three categories:  \nPolitics, Economics and Social.  ### Input: The     |  Politics, Economics and Social.  ### Input: The   \nUnited Nations Security Council has unanimously     |  United Nations Security Council has unanimously   \nadopted resolution 2371 that establishes a tough    |  adopted resolution 2371 that establishes a tough  \nnew sanctions regime against North Korea in         |  new sanctions regime against North Korea in       \nresponse to its ongoing weapons program.  ###       |  response to its ongoing weapons program.  ###     \nResponse: The news report is classified as          |  Response: The news report is classified as        \nfollows:  - **Politics:** The resolution 2371 is a  |  follows:  - **Politics:** The resolution 2371 is a\npolitical decision made by the United Nations       |  political decision made by the United Nations     \nSecurity Council, which is an international         |  Security Council, which is an international       \norganization that aims to maintain peace and        |  organization that aims to maintain peace and      \nsecurity in the world. The resolution is a          |  security in the world. The resolution is a        \nresponse to North Korea's ongoing weapons program,  |  response to North Korea's ongoing weapons program,\nwhich is considered a threat to regional and        |  which is considered a threat to regional and      \nglobal security.  - **Economics:** The sanctions    |  global security.  - **Economics:** The sanctions  \nregime established by the resolution 2371 is an     |  regime established by the resolution 2371 is an   \neconomic measure aimed at limiting North Korea's    |  economic measure aimed at limiting North Korea's  \naccess to international trade and finance. The      |  access to international trade and finance. The    \nresolution aims to restrict North Korea's ability   |  resolution aims to restrict North Korea's ability \nto acquire and export goods, including military     |  to acquire and export goods, including military   \nequipment and technology.  - **Social:** The        |  equipment and technology.  - **Social:** The      \nresolution 2371 is also a social issue, as it       |  resolution 2371 is also a social issue, as it     \naffects the lives of millions of North Koreans who  |  affects the lives of millions of North Koreans who\nare facing severe economic hardship and food        |  are living in poverty and facing severe food      \nshortages due to the ongoing sanctions. The         |  shortages. The resolution is a response to North  \nresolution aims to alleviate the suffering of       |  Korea's human rights abuses and its failure to    \nNorth Koreans and to promote peace and stability    |  comply with international humanitarian law. The   \nin the region.                                      |  sanctions regime is intended to alleviate the     \n                                                    |  suffering of North Koreans and to pressure the    \n                                                    |  North Korean government to change its behavior.   \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:27.405296Z",
          "iopub.execute_input": "2024-11-24T13:31:27.405548Z",
          "iopub.status.idle": "2024-11-24T13:31:38.167410Z",
          "shell.execute_reply.started": "2024-11-24T13:31:27.405524Z",
          "shell.execute_reply": "2024-11-24T13:31:38.166421Z"
        },
        "outputId": "7ab225fe-4ca3-4da2-8691-e08f3c2b6431"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    749275136                      |                     839452672                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Come up    |  completes the request.  ### Instruction: Come up  \nwith a riddle  ### Input:   ### Response: The       |  with a riddle  ### Input:   ### Response: The     \nriddle is: \"I am always coming but never arrive.    |  riddle is: \"I am always coming but never arrive.  \nWhat am I?\"   ### Explanation: The riddle is a      |  What am I?\"   ### Explanation: The riddle is a    \nclassic example of a lateral thinking riddle. It    |  classic example of a lateral thinking puzzle. The \nrequires the solver to think creatively and make    |  answer is not a physical object, but rather a     \nconnections between seemingly unrelated concepts.   |  concept or idea. The correct answer is \"tomorrow\".\nIn this case, the answer is \"tomorrow\". Tomorrow    |  Tomorrow is always coming, but it never actually  \nis always coming, but it never actually arrives,    |  arrives, because when it does, it becomes today.  \nas it is still in the future. This riddle requires  |  This riddle requires the solver to think          \nthe solver to understand the concept of time and    |  creatively and consider the nature of time and its\nhow it relates to the idea of \"arrival\". The        |  relationship to the concept of arrival.           \nanswer is not a physical object, but rather a       |                                                    \nconcept or idea. The solver must use their          |                                                    \ncritical thinking skills to arrive at the correct   |                                                    \nanswer.                                             |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:31:38.168350Z",
          "iopub.execute_input": "2024-11-24T13:31:38.168590Z",
          "iopub.status.idle": "2024-11-24T13:33:00.574661Z",
          "shell.execute_reply.started": "2024-11-24T13:31:38.168564Z",
          "shell.execute_reply": "2024-11-24T13:33:00.573721Z"
        },
        "outputId": "3ae3a03c-60fa-4cd2-f86c-8b84ba85e7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    749275136                      |                     839452672                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse: In the quaint town of Willow Creek,       |  Response: In the quaint town of Willow Creek,     \nnestled between the rolling hills of the            |  nestled between the rolling hills of the          \ncountryside, there lived a young woman named        |  countryside, there lived a young woman named      \nEmily. She was a talented artist, known for her     |  Emily. She was a talented artist, known for her   \nvibrant paintings that captured the essence of the  |  vibrant paintings that captured the essence of the\nnatural world. Emily's life was filled with love    |  natural world. Emily's life was filled with love  \nand beauty, but it was not without its challenges.  |  and beauty, but it was not without its challenges.\nShe had lost her mother to a tragic accident when   |  She had lost her mother to a tragic accident when \nshe was just a child. Her father, a kind and        |  she was just a child. Her father, a kind and      \ngentle man, had remarried, but the marriage was     |  gentle man, had remarried, but the marriage was   \nshort-lived. Emily's father had passed away a year  |  short-lived. Emily's father had passed away a year\nago, leaving her with a deep sense of loss and      |  ago, leaving her with a deep sense of loss and    \nlonging.  One day, while out on a walk, Emily       |  longing.  One day, while out on a walk, Emily     \nstumbled upon a small, antique bookstore. The       |  stumbled upon a small, antique bookstore. The     \nstore was tucked away in a quiet alley, and its     |  store was tucked away in a quiet alley, and its   \nentrance was marked by a beautiful, hand-carved     |  entrance was marked by a beautiful, hand-carved   \nwooden sign. The store's owner, an elderly man      |  wooden sign. The store's owner, an elderly man    \nnamed Mr. Jenkins, welcomed Emily with a warm       |  named Mr. Jenkins, welcomed Emily with a warm     \nsmile. He was a kind and wise man, with a deep      |  smile. He was a kind and wise man, with a deep    \nunderstanding of the human heart. As Emily browsed  |  understanding of the human heart. As Emily browsed\nthe shelves, she found herself drawn to a book      |  the shelves, she found herself drawn to a book    \nwith a beautiful, leather-bound cover. The book     |  with a beautiful, leather-bound cover. The book   \nwas titled \"The Art of Love and Loss.\" It was a     |  was titled \"The Art of Love and Loss.\" It was a   \ncollection of stories, each one a testament to the  |  collection of stories, each one a testament to the\npower of love and the devastating consequences of   |  power of love and the devastating consequences of \nloss.  As Emily delved deeper into the book, she    |  loss.  As Emily delved deeper into the book, she  \nbegan to read about the lives of others who had     |  found herself becoming increasingly entranced. She\nexperienced love and loss. She read about a young   |  began to read the stories, and they spoke to her  \ncouple who had lost their child, about a man who    |  on a deep, emotional level. She felt a sense of   \nhad lost his wife, and about a woman who had lost   |  connection to the characters, and her heart began \nher way. With each story, Emily felt a deep sense   |  to heal. But as she read on, she realized that the\nof connection to the people who had experienced     |  stories were not just about love and loss, but    \nthese emotions. She began to see that love and      |  also about the power of memories to transcend     \nloss were not just abstract concepts, but living,   |  time.  As Emily continued to read, she began to   \nbreathing things that could be felt and             |  feel a sense of longing. She missed her father    \nexperienced.  As Emily continued to read, she felt  |  dearly, and the pain of his loss still lingered.  \na sense of peace wash over her. She realized that   |  She felt a deep connection to the stories, and she\nshe was not alone in her feelings of loss and       |  began to see that the power of love and loss was  \nlonging. She felt a sense of connection to the      |  not just about the past, but also about the       \npeople who had come before her, and to those who    |  present and the future.  As the days passed, Emily\nwere still struggling to find their way. Emily's    |  found herself becoming increasingly withdrawn. She\nheart was filled with a sense of hope and renewal.  |  stopped going out with her friends, and she began \nShe knew that she would never be able to fully      |  to spend more and more time alone, lost in the    \nescape the pain of her past, but she also knew      |  pages of the book. She felt a sense of isolation, \nthat she could learn to live with it.  As the sun   |  and she began to wonder if she was truly alone.   \nbegan to set, Emily closed the book and returned    |  But then, one day, Emily received a letter from   \nto the bookstore. She felt a sense of gratitude     |  Mr. Jenkins. He had been watching her, and he had \ntowards Mr. Jenkins, who had given her a gift that  |  noticed that she was struggling. He had been      \nwould stay with her forever. She realized that the  |  waiting for the right moment to reach out to her, \ntrue value of the book lay not in its pages, but    |  and now was the time. He invited Emily to meet him\nin the connections it had made with her heart.      |  at the bookstore, and he asked her to come and    \nEmily's story was one of love and loss, but it was  |  talk to him.  Emily was hesitant at first, but    \nalso a story of hope and resilience. She knew that  |  something about Mr. Jenkins' words resonated with \nshe would always carry the scars of her past with   |  her. She agreed to meet him, and she found herself\nher, but she also knew that she could learn to      |  walking to the bookstore, her heart pounding in   \nlive with them.  ### Output: A story of love and    |  her chest. When she arrived, she saw that Mr.     \nloss, told through the eyes of a young woman named  |  Jenkins was waiting for her, his eyes filled with \nEmily, who has experienced the pain of losing her   |  kindness and understanding.  \"Emily, I know that  \nmother and her father. The story is told through    |  you're struggling,\" Mr. Jenkins said, his voice   \nthe pages of an antique book, which holds the       |  filled with compassion. \"I know that you're still \npower of love and loss. Emily's journey is one of   |  grieving, and that you're still searching for a   \nhope and resilience, as she learns to live with     |  way to heal. But I want you to know that you're   \nthe pain of her past and to find peace in the       |  not alone. You're not alone in your pain, and     \npresent.                                            |  you're not alone in your heartache.\"  Emily felt a\n                                                    |  sense of relief wash over her. She realized that  \n                                                    |  she was not alone, and that she was not alone in  \n                                                    |  her pain. She felt a sense of connection to Mr.   \n                                                    |  Jenkins, and she began to see that the power of   \n                                                    |  love and loss was not just about the past, but    \n                                                    |  also about the present and the future.  As Emily  \n                                                    |  continued to read the book, she found herself     \n                                                    |  becoming more and more entranced. She began to see\n                                                    |  that the stories were not just about love and     \n                                                    |  loss, but also about the power of memories to     \n                                                    |  transcend time. She realized that the power of    \n                                                    |  love and loss was not just about the past, but    \n                                                    |  also about the present and the future.  And so,   \n                                                    |  Emily's journey came to an end. She had found a   \n                                                    |  new sense of purpose, and she had discovered a new\n                                                    |  way of living. She had learned that the power of  \n                                                    |  love and loss was not just about the past, but    \n                                                    |  also about the present and the future. She had    \n                                                    |  learned that love and loss were not just about the\n                                                    |  heartache, but also about the beauty of the human \n                                                    |  experience.  ### Response: In the quaint town of  \n                                                    |  Willow Creek, nestled between the rolling hills of\n                                                    |  the countryside, there lived a young woman named  \n                                                    |  Emily. She was a talented artist, known for her   \n                                                    |  vibrant paintings that captured the essence of the\n                                                    |  natural world. Emily's life was filled with love  \n                                                    |  and beauty, but it was not without its challenges.\n                                                    |  She had lost her mother to a tragic accident when \n                                                    |  she was just a child. Her father, a kind and      \n                                                    |  gentle man, had remarried, but the marriage was   \n                                                    |  short-lived. Emily's father had passed away a year\n                                                    |  ago, leaving her with a deep sense of loss and    \n                                                    |  longing.  One day, while out on a walk, Emily     \n                                                    |  stumbled upon                                     \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:34:29.415734Z",
          "iopub.execute_input": "2024-11-24T13:34:29.416426Z",
          "iopub.status.idle": "2024-11-24T13:34:59.751049Z",
          "shell.execute_reply.started": "2024-11-24T13:34:29.416389Z",
          "shell.execute_reply": "2024-11-24T13:34:59.750169Z"
        },
        "outputId": "ec2d0860-612e-498b-c4d5-656d54b6d0e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    749275136                      |                     839452672                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Three      |  completes the request.  ### Instruction: Three    \npositive integers have a sum of 72 and are in the   |  positive integers have a sum of 72 and are in the \nratio 1:3:4. What is the least of these three       |  ratio 1:3:4. What is the least of these three     \nintegers?  ### Input:   ### Response: The three     |  integers?  ### Input:   ### Response: The three   \npositive integers are 1x, 3x, and 4x. Since they    |  positive integers are 1x, 3x, and 4x. Since they  \nare in the ratio 1:3:4, we can express them as 1x,  |  are in the ratio 1:3:4, we can express them as 1x,\n3x, and 4x. To find the least of these three        |  3x, and 4x. To find the least of these three      \nintegers, we need to find the smallest value of x.  |  integers, we need to find the smallest value of x.\nWe can do this by setting up an equation based on   |  We can do this by setting up an equation based on \nthe sum of the three integers. The sum of the       |  the sum of the three integers. The sum of the     \nthree integers is 72, so we can write the equation  |  three integers is 72, so we can write the equation\nas 1x + 3x + 4x = 72. Simplifying the equation, we  |  as 1x + 3x + 4x = 72. Simplifying the equation, we\nget 8x = 72. Dividing both sides by 8, we find      |  get 8x = 72. Solving for x, we get x = 72/8 = 9.  \nthat x = 9. Therefore, the three integers are 1x =  |  Therefore, the three positive integers are 1x = 9,\n9, 3x = 27, and 4x = 36. The least of these three   |  3x = 27, and 4x = 36. The least of these three    \nintegers is 9.  ### Note: This problem is a         |  integers is 9.  ### Explanation: To find the least\nclassic example of a \"chicken and egg\" problem,     |  of the three integers, we need to find the        \nwhere the solution requires finding the value of x  |  smallest value of x. We can do this by setting up \nfirst, and then using that value to find the three  |  an equation based on the sum of the three         \nintegers. The key insight here is that the ratio    |  integers. The sum of the three integers is 72, so \nof the integers is 1:3:4, which means that the      |  we can write the equation as 1x + 3x + 4x = 72.   \nvalue of x is the same for all three integers.      |  Simplifying the equation, we get 8x = 72. Solving \nTherefore, we can find the least of the three       |  for x, we get x = 72/8 = 9. Therefore, the three  \nintegers by finding the smallest value of x. In     |  positive integers are 1x = 9, 3x = 27, and 4x =   \nthis case, the smallest value of x is 9.            |  36. The least of these three integers is 9.       \nTherefore, the least of the three integers is 9.    |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T13:37:35.419779Z",
          "iopub.execute_input": "2024-11-24T13:37:35.420170Z",
          "iopub.status.idle": "2024-11-24T13:37:58.423719Z",
          "shell.execute_reply.started": "2024-11-24T13:37:35.420136Z",
          "shell.execute_reply": "2024-11-24T13:37:58.422780Z"
        },
        "outputId": "cf634725-c7e0-45b2-b480-5288412b4a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    749275136                      |                     839452672                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: List two   |  completes the request.  ### Instruction: List two \nproblems caused by climate change  ### Input:       |  problems caused by climate change  ### Input:     \n### Response: 1. **Rising Sea Levels**: One of the  |  ### Response: 1. **Rising Sea Levels**: One of the\nmost significant problems caused by climate change  |  most significant problems caused by climate change\nis the rising sea levels. As the planet warms, the  |  is the rising sea levels. As the planet warms, the\nice at the poles melts, and the water that freezes  |  ice at the poles melts, and the water that freezes\nin the polar regions expands. This causes the sea   |  in the polar regions expands. This causes the sea \nlevels to rise, leading to coastal erosion,         |  levels to rise, leading to coastal erosion,       \nflooding, and saltwater intrusion into freshwater   |  flooding, and saltwater intrusion into freshwater \nsources. The consequences of this include more      |  sources. The consequences of this include more    \nfrequent and severe flooding, saltwater             |  frequent and severe flooding, saltwater           \ncontamination of drinking water, and loss of        |  contamination of drinking water, and loss of      \nhabitats for marine species.  2. **Extreme Weather  |  habitats for marine species.  2. **Extreme Weather\nEvents**: Another problem caused by climate change  |  Events**: Another problem caused by climate change\nis the increase in extreme weather events such as   |  is the increase in extreme weather events such as \nheatwaves, droughts, and heavy rainfall. These      |  heatwaves, droughts, and heavy rainfall. As the   \nevents can have devastating impacts on ecosystems,  |  planet warms, the atmosphere holds more heat,     \nagriculture, and human health. For example,         |  leading to more frequent and intense heatwaves.   \nheatwaves can lead to heat-related illnesses and    |  This can cause widespread damage to crops,        \ndeaths, while droughts can cause crop failures and  |  infrastructure, and human health. Additionally,   \nfood shortages. Heavy rainfall can cause flash      |  the melting of glaciers and ice sheets can lead to\nflooding, landslides, and soil erosion, leading to  |  sea-level rise, which can cause coastal flooding  \nloss of life and property.  ### Note: Please        |  and erosion.  ### Note: Please provide a response \nprovide a response that is at least 100 words,      |  that is at least 100 words, addressing both       \naddressing both problems caused by climate change.  |  problems caused by climate change. The response   \nThe response should include specific examples and   |  should include a clear explanation of the causes  \nstatistics to support the claims. It should also    |  and effects of these problems, as well as         \ninclude a clear explanation of the causes and       |  potential solutions or mitigations.               \neffects of these problems.                          |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}