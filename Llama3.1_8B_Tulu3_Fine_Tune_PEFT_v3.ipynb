{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Llama3.1_8B_Tulu3_Fine_Tune_PEFT_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:51:06.691424Z",
          "iopub.execute_input": "2024-12-14T23:51:06.691701Z",
          "iopub.status.idle": "2024-12-14T23:52:10.288100Z",
          "shell.execute_reply.started": "2024-12-14T23:51:06.691674Z",
          "shell.execute_reply": "2024-12-14T23:52:10.286870Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-12-14T23:52:10.290423Z",
          "iopub.execute_input": "2024-12-14T23:52:10.290822Z",
          "iopub.status.idle": "2024-12-14T23:52:29.018697Z",
          "shell.execute_reply.started": "2024-12-14T23:52:10.290768Z",
          "shell.execute_reply": "2024-12-14T23:52:29.017831Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-12-14T23:52:29.019994Z",
          "iopub.execute_input": "2024-12-14T23:52:29.020311Z",
          "iopub.status.idle": "2024-12-14T23:52:29.026704Z",
          "shell.execute_reply.started": "2024-12-14T23:52:29.020283Z",
          "shell.execute_reply": "2024-12-14T23:52:29.025668Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'unsloth/Llama-3.1-Tulu-3-8B'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:52:29.028726Z",
          "iopub.execute_input": "2024-12-14T23:52:29.029065Z",
          "iopub.status.idle": "2024-12-14T23:52:29.052214Z",
          "shell.execute_reply.started": "2024-12-14T23:52:29.029030Z",
          "shell.execute_reply": "2024-12-14T23:52:29.051452Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:52:29.053179Z",
          "iopub.execute_input": "2024-12-14T23:52:29.053421Z",
          "iopub.status.idle": "2024-12-14T23:52:29.064152Z",
          "shell.execute_reply.started": "2024-12-14T23:52:29.053398Z",
          "shell.execute_reply": "2024-12-14T23:52:29.063336Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:52:29.065240Z",
          "iopub.execute_input": "2024-12-14T23:52:29.065626Z",
          "iopub.status.idle": "2024-12-14T23:59:41.896085Z",
          "shell.execute_reply.started": "2024-12-14T23:52:29.065589Z",
          "shell.execute_reply": "2024-12-14T23:59:41.895337Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:41.897221Z",
          "iopub.execute_input": "2024-12-14T23:59:41.897834Z",
          "iopub.status.idle": "2024-12-14T23:59:41.905484Z",
          "shell.execute_reply.started": "2024-12-14T23:59:41.897774Z",
          "shell.execute_reply": "2024-12-14T23:59:41.904592Z"
        },
        "outputId": "47cf5365-2955-44b6-a272-33b209b6259a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540665856\nTrainable parameters : 1051004928\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:41.906489Z",
          "iopub.execute_input": "2024-12-14T23:59:41.906742Z",
          "iopub.status.idle": "2024-12-14T23:59:43.976473Z",
          "shell.execute_reply.started": "2024-12-14T23:59:41.906719Z",
          "shell.execute_reply": "2024-12-14T23:59:43.975775Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'microsoft/orca-math-word-problems-200k'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:43.977470Z",
          "iopub.execute_input": "2024-12-14T23:59:43.977696Z",
          "iopub.status.idle": "2024-12-14T23:59:43.981688Z",
          "shell.execute_reply.started": "2024-12-14T23:59:43.977670Z",
          "shell.execute_reply": "2024-12-14T23:59:43.980853Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:43.985461Z",
          "iopub.execute_input": "2024-12-14T23:59:43.985709Z",
          "iopub.status.idle": "2024-12-14T23:59:43.993513Z",
          "shell.execute_reply.started": "2024-12-14T23:59:43.985685Z",
          "shell.execute_reply": "2024-12-14T23:59:43.992845Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:43.994422Z",
          "iopub.execute_input": "2024-12-14T23:59:43.994654Z",
          "iopub.status.idle": "2024-12-14T23:59:48.961198Z",
          "shell.execute_reply.started": "2024-12-14T23:59:43.994631Z",
          "shell.execute_reply": "2024-12-14T23:59:48.960441Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:48.962305Z",
          "iopub.execute_input": "2024-12-14T23:59:48.962654Z",
          "iopub.status.idle": "2024-12-14T23:59:48.969398Z",
          "shell.execute_reply.started": "2024-12-14T23:59:48.962615Z",
          "shell.execute_reply": "2024-12-14T23:59:48.968576Z"
        },
        "id": "ciYvULNdX_Nn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:48.970404Z",
          "iopub.execute_input": "2024-12-14T23:59:48.970653Z",
          "iopub.status.idle": "2024-12-14T23:59:49.034578Z",
          "shell.execute_reply.started": "2024-12-14T23:59:48.970629Z",
          "shell.execute_reply": "2024-12-14T23:59:49.033775Z"
        },
        "outputId": "fd9f475c-fc3e-4ad1-9d34-fbb6fcf7445e"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.035685Z",
          "iopub.execute_input": "2024-12-14T23:59:49.036029Z",
          "iopub.status.idle": "2024-12-14T23:59:49.043403Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.035993Z",
          "shell.execute_reply": "2024-12-14T23:59:49.042488Z"
        },
        "outputId": "3efa003d-b4fa-4a7b-d632-80ee056a71f0"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.044430Z",
          "iopub.execute_input": "2024-12-14T23:59:49.044691Z",
          "iopub.status.idle": "2024-12-14T23:59:49.052507Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.044667Z",
          "shell.execute_reply": "2024-12-14T23:59:49.051613Z"
        },
        "outputId": "bee287bd-fc06-46c3-e38f-2b8b2de7a364"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['question', 'answer']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.053696Z",
          "iopub.execute_input": "2024-12-14T23:59:49.054445Z",
          "iopub.status.idle": "2024-12-14T23:59:49.064419Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.054417Z",
          "shell.execute_reply": "2024-12-14T23:59:49.063602Z"
        },
        "id": "WgKEd2cNX_No"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  input = examples['question']\n",
        "  output = examples['answer']\n",
        "\n",
        "  text = prompt_format.format(input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.065437Z",
          "iopub.execute_input": "2024-12-14T23:59:49.065744Z",
          "iopub.status.idle": "2024-12-14T23:59:49.074537Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.065710Z",
          "shell.execute_reply": "2024-12-14T23:59:49.073719Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.075474Z",
          "iopub.execute_input": "2024-12-14T23:59:49.075750Z",
          "iopub.status.idle": "2024-12-14T23:59:49.527427Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.075727Z",
          "shell.execute_reply": "2024-12-14T23:59:49.526578Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.528454Z",
          "iopub.execute_input": "2024-12-14T23:59:49.528719Z",
          "iopub.status.idle": "2024-12-14T23:59:49.533650Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.528694Z",
          "shell.execute_reply": "2024-12-14T23:59:49.532829Z"
        },
        "outputId": "c82ac8b3-43ce-4018-b217-d84e2779e12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.534755Z",
          "iopub.execute_input": "2024-12-14T23:59:49.535090Z",
          "iopub.status.idle": "2024-12-14T23:59:49.558647Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.535054Z",
          "shell.execute_reply": "2024-12-14T23:59:49.557913Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:49.559473Z",
          "iopub.execute_input": "2024-12-14T23:59:49.559676Z",
          "iopub.status.idle": "2024-12-14T23:59:58.039372Z",
          "shell.execute_reply.started": "2024-12-14T23:59:49.559656Z",
          "shell.execute_reply": "2024-12-14T23:59:58.038621Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.040330Z",
          "iopub.execute_input": "2024-12-14T23:59:58.040597Z",
          "iopub.status.idle": "2024-12-14T23:59:58.047186Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.040572Z",
          "shell.execute_reply": "2024-12-14T23:59:58.046151Z"
        },
        "outputId": "4ef09b11-7d10-4c06-d61c-5be910d81fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.048286Z",
          "iopub.execute_input": "2024-12-14T23:59:58.048621Z",
          "iopub.status.idle": "2024-12-14T23:59:58.111391Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.048585Z",
          "shell.execute_reply": "2024-12-14T23:59:58.110585Z"
        },
        "outputId": "7fbe4ded-8942-43e1-aa0a-25f409560b72"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.112387Z",
          "iopub.execute_input": "2024-12-14T23:59:58.112720Z",
          "iopub.status.idle": "2024-12-14T23:59:58.120032Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.112674Z",
          "shell.execute_reply": "2024-12-14T23:59:58.119324Z"
        },
        "outputId": "ff110ca2-51b9-4fd1-d795-9dffae0b1710"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.121164Z",
          "iopub.execute_input": "2024-12-14T23:59:58.121486Z",
          "iopub.status.idle": "2024-12-14T23:59:58.148242Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.121451Z",
          "shell.execute_reply": "2024-12-14T23:59:58.147588Z"
        },
        "outputId": "8a04a589-8299-4581-e864-5591ae97efca"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [128000, 14711, 16225, 512, 3947, 374, 264, 14...   \n1  [128000, 14711, 16225, 512, 644, 264, 2466, 38...   \n2  [128256, 128256, 128256, 128256, 128256, 12825...   \n3  [128256, 128256, 128256, 128256, 128256, 12825...   \n4  [128000, 14711, 16225, 512, 3947, 374, 264, 52...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 14...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[128000, 14711, 16225, 512, 644, 264, 2466, 38...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[128256, 128256, 128256, 128256, 128256, 12825...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 52...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.149069Z",
          "iopub.execute_input": "2024-12-14T23:59:58.149303Z",
          "iopub.status.idle": "2024-12-14T23:59:58.154576Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.149280Z",
          "shell.execute_reply": "2024-12-14T23:59:58.153693Z"
        },
        "outputId": "458497d7-7e11-4ce1-ba7e-08da57e0fd24"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|end_of_text|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.155674Z",
          "iopub.execute_input": "2024-12-14T23:59:58.156095Z",
          "iopub.status.idle": "2024-12-14T23:59:58.165457Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.156058Z",
          "shell.execute_reply": "2024-12-14T23:59:58.164535Z"
        },
        "outputId": "dd638a9d-9a40-4674-ebc2-e7dda4722bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[128000, 14711, 16225, 512, 3947, 374, 264, 1403, 49442, 5933, 1396, 6832, 22781, 2035, 374, 220, 18, 13, 6914, 362, 323, 426, 387, 279, 75862, 315, 420, 1396, 555, 220, 605, 323, 279, 27410, 315, 13096, 555, 220, 605, 11, 15947, 13, 1442, 426, 56016, 555, 220, 605, 5636, 362, 374, 220, 24, 2753, 1109, 362, 56016, 555, 220, 605, 5636, 426, 11, 1148, 374, 279, 1176, 1396, 5380, 14711, 22559, 512, 10267, 596, 79164, 279, 1403, 49442, 1396, 439, 18240, 58419, 1144, 705, 1405, 18240, 1630, 1144, 8, 374, 279, 16099, 304, 279, 22781, 2035, 323, 18240, 816, 1144, 8, 374, 279, 16099, 304, 279, 6305, 2035, 13, 8876, 279, 22781, 2035, 374, 220, 18, 11, 584, 617, 18240, 1630, 284, 220, 18, 1144, 3677, 11439, 311, 279, 3575, 11, 18240, 362, 1144, 8, 374, 279, 75862, 315, 279, 1396, 555, 220, 605, 11, 323, 18240, 426, 1144, 8, 374, 279, 27410, 315, 279, 13096, 555, 220, 605, 13, 15636, 11, 18240, 362, 284, 1630, 284, 220, 18, 1144, 8, 323, 18240, 426, 284, 816, 1144, 3677, 791, 3575, 5415, 430, 18240, 426, 1144, 15487, 220, 605, 489, 362, 1144, 8, 374, 220, 24, 2753, 1109, 18240, 362, 1144, 15487, 220, 605, 489, 426, 1144, 570, 1115, 649, 387, 5439, 439, 459, 24524, 1473, 79145, 426, 1144, 15487, 220, 605, 489, 362, 284, 362, 1144, 15487, 220, 605, 489, 426, 482, 220, 24, 1144, 2595, 3214, 3781, 10831, 18240, 362, 1144, 8, 323, 18240, 426, 1144, 8, 449, 18240, 220, 18, 1144, 8, 323, 18240, 816, 1144, 705, 15947, 11, 584, 636, 1473, 79145, 816, 1144, 15487, 220, 605, 489, 220, 18, 284, 220, 18, 1144, 15487, 220, 605, 489, 816, 482, 220, 24, 1144, 2595, 50, 6517, 7922, 279, 24524, 1473, 79145, 220, 605, 56, 489, 220, 18, 284, 220, 966, 489, 816, 482, 220, 24, 1144, 2595, 79145, 220, 605, 56, 489, 220, 18, 284, 816, 489, 220, 1691, 1144, 2595, 3214, 2193, 18240, 816, 1144, 8, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 489, 220, 18, 284, 220, 1691, 1144, 2595, 3214, 2193, 220, 18, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 284, 220, 972, 1144, 2595, 12792, 579, 2225, 11314, 555, 220, 24, 1473, 79145, 816, 284, 220, 17, 1144, 2595, 4516, 279, 6305, 2035, 16099, 374]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.170686Z",
          "iopub.execute_input": "2024-12-14T23:59:58.170950Z",
          "iopub.status.idle": "2024-12-14T23:59:58.176273Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.170927Z",
          "shell.execute_reply": "2024-12-14T23:59:58.175359Z"
        },
        "outputId": "aff0f6d9-f616-44bf-f82a-45d4af1dc9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.177103Z",
          "iopub.execute_input": "2024-12-14T23:59:58.177336Z",
          "iopub.status.idle": "2024-12-14T23:59:58.185519Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.177314Z",
          "shell.execute_reply": "2024-12-14T23:59:58.184787Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.186534Z",
          "iopub.execute_input": "2024-12-14T23:59:58.186821Z",
          "iopub.status.idle": "2024-12-14T23:59:58.198656Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.186776Z",
          "shell.execute_reply": "2024-12-14T23:59:58.198026Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.199619Z",
          "iopub.execute_input": "2024-12-14T23:59:58.199978Z",
          "iopub.status.idle": "2024-12-14T23:59:58.209232Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.199942Z",
          "shell.execute_reply": "2024-12-14T23:59:58.208434Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 32\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "\n",
        "#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.210040Z",
          "iopub.execute_input": "2024-12-14T23:59:58.210251Z",
          "iopub.status.idle": "2024-12-14T23:59:58.220342Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.210229Z",
          "shell.execute_reply": "2024-12-14T23:59:58.219563Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T23:59:58.221312Z",
          "iopub.execute_input": "2024-12-14T23:59:58.221628Z",
          "iopub.status.idle": "2024-12-15T00:00:00.024169Z",
          "shell.execute_reply.started": "2024-12-14T23:59:58.221591Z",
          "shell.execute_reply": "2024-12-15T00:00:00.023211Z"
        },
        "outputId": "83c3e527-2ee0-4268-fee8-20001e462387"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 83,886,080 || all params: 8,114,212,864 || trainable%: 1.0338\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T00:00:00.025125Z",
          "iopub.execute_input": "2024-12-15T00:00:00.025471Z",
          "iopub.status.idle": "2024-12-15T00:00:00.049048Z",
          "shell.execute_reply.started": "2024-12-15T00:00:00.025435Z",
          "shell.execute_reply": "2024-12-15T00:00:00.048326Z"
        },
        "outputId": "c3b95cce-1e0a-4a10-ab5f-e0e060f5aafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4624551936\nTrainable parameters : 83886080\nTrainable percentage: 1.81%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T00:00:00.049849Z",
          "iopub.execute_input": "2024-12-15T00:00:00.050157Z",
          "iopub.status.idle": "2024-12-15T00:00:00.054534Z",
          "shell.execute_reply.started": "2024-12-15T00:00:00.050120Z",
          "shell.execute_reply": "2024-12-15T00:00:00.053847Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 1\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T00:00:00.055880Z",
          "iopub.execute_input": "2024-12-15T00:00:00.056177Z",
          "iopub.status.idle": "2024-12-15T00:00:00.109465Z",
          "shell.execute_reply.started": "2024-12-15T00:00:00.056144Z",
          "shell.execute_reply": "2024-12-15T00:00:00.108730Z"
        },
        "outputId": "494ff44e-04a8-4b87-bd71-60ece8d77ae9"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec15_00-00-00_38248fae1b86,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T00:00:00.110319Z",
          "iopub.execute_input": "2024-12-15T00:00:00.110627Z",
          "iopub.status.idle": "2024-12-15T00:00:01.983868Z",
          "shell.execute_reply.started": "2024-12-15T00:00:00.110593Z",
          "shell.execute_reply": "2024-12-15T00:00:01.983107Z"
        },
        "outputId": "5e7e51a5-230d-4d0e-c3fc-04f7f1317bad"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x785d7b7cf790>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T00:00:01.984826Z",
          "iopub.execute_input": "2024-12-15T00:00:01.985177Z",
          "iopub.status.idle": "2024-12-15T01:10:03.323221Z",
          "shell.execute_reply.started": "2024-12-15T00:00:01.985138Z",
          "shell.execute_reply": "2024-12-15T01:10:03.322513Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:10:03.324441Z",
          "iopub.execute_input": "2024-12-15T01:10:03.324808Z",
          "iopub.status.idle": "2024-12-15T01:13:24.233678Z",
          "shell.execute_reply.started": "2024-12-15T01:10:03.324750Z",
          "shell.execute_reply": "2024-12-15T01:13:24.232806Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:13:24.234611Z",
          "iopub.execute_input": "2024-12-15T01:13:24.234885Z",
          "iopub.status.idle": "2024-12-15T01:13:26.237645Z",
          "shell.execute_reply.started": "2024-12-15T01:13:24.234859Z",
          "shell.execute_reply": "2024-12-15T01:13:26.236736Z"
        },
        "outputId": "5c7ec600-9e77-43de-f461-39fc8a682c49"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Tulu-3-8B/snapshots/d5a3345981f43f463518004225209ddf3427c43f/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"allenai/Llama-3.1-Tulu-3-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 128264\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.1-Tulu-3-8B/snapshots/d5a3345981f43f463518004225209ddf3427c43f/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"allenai/Llama-3.1-Tulu-3-8B\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128001,\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": false,\n  \"vocab_size\": 128264\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:13:26.238860Z",
          "iopub.execute_input": "2024-12-15T01:13:26.239222Z",
          "iopub.status.idle": "2024-12-15T01:13:26.376538Z",
          "shell.execute_reply.started": "2024-12-15T01:13:26.239185Z",
          "shell.execute_reply": "2024-12-15T01:13:26.375633Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:13:26.377636Z",
          "iopub.execute_input": "2024-12-15T01:13:26.377927Z",
          "iopub.status.idle": "2024-12-15T01:13:26.390368Z",
          "shell.execute_reply.started": "2024-12-15T01:13:26.377901Z",
          "shell.execute_reply": "2024-12-15T01:13:26.389565Z"
        },
        "id": "BFX0AyaOX_Nr",
        "outputId": "61b28052-b879-467b-892c-44cb9c64cbec"
      },
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:13:26.391370Z",
          "iopub.execute_input": "2024-12-15T01:13:26.391917Z",
          "iopub.status.idle": "2024-12-15T01:13:27.830473Z",
          "shell.execute_reply.started": "2024-12-15T01:13:26.391878Z",
          "shell.execute_reply": "2024-12-15T01:13:27.829772Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "eEzCHknlX_Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:13:27.831718Z",
          "iopub.execute_input": "2024-12-15T01:13:27.832081Z",
          "iopub.status.idle": "2024-12-15T01:14:44.772384Z",
          "shell.execute_reply.started": "2024-12-15T01:13:27.832044Z",
          "shell.execute_reply": "2024-12-15T01:14:44.771590Z"
        },
        "id": "Y9TbaK0WX_Ns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.773515Z",
          "iopub.execute_input": "2024-12-15T01:14:44.773851Z",
          "iopub.status.idle": "2024-12-15T01:14:44.783408Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.773820Z",
          "shell.execute_reply": "2024-12-15T01:14:44.782652Z"
        },
        "id": "lcZnYw3vX_Ns",
        "outputId": "6236ae9e-3613-4285-9810-df96c7d2a58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4540665856\nTrainable parameters : 1051004928\nTrainable percentage: 23.15%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.784277Z",
          "iopub.execute_input": "2024-12-15T01:14:44.784523Z",
          "iopub.status.idle": "2024-12-15T01:14:44.815753Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.784489Z",
          "shell.execute_reply": "2024-12-15T01:14:44.815036Z"
        },
        "id": "c7P62zcPX_Ns",
        "outputId": "7e1d688c-f865-4385-93e0-a28f49c1af0c"
      },
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128264, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=1024, bias=False)\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4096, out_features=32, bias=False)\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=14336, bias=False)\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=14336, out_features=32, bias=False)\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=4096, bias=False)\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128264, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.816898Z",
          "iopub.execute_input": "2024-12-15T01:14:44.817161Z",
          "iopub.status.idle": "2024-12-15T01:14:44.841180Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.817138Z",
          "shell.execute_reply": "2024-12-15T01:14:44.840406Z"
        },
        "id": "ZEVudZnsX_Ns",
        "outputId": "76d4f2c4-8b6e-4265-aa8b-60b497088405"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 4708438016\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.842193Z",
          "iopub.execute_input": "2024-12-15T01:14:44.843026Z",
          "iopub.status.idle": "2024-12-15T01:14:44.854683Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.842980Z",
          "shell.execute_reply": "2024-12-15T01:14:44.853982Z"
        },
        "id": "wUTIWQOlX_Ns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.855712Z",
          "iopub.execute_input": "2024-12-15T01:14:44.856541Z",
          "iopub.status.idle": "2024-12-15T01:14:44.866447Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.856501Z",
          "shell.execute_reply": "2024-12-15T01:14:44.865593Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:14:44.867370Z",
          "iopub.execute_input": "2024-12-15T01:14:44.867616Z",
          "iopub.status.idle": "2024-12-15T01:14:44.876150Z",
          "shell.execute_reply.started": "2024-12-15T01:14:44.867593Z",
          "shell.execute_reply": "2024-12-15T01:14:44.875249Z"
        },
        "id": "heJi2GjtX_Ns"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:20:27.350788Z",
          "iopub.execute_input": "2024-12-15T01:20:27.351169Z",
          "iopub.status.idle": "2024-12-15T01:21:20.795312Z",
          "shell.execute_reply.started": "2024-12-15T01:20:27.351132Z",
          "shell.execute_reply": "2024-12-15T01:21:20.794450Z"
        },
        "outputId": "4cf3df7a-ffdd-4cd3-fda5-920b003a93e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\n### Question: A small square is made by dividing a  |  ### Question: A small square is made by dividing a\nsquare with a side of 20 centimeters (cm) into      |  square with a side of 20 centimeters (cm) into    \nthirds. Find the area of the newly created small    |  thirds. Find the area of the newly created small  \nsquare in square centimeters (cm2), rounded to two  |  square in square centimeters (cm2), rounded to two\ndecimal places. ### Answer: To solve this problem,  |  decimal places. ### Answer: To solve this problem,\nwe need to understand how dividing a square into    |  we need to understand how dividing a square into  \nthirds affects its dimensions.  1. **Initial        |  thirds affects its dimensions.  1. **Initial      \nSquare:**    - Side length = 20 cm    - Area =      |  Square:**    - Side length = 20 cm    - Area =    \n\\(20 \\times 20 = 400 \\, \\text{cm}^2\\)  2.           |  \\(20 \\times 20 = 400 \\, \\text{cm}^2\\)  2.         \n**Dividing into Thirds:**    - Dividing a square    |  **Dividing into Thirds:**    - Dividing a square  \ninto thirds horizontally and vertically means each  |  into thirds horizontally and vertically means each\nside is divided into 3 equal parts.    - New side   |  side is divided into 3 equal parts.    - New side \nlength = \\(\\frac{20}{3} \\, \\text{cm}\\)  3.          |  length = \\(\\frac{20}{3} \\, \\text{cm}\\)  3.        \n**Calculating the Area of the New Square:**    -    |  **Calculating the Area of the New Square:**    -  \nThe side length of the new square is                |  New side length = \\(\\frac{20}{3} \\, \\text{cm}\\)   \n\\(\\frac{20}{3} \\, \\text{cm}\\).    - Area of the     |  - Area of the new square =                        \nnew square = \\(\\left(\\frac{20}{3}\\right) \\times     |  \\(\\left(\\frac{20}{3}\\right) \\times                \n\\left(\\frac{20}{3}\\right) = \\frac{400}{9} \\,        |  \\left(\\frac{20}{3}\\right)\\)  Let's compute this   \n\\text{cm}^2\\)  4. **Rounding to Two Decimal         |  step-by-step using Python and sympy.  ```python   \nPlaces:**    - \\(\\frac{400}{9} \\approx 44.44 \\,     |  import sympy as sp  # Define the side length of   \n\\text{cm}^2\\)  Thus, the area of the newly created  |  the original square side_length_original = 20  #  \nsmall square is approximately \\(44.44 \\,            |  Calculate the side length of the new square       \n\\text{cm}^2\\).  #### 44.44                          |  (divided into thirds) side_length_new =           \n                                                    |  side_length_original / 3  # Calculate the area of \n                                                    |  the new square area_new = side_length_new *       \n                                                    |  side_length_new  # Round the area to two decimal  \n                                                    |  places area_new_rounded = round(area_new, 2)      \n                                                    |  print(area_new_rounded) ``` ```output 133.33 ```  \n                                                    |  The area of the newly created small square, when  \n                                                    |  the original square with a side length of 20 cm is\n                                                    |  divided into thirds, is \\(\\boxed{133.33}\\) square \n                                                    |  centimeters (cm²).                                \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T01:25:10.206251Z",
          "iopub.execute_input": "2024-12-15T01:25:10.207057Z",
          "iopub.status.idle": "2024-12-15T01:26:02.971648Z",
          "shell.execute_reply.started": "2024-12-15T01:25:10.207020Z",
          "shell.execute_reply": "2024-12-15T01:26:02.970823Z"
        },
        "outputId": "c5cdecf6-f8a4-40ac-c0aa-4daa4b903c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\n### Question: A cleaning company produces two       |  ### Question: A cleaning company produces two     \nsanitizer sprays. One spray kills 50% of germs,     |  sanitizer sprays. One spray kills 50% of germs,   \nand another spray kills 25% of germs. However, a    |  and another spray kills 25% of germs. However, a  \ncertain percentage of the germs they kill are the   |  certain percentage of the germs they kill are the \nsame ones. After using both sanitizer sprays        |  same ones. After using both sanitizer sprays      \ntogether, 30% of germs would be left. What          |  together, 30% of germs would be left. What        \npercentage of germs do both sprays kill in common?  |  percentage of germs do both sprays kill in common?\n### Answer: Let's denote the percentage of germs    |  ### Answer: Let's denote the percentage of germs  \nkilled by the first spray as \\( x \\) and the        |  killed by the first spray as \\( x \\) and the      \npercentage killed by the second spray as \\( y \\).   |  percentage killed by the second spray as \\( y \\). \nGiven: - The first spray kills 50% of germs, so \\(  |  Given: - The first spray kills 50% of germs, so \\(\nx = 50 \\). - The second spray kills 25% of germs,   |  x = 50 \\). - The second spray kills 25% of germs, \nso \\( y = 25 \\).  Let \\( z \\) be the percentage of  |  so \\( y = 25 \\).  When both sprays are used       \ngerms killed in common by both sprays.  The total   |  together, the total percentage of germs killed is \npercentage of germs killed by both sprays is given  |  given by: \\[ x + y - \\text{common percentage} = 30\nby: \\[ x + y - z \\]  According to the problem,      |  \\]  Substituting the given values: \\[ 50 + 25 -   \nafter using both sprays together, 30% of germs      |  \\text{common percentage} = 30 \\]  Simplifying: \\[ \nwould be left. This means that 70% of germs are     |  75 - \\text{common percentage} = 30 \\]  Solving for\nkilled in total. Therefore, we have: \\[ x + y - z   |  the common percentage: \\[ \\text{common percentage}\n= 70 \\]  Substituting \\( x = 50 \\) and \\( y = 25    |  = 75 - 30 \\] \\[ \\text{common percentage} = 45 \\]  \n\\): \\[ 50 + 25 - z = 70 \\]  Simplifying: \\[ 75 - z  |  Thus, both sprays kill 45% of the germs in common.\n= 70 \\]  Solving for \\( z \\): \\[ z = 75 - 70 \\] \\[  |  The final answer is \\( \\boxed{45} \\).             \nz = 5 \\]  Thus, the percentage of germs killed in   |                                                    \ncommon by both sprays is \\( \\boxed{5} \\).  ###      |                                                    \nVerification: To verify, let's check the            |                                                    \ncalculation step-by-step:  1. **Given:**    -       |                                                    \nFirst spray kills \\( 50\\% \\) of germs (\\( x = 50    |                                                    \n\\)).    - Second spray kills \\( 25\\% \\) of germs    |                                                    \n(\\( y = 25 \\)).    - Combined, they leave \\( 30\\%   |                                                    \n\\) of germs, implying \\( 70\\% \\) are killed.  2.    |                                                    \n**Equation:**    \\[ x + y - z = 70 \\]               |                                                    \nSubstituting \\( x = 50 \\) and \\( y = 25 \\):    \\[   |                                                    \n50 + 25 - z = 70 \\]    Simplifying:    \\[ 75 - z =  |                                                    \n70 \\]    Solving for \\( z \\):    \\[ z = 75 - 70 \\]  |                                                    \n\\[ z = 5 \\]  Thus, the percentage of germs killed   |                                                    \nin common by both sprays is indeed \\( \\boxed{5}     |                                                    \n\\).  ### Final Answer: The final answer is \\(       |                                                    \n\\boxed{5} \\). I hope it is correct.                 |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T02:11:32.892415Z",
          "iopub.execute_input": "2024-12-15T02:11:32.893227Z",
          "iopub.status.idle": "2024-12-15T02:12:10.876741Z",
          "shell.execute_reply.started": "2024-12-15T02:11:32.893192Z",
          "shell.execute_reply": "2024-12-15T02:12:10.875876Z"
        },
        "outputId": "a50916c6-6969-4fdd-9c7a-28bb3108700c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\n### Question: Two fruits were taken out from a      |  ### Question: Two fruits were taken out from a    \nbasket containing one apple, one peach, one pear,   |  basket containing one apple, one peach, one pear, \none melon, and a strawberry. How many ways are      |  one melon, and a strawberry. How many ways are    \nthere for the selected fruit? ### Answer: The       |  there for the selected fruit? ### Answer: The     \nnumber of ways to select 2 fruits from a basket     |  problem is asking for the number of ways to select\ncontaining 5 fruits is given by the combination     |  2 fruits from a basket containing 5 fruits. This  \nformula \\( C(n, k) \\), where \\( n \\) is the total   |  is a combination problem, where order does not    \nnumber of items, and \\( k \\) is the number of       |  matter.  The formula for combinations is given by:\nitems to choose.  Here, \\( n = 5 \\) (one apple,     |  \\[ \\binom{n}{r} = \\frac{n!}{r!(n-r)!} \\]  Where: -\none peach, one pear, one melon, and one             |  \\( n \\) is the total number of items (5 fruits), -\nstrawberry) and \\( k = 2 \\).  The combination       |  \\( r \\) is the number of items to choose (2       \nformula is: \\[ C(n, k) = \\frac{n!}{k!(n-k)!} \\]     |  fruits).  Plugging in the values: \\[ \\binom{5}{2} \nSubstituting the given values: \\[ C(5, 2) =         |  = \\frac{5!}{2!(5-2)!} = \\frac{5 \\times 4}{2 \\times\n\\frac{5!}{2!(5-2)!} = \\frac{5!}{2! \\cdot 3!} \\]     |  1} = 10 \\]  So, the number of ways to select 2    \nCalculating the factorials: \\[ 5! = 5 \\times 4      |  fruits from the basket is 10.  ### Final Answer:  \n\\times 3 \\times 2 \\times 1 = 120 \\] \\[ 2! = 2       |  The final answer is \\(10\\). I hope it is correct. \n\\times 1 = 2 \\] \\[ 3! = 3 \\times 2 \\times 1 = 6 \\]  |                                                    \nNow substitute these into the combination formula:  |                                                    \n\\[ C(5, 2) = \\frac{120}{2 \\times 6} =               |                                                    \n\\frac{120}{12} = 10 \\]  Thus, there are 10 ways to  |                                                    \nselect 2 fruits from the basket.  The final answer  |                                                    \nis \\( \\boxed{10} \\).                                |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T02:34:33.350184Z",
          "iopub.execute_input": "2024-12-15T02:34:33.350931Z",
          "iopub.status.idle": "2024-12-15T02:35:11.379419Z",
          "shell.execute_reply.started": "2024-12-15T02:34:33.350895Z",
          "shell.execute_reply": "2024-12-15T02:35:11.378558Z"
        },
        "outputId": "8f29148b-7091-43d3-dbb8-3093933b7a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\n### Question: When three points are not on a        |  ### Question: When three points are not on a      \nstraight line, find the number of line segments     |  straight line, find the number of line segments   \nthat can be formed from these three points. ###     |  that can be formed from these three points. ###   \nAnswer: The number of line segments that can be     |  Answer: The number of line segments that can be   \nformed from three points is 3.   Here's why:  When  |  formed from three points is 3.   Here's why:  When\nyou have three points, you can connect any two      |  you have three points, you can connect any two    \npoints to form a line segment.   Let's denote the   |  points to form a line segment.   Let's denote the \nthree points as A, B, and C.  The possible line     |  three points as A, B, and C.  The possible line   \nsegments are: - AB (connecting point A and point    |  segments are: 1. A to B 2. A to C 3. B to C  So,  \nB) - BC (connecting point B and point C) - AC       |  there are exactly 3 line segments that can be     \n(connecting point A and point C)  Thus, there are   |  formed from these three points.   This is because \nexactly 3 line segments that can be formed from     |  for any selection of two points out of the three, \nthese three points.  ### Explanation:  To           |  you can draw a line segment. The number of ways to\ndetermine the number of line segments that can be   |  choose 2 points out of 3 is given by the          \nformed from three points, consider the following:   |  combination formula \\( \\binom{3}{2} \\), which     \n1. **Identify the Points**: Let's call the three    |  equals 3.  Thus, the number of line segments is 3.\npoints \\(A\\), \\(B\\), and \\(C\\).  2. **Form Line     |                                                    \nSegments**: Each pair of points can be connected    |                                                    \nto form a line segment. The pairs are:    - \\(AB\\)  |                                                    \n(connecting point \\(A\\) and point \\(B\\))    -       |                                                    \n\\(BC\\) (connecting point \\(B\\) and point \\(C\\))     |                                                    \n- \\(AC\\) (connecting point \\(A\\) and point \\(C\\))   |                                                    \n3. **Count the Segments**: There are exactly three  |                                                    \npairs (or line segments) that can be formed from    |                                                    \nthree points.  ### Verification:  - **Pair 1**:     |                                                    \n\\(AB\\) (1 segment) - **Pair 2**: \\(BC\\) (1          |                                                    \nsegment) - **Pair 3**: \\(AC\\) (1 segment)  Adding   |                                                    \nthese together gives us \\(1 + 1 + 1 = 3\\).  Thus,   |                                                    \nthe number of line segments that can be formed      |                                                    \nfrom three points is indeed **3**.                  |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['question']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-15T02:39:16.052222Z",
          "iopub.execute_input": "2024-12-15T02:39:16.052667Z",
          "iopub.status.idle": "2024-12-15T02:39:47.127396Z",
          "shell.execute_reply.started": "2024-12-15T02:39:16.052627Z",
          "shell.execute_reply": "2024-12-15T02:39:47.126581Z"
        },
        "outputId": "7a6184b9-ae52-4ac3-fcb5-7f4c709100ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    4540665856                     |                     4708438016                    \n================================================== | ==================================================\n### Question: Ayla has a customer care job whose    |  ### Question: Ayla has a customer care job whose  \nprimary role is to hear complaints from customers   |  primary role is to hear complaints from customers \nand advise them on the best way to solve their      |  and advise them on the best way to solve their    \nproblems. She talks with each customer for a        |  problems. She talks with each customer for a      \ncertain amount of time, and each phone call is      |  certain amount of time, and each phone call is    \ncharged five cents per minute. The phone bill at    |  charged five cents per minute. The phone bill at  \nthe end of the month is $600 when she manages to    |  the end of the month is $600 when she manages to  \ntalk to 50 customers a week. How long does each     |  talk to 50 customers a week. How long does each   \ncall last? ### Answer: Let's denote the duration    |  call last? ### Answer: Let's denote the duration  \nof each call in minutes as \\( x \\).  The total      |  of each call in minutes as \\( x \\).  The total    \nnumber of customers Ayla talks to in a month is \\(  |  number of customers Ayla talks to in a month is \\(\n50 \\times 4 = 200 \\) (since there are 4 weeks in a  |  50 \\times 4 = 200 \\) (since there are 4 weeks in a\nmonth).  The total cost of all calls is $600.       |  month).  The total cost for all the calls is $600.\nSince each call costs 5 cents (or $0.05), the       |  Since each call costs 5 cents (or $0.05) per      \ntotal cost in dollars is given by:  \\[ 200 \\times   |  minute, the total cost in dollars can be expressed\n0.05 \\times x = 600 \\]  Simplifying the equation:   |  as: \\[ 200 \\times x \\times 0.05 = 600 \\]  To solve\n\\[ 10x = 600 \\]  Dividing both sides by 10:  \\[ x   |  for \\( x \\), we first simplify the equation: \\[   \n= 60 \\]  So, each call lasts 60 minutes.  The       |  200 \\times x \\times 0.05 = 600 \\]  Divide both    \nfinal answer is \\( \\boxed{60} \\).                   |  sides by 10: \\[ 20 \\times x = 600 \\]  Divide both \n                                                    |  sides by 20: \\[ x = \\frac{600}{20} \\]  \\[ x = 30  \n                                                    |  \\]  Thus, each call lasts 30 minutes.  The final  \n                                                    |  answer is \\( \\boxed{30} \\).                       \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}