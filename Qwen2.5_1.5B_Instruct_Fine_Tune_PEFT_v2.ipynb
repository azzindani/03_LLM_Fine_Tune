{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Qwen2.5_1.5B_Instruct_Fine_Tune_PEFT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T01:55:38.827286Z",
          "iopub.execute_input": "2024-11-23T01:55:38.827971Z",
          "iopub.status.idle": "2024-11-23T01:56:15.130193Z",
          "shell.execute_reply.started": "2024-11-23T01:55:38.827905Z",
          "shell.execute_reply": "2024-11-23T01:56:15.129048Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-23T01:56:15.132703Z",
          "iopub.execute_input": "2024-11-23T01:56:15.133494Z",
          "iopub.status.idle": "2024-11-23T01:56:23.104886Z",
          "shell.execute_reply.started": "2024-11-23T01:56:15.133440Z",
          "shell.execute_reply": "2024-11-23T01:56:23.103715Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-23T01:56:23.106145Z",
          "iopub.execute_input": "2024-11-23T01:56:23.106438Z",
          "iopub.status.idle": "2024-11-23T01:56:23.114169Z",
          "shell.execute_reply.started": "2024-11-23T01:56:23.106407Z",
          "shell.execute_reply": "2024-11-23T01:56:23.113081Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'Qwen/Qwen2.5-1.5B-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T01:56:23.115574Z",
          "iopub.execute_input": "2024-11-23T01:56:23.115998Z",
          "iopub.status.idle": "2024-11-23T01:56:23.123642Z",
          "shell.execute_reply.started": "2024-11-23T01:56:23.115955Z",
          "shell.execute_reply": "2024-11-23T01:56:23.122800Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "  if base == True:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      torch_dtype = torch.float16,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "  else:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "      load_in_4bit = True,\n",
        "      bnb_4bit_quant_type = 'nf4',\n",
        "      bnb_4bit_compute_dtype = torch.float16,\n",
        "      bnb_4bit_use_double_quant = True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      quantization_config = bnb_config,\n",
        "      trust_remote_code = True\n",
        "    ).to(device)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T01:56:23.125757Z",
          "iopub.execute_input": "2024-11-23T01:56:23.126059Z",
          "iopub.status.idle": "2024-11-23T01:56:23.137554Z",
          "shell.execute_reply.started": "2024-11-23T01:56:23.126030Z",
          "shell.execute_reply": "2024-11-23T01:56:23.136566Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T01:56:23.138725Z",
          "iopub.execute_input": "2024-11-23T01:56:23.139098Z",
          "iopub.status.idle": "2024-11-23T02:01:25.759569Z",
          "shell.execute_reply.started": "2024-11-23T01:56:23.139056Z",
          "shell.execute_reply": "2024-11-23T02:01:25.758723Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:25.760533Z",
          "iopub.execute_input": "2024-11-23T02:01:25.760811Z",
          "iopub.status.idle": "2024-11-23T02:01:25.768570Z",
          "shell.execute_reply.started": "2024-11-23T02:01:25.760784Z",
          "shell.execute_reply": "2024-11-23T02:01:25.767720Z"
        },
        "outputId": "e3fc333f-db5a-4bf2-97ca-a2a6e5aaa9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 888616448\nTrainable parameters : 233461248\nTrainable percentage: 26.27%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:25.769764Z",
          "iopub.execute_input": "2024-11-23T02:01:25.770022Z",
          "iopub.status.idle": "2024-11-23T02:01:27.920495Z",
          "shell.execute_reply.started": "2024-11-23T02:01:25.769997Z",
          "shell.execute_reply": "2024-11-23T02:01:27.919739Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'yahma/alpaca-cleaned'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:27.921619Z",
          "iopub.execute_input": "2024-11-23T02:01:27.921954Z",
          "iopub.status.idle": "2024-11-23T02:01:27.926316Z",
          "shell.execute_reply.started": "2024-11-23T02:01:27.921926Z",
          "shell.execute_reply": "2024-11-23T02:01:27.925395Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 512"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:27.927418Z",
          "iopub.execute_input": "2024-11-23T02:01:27.927717Z",
          "iopub.status.idle": "2024-11-23T02:01:27.938895Z",
          "shell.execute_reply.started": "2024-11-23T02:01:27.927674Z",
          "shell.execute_reply": "2024-11-23T02:01:27.938009Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:27.939756Z",
          "iopub.execute_input": "2024-11-23T02:01:27.940015Z",
          "iopub.status.idle": "2024-11-23T02:01:29.211551Z",
          "shell.execute_reply.started": "2024-11-23T02:01:27.939975Z",
          "shell.execute_reply": "2024-11-23T02:01:29.210502Z"
        },
        "outputId": "bd8a8b8d-2b36-48ce-b79b-55946530b0a4"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.212754Z",
          "iopub.execute_input": "2024-11-23T02:01:29.213096Z",
          "iopub.status.idle": "2024-11-23T02:01:29.220738Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.213065Z",
          "shell.execute_reply": "2024-11-23T02:01:29.219734Z"
        },
        "id": "3liMdl69tLnY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.221759Z",
          "iopub.execute_input": "2024-11-23T02:01:29.222045Z",
          "iopub.status.idle": "2024-11-23T02:01:29.248296Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.222017Z",
          "shell.execute_reply": "2024-11-23T02:01:29.247401Z"
        },
        "outputId": "3f823dab-d853-49ee-b6c7-d591bfd8a40f"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.251764Z",
          "iopub.execute_input": "2024-11-23T02:01:29.252027Z",
          "iopub.status.idle": "2024-11-23T02:01:29.258133Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.252002Z",
          "shell.execute_reply": "2024-11-23T02:01:29.257313Z"
        },
        "outputId": "17b9e4f4-5b11-418a-c096-5f9f92d15abe"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.259293Z",
          "iopub.execute_input": "2024-11-23T02:01:29.259591Z",
          "iopub.status.idle": "2024-11-23T02:01:29.268252Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.259566Z",
          "shell.execute_reply": "2024-11-23T02:01:29.267459Z"
        },
        "outputId": "df1568ad-4f57-4a27-faa0-4cb110cc1a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['output', 'input', 'instruction']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.269238Z",
          "iopub.execute_input": "2024-11-23T02:01:29.269558Z",
          "iopub.status.idle": "2024-11-23T02:01:29.279177Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.269531Z",
          "shell.execute_reply": "2024-11-23T02:01:29.278316Z"
        },
        "id": "pITc3WUYtLnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "def preprocess(examples):\n",
        "  instruction = examples['instruction']\n",
        "  input = examples['input']\n",
        "  output = examples['output']\n",
        "\n",
        "  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n",
        "  return {'prompt' : text}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.280256Z",
          "iopub.execute_input": "2024-11-23T02:01:29.280604Z",
          "iopub.status.idle": "2024-11-23T02:01:29.293371Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.280574Z",
          "shell.execute_reply": "2024-11-23T02:01:29.292632Z"
        },
        "id": "f0-NncFctLnZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(preprocess, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.294460Z",
          "iopub.execute_input": "2024-11-23T02:01:29.294797Z",
          "iopub.status.idle": "2024-11-23T02:01:29.312597Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.294768Z",
          "shell.execute_reply": "2024-11-23T02:01:29.311650Z"
        },
        "outputId": "fe15356f-b8b8-4d5b-83ce-9474474edbe0"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "cZya4tPEWUc9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.313985Z",
          "iopub.execute_input": "2024-11-23T02:01:29.314973Z",
          "iopub.status.idle": "2024-11-23T02:01:29.321430Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.314921Z",
          "shell.execute_reply": "2024-11-23T02:01:29.320629Z"
        },
        "outputId": "9bb30576-7372-4c33-8c1a-799ec68e4d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.322483Z",
          "iopub.execute_input": "2024-11-23T02:01:29.322805Z",
          "iopub.status.idle": "2024-11-23T02:01:29.335335Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.322776Z",
          "shell.execute_reply": "2024-11-23T02:01:29.334552Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:29.336426Z",
          "iopub.execute_input": "2024-11-23T02:01:29.336828Z",
          "iopub.status.idle": "2024-11-23T02:01:39.434083Z",
          "shell.execute_reply.started": "2024-11-23T02:01:29.336784Z",
          "shell.execute_reply": "2024-11-23T02:01:39.433003Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.435319Z",
          "iopub.execute_input": "2024-11-23T02:01:39.435717Z",
          "iopub.status.idle": "2024-11-23T02:01:39.442899Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.435648Z",
          "shell.execute_reply": "2024-11-23T02:01:39.440444Z"
        },
        "outputId": "89cd0e83-3942-4d7d-c3bb-128e7749c68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.444244Z",
          "iopub.execute_input": "2024-11-23T02:01:39.444614Z",
          "iopub.status.idle": "2024-11-23T02:01:39.481519Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.444571Z",
          "shell.execute_reply": "2024-11-23T02:01:39.480469Z"
        },
        "outputId": "72a2efa0-e3ad-48a5-d63b-acfde4203835"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.483088Z",
          "iopub.execute_input": "2024-11-23T02:01:39.483552Z",
          "iopub.status.idle": "2024-11-23T02:01:39.489503Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.483509Z",
          "shell.execute_reply": "2024-11-23T02:01:39.488424Z"
        },
        "outputId": "3fd6b37f-d36f-4263-e136-9706c4bee3c3"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.490870Z",
          "iopub.execute_input": "2024-11-23T02:01:39.491226Z",
          "iopub.status.idle": "2024-11-23T02:01:39.521682Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.491187Z",
          "shell.execute_reply": "2024-11-23T02:01:39.520749Z"
        },
        "outputId": "f30d5cb0-54b0-4a66-9467-ba658ff3bac7"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n1  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n2  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n3  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n4  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.523068Z",
          "iopub.execute_input": "2024-11-23T02:01:39.523811Z",
          "iopub.status.idle": "2024-11-23T02:01:39.529130Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.523760Z",
          "shell.execute_reply": "2024-11-23T02:01:39.528184Z"
        },
        "outputId": "f1ca3535-ba76-4b0b-e448-e5269d152a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.530589Z",
          "iopub.execute_input": "2024-11-23T02:01:39.530999Z",
          "iopub.status.idle": "2024-11-23T02:01:39.540987Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.530956Z",
          "shell.execute_reply": "2024-11-23T02:01:39.540071Z"
        },
        "outputId": "b3b04f26-2997-4bff-f93f-98a686fd8c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[38214, 374, 458, 7600, 429, 16555, 264, 3383, 11, 34426, 448, 458, 1946, 429, 5707, 4623, 2266, 13, 9645, 264, 2033, 429, 34901, 44595, 279, 1681, 382, 14374, 29051, 510, 2082, 55856, 279, 2661, 32794, 323, 10542, 1181, 1887, 6912, 382, 14374, 5571, 510, 11613, 19241, 36341, 3556, 304, 264, 13753, 7579, 26266, 77, 3036, 14589, 358, 1410, 537, 5821, 2176, 1699, 3036, 387, 825, 62765, 11, 1293, 358, 14638, 1699, 3036, 6966, 1495, 825, 438, 3041, 438, 358, 1410, 1699, 1249, 1380, 432, 29180, 304, 279, 1212, 73089, 17882, 77, 1699, 12209, 3867, 279, 1008, 11, 438, 1101, 438, 6624, 26266, 77, 3036, 3432, 8365, 279, 2664, 3717, 26266, 77, 17949, 432, 572, 16359, 88, 323, 4829, 9850, 17882, 77, 26733, 438, 369, 429, 279, 12299, 1052, 1699, 55468, 23704, 1105, 2167, 911, 279, 1852, 26266, 88230, 19241, 429, 6556, 18308, 10962, 1699, 641, 10901, 902, 3019, 1030, 8185, 10792, 3691, 7110, 77, 11908, 11, 358, 2115, 279, 1156, 369, 2441, 1899, 14771, 77, 28074, 14063, 1246, 1616, 11508, 389, 311, 1616, 26266, 77, 40, 92662, 421, 358, 1265, 3512, 2525, 1182, 7110, 77, 1699, 40, 4880, 387, 11629, 419, 448, 264, 30138, 1699, 49882, 60652, 16639, 323, 16639, 16085, 7190, 77, 11613, 19241, 36341, 3556, 304, 264, 7579, 11, 323, 358, 2293, 59, 77, 40, 3867, 279, 825, 2686, 30696, 553, 26266, 77, 3036, 429, 702, 1865, 678, 279, 6672, 382, 14374, 5949, 510, 785, 1887, 6912, 315, 279, 32794, 374, 279, 12650, 315, 3259, 11454, 323, 279, 5421, 315, 1846, 11454, 389, 825, 594, 2272, 13, 576, 18601, 374, 16601, 448, 264, 5480, 1948, 1378, 12716, 323, 13653, 39911, 279, 825, 2686, 30696, 11, 892, 13653, 20816, 862, 2272, 3139, 13, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.542223Z",
          "iopub.execute_input": "2024-11-23T02:01:39.542589Z",
          "iopub.status.idle": "2024-11-23T02:01:39.555349Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.542550Z",
          "shell.execute_reply": "2024-11-23T02:01:39.554346Z"
        },
        "outputId": "749ec521-f180-4050-ad19-a0aab731155d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.556609Z",
          "iopub.execute_input": "2024-11-23T02:01:39.557049Z",
          "iopub.status.idle": "2024-11-23T02:01:39.567034Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.557000Z",
          "shell.execute_reply": "2024-11-23T02:01:39.566172Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.568078Z",
          "iopub.execute_input": "2024-11-23T02:01:39.568374Z",
          "iopub.status.idle": "2024-11-23T02:01:39.579627Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.568341Z",
          "shell.execute_reply": "2024-11-23T02:01:39.578814Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.580865Z",
          "iopub.execute_input": "2024-11-23T02:01:39.581169Z",
          "iopub.status.idle": "2024-11-23T02:01:39.590306Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.581141Z",
          "shell.execute_reply": "2024-11-23T02:01:39.589510Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.591338Z",
          "iopub.execute_input": "2024-11-23T02:01:39.591628Z",
          "iopub.status.idle": "2024-11-23T02:01:39.602311Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.591585Z",
          "shell.execute_reply": "2024-11-23T02:01:39.601470Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:39.603339Z",
          "iopub.execute_input": "2024-11-23T02:01:39.603634Z",
          "iopub.status.idle": "2024-11-23T02:01:40.637573Z",
          "shell.execute_reply.started": "2024-11-23T02:01:39.603604Z",
          "shell.execute_reply": "2024-11-23T02:01:40.636573Z"
        },
        "outputId": "4a84a876-64b8-4894-d15e-37b415d042c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 73,859,072 || all params: 1,617,573,376 || trainable%: 4.5660\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:40.638826Z",
          "iopub.execute_input": "2024-11-23T02:01:40.639142Z",
          "iopub.status.idle": "2024-11-23T02:01:40.662626Z",
          "shell.execute_reply.started": "2024-11-23T02:01:40.639109Z",
          "shell.execute_reply": "2024-11-23T02:01:40.661589Z"
        },
        "outputId": "186dba40-16de-4542-866f-96535ddfaf78"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8960, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:40.664009Z",
          "iopub.execute_input": "2024-11-23T02:01:40.664420Z",
          "iopub.status.idle": "2024-11-23T02:01:40.691716Z",
          "shell.execute_reply.started": "2024-11-23T02:01:40.664377Z",
          "shell.execute_reply": "2024-11-23T02:01:40.690739Z"
        },
        "outputId": "09e0d862-93de-4e7a-9d50-7f4eb79be34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 962475520\nTrainable parameters : 73859072\nTrainable percentage: 7.67%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:40.692912Z",
          "iopub.execute_input": "2024-11-23T02:01:40.694077Z",
          "iopub.status.idle": "2024-11-23T02:01:40.698095Z",
          "shell.execute_reply.started": "2024-11-23T02:01:40.694040Z",
          "shell.execute_reply": "2024-11-23T02:01:40.697135Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:40.699329Z",
          "iopub.execute_input": "2024-11-23T02:01:40.699808Z",
          "iopub.status.idle": "2024-11-23T02:01:40.755981Z",
          "shell.execute_reply.started": "2024-11-23T02:01:40.699775Z",
          "shell.execute_reply": "2024-11-23T02:01:40.755034Z"
        },
        "outputId": "263c1ba7-c199-42d2-f630-b8877e8ea712"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov23_02-01-40_41736bf96ed5,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:40.756931Z",
          "iopub.execute_input": "2024-11-23T02:01:40.757276Z",
          "iopub.status.idle": "2024-11-23T02:01:42.530371Z",
          "shell.execute_reply.started": "2024-11-23T02:01:40.757238Z",
          "shell.execute_reply": "2024-11-23T02:01:42.529498Z"
        },
        "outputId": "19baf2c8-b672-42f0-93f1-3601c992c0e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7e3cb4543f10>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:01:42.531386Z",
          "iopub.execute_input": "2024-11-23T02:01:42.531646Z",
          "iopub.status.idle": "2024-11-23T02:32:52.250065Z",
          "shell.execute_reply.started": "2024-11-23T02:01:42.531619Z",
          "shell.execute_reply": "2024-11-23T02:32:52.248936Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:32:52.251831Z",
          "iopub.execute_input": "2024-11-23T02:32:52.252264Z",
          "iopub.status.idle": "2024-11-23T02:33:59.206745Z",
          "shell.execute_reply.started": "2024-11-23T02:32:52.252215Z",
          "shell.execute_reply": "2024-11-23T02:33:59.205606Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:33:59.214953Z",
          "iopub.execute_input": "2024-11-23T02:33:59.215278Z",
          "iopub.status.idle": "2024-11-23T02:34:01.161479Z",
          "shell.execute_reply.started": "2024-11-23T02:33:59.215249Z",
          "shell.execute_reply": "2024-11-23T02:34:01.160389Z"
        },
        "outputId": "7d03bc68-9812-4d85-bad0-d2b0b10fe3fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:01.162955Z",
          "iopub.execute_input": "2024-11-23T02:34:01.163364Z",
          "iopub.status.idle": "2024-11-23T02:34:01.602974Z",
          "shell.execute_reply.started": "2024-11-23T02:34:01.163320Z",
          "shell.execute_reply": "2024-11-23T02:34:01.601820Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:01.604365Z",
          "iopub.execute_input": "2024-11-23T02:34:01.604763Z",
          "iopub.status.idle": "2024-11-23T02:34:01.622245Z",
          "shell.execute_reply.started": "2024-11-23T02:34:01.604731Z",
          "shell.execute_reply": "2024-11-23T02:34:01.621195Z"
        },
        "id": "FYy_AVIFtLnd",
        "outputId": "b4ed6bc0-505a-43fe-f05b-5084513165e2"
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:01.623547Z",
          "iopub.execute_input": "2024-11-23T02:34:01.623892Z",
          "iopub.status.idle": "2024-11-23T02:34:02.900414Z",
          "shell.execute_reply.started": "2024-11-23T02:34:01.623837Z",
          "shell.execute_reply": "2024-11-23T02:34:02.899640Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "Sjv1OoBatLnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:02.901795Z",
          "iopub.execute_input": "2024-11-23T02:34:02.902515Z",
          "iopub.status.idle": "2024-11-23T02:34:08.240327Z",
          "shell.execute_reply.started": "2024-11-23T02:34:02.902464Z",
          "shell.execute_reply": "2024-11-23T02:34:08.239354Z"
        },
        "id": "zJqI4Ku0tLnd",
        "outputId": "a66b5585-3e59-4d87-98ee-494fcd697544"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=1536, out_features=1536, bias=True)\n          (k_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=1536, out_features=1536, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (up_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (down_proj): Linear4bit(in_features=8960, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.241513Z",
          "iopub.execute_input": "2024-11-23T02:34:08.241833Z",
          "iopub.status.idle": "2024-11-23T02:34:08.253037Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.241803Z",
          "shell.execute_reply": "2024-11-23T02:34:08.252072Z"
        },
        "id": "qMN5gOP5tLnd",
        "outputId": "41c256ff-b5d8-46de-df02-183dd0e6a519"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 888616448\nTrainable parameters : 233461248\nTrainable percentage: 26.27%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.254427Z",
          "iopub.execute_input": "2024-11-23T02:34:08.255307Z",
          "iopub.status.idle": "2024-11-23T02:34:08.277787Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.255275Z",
          "shell.execute_reply": "2024-11-23T02:34:08.276557Z"
        },
        "id": "nUfFURpBtLnd",
        "outputId": "07589b3d-d8e5-48ac-c285-8b4d22cccc4a"
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 1536)\n        (layers): ModuleList(\n          (0-27): 28 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n                  (default): Linear(in_features=64, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n                  (default): Linear(in_features=64, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8960, out_features=64, bias=False)\n                  (default): Linear(in_features=8960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.279090Z",
          "iopub.execute_input": "2024-11-23T02:34:08.279393Z",
          "iopub.status.idle": "2024-11-23T02:34:08.308479Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.279367Z",
          "shell.execute_reply": "2024-11-23T02:34:08.307562Z"
        },
        "id": "2Lc_H_4jtLnd",
        "outputId": "e907b48c-0819-4938-e823-56999b75facb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1036334592\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.309631Z",
          "iopub.execute_input": "2024-11-23T02:34:08.309953Z",
          "iopub.status.idle": "2024-11-23T02:34:08.316546Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.309924Z",
          "shell.execute_reply": "2024-11-23T02:34:08.315629Z"
        },
        "id": "MsHazcIntLne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt, inputs):\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "    prompt_format.format(\n",
        "      prompt,\n",
        "      inputs,\n",
        "      ''\n",
        "    )\n",
        "  ], return_tensors = 'pt').to(device)\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    **inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.317607Z",
          "iopub.execute_input": "2024-11-23T02:34:08.317919Z",
          "iopub.status.idle": "2024-11-23T02:34:08.333005Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.317894Z",
          "shell.execute_reply": "2024-11-23T02:34:08.332048Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:34:08.334095Z",
          "iopub.execute_input": "2024-11-23T02:34:08.334348Z",
          "iopub.status.idle": "2024-11-23T02:34:08.346802Z",
          "shell.execute_reply.started": "2024-11-23T02:34:08.334323Z",
          "shell.execute_reply": "2024-11-23T02:34:08.345748Z"
        },
        "id": "9UcV9vqftLne"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T02:44:32.218268Z",
          "iopub.execute_input": "2024-11-23T02:44:32.218698Z",
          "iopub.status.idle": "2024-11-23T02:46:06.442391Z",
          "shell.execute_reply.started": "2024-11-23T02:44:32.218641Z",
          "shell.execute_reply": "2024-11-23T02:46:06.441292Z"
        },
        "outputId": "bf2e3046-5d38-4ca6-e5ac-c2aba4e983fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe implications of Artificial Intelligence  ###    |  the implications of Artificial Intelligence  ###  \nInput:   ### Response: Artificial Intelligence      |  Input:   ### Response: Artificial Intelligence    \n(AI) has profound implications across various       |  (AI) has profound implications across various     \ndomains, including but not limited to:  1.          |  domains, including but not limited to:  1.        \n**Economic Impact**: The rise of AI is expected to  |  **Economic Impact**: The rise of AI is expected to\nsignificantly alter the global economy. Automation  |  significantly alter the global economy. Automation\nand AI-driven technologies are projected to         |  and AI-driven technologies are projected to       \ndisplace many jobs, particularly in industries      |  displace many jobs, particularly in industries    \nsuch as manufacturing, transportation, and          |  such as manufacturing, transportation, and        \ncustomer service. This could lead to significant    |  customer service. This could lead to significant  \njob losses and economic shifts, necessitating       |  job losses and economic shifts, necessitating     \nretraining programs and social safety nets to       |  retraining programs and social safety nets to     \nsupport affected workers.  2. **Ethical             |  support affected workers.  2. **Ethical           \nConsiderations**: The use of AI raises ethical      |  Considerations**: The use of AI raises ethical    \nconcerns, particularly in areas such as privacy,    |  concerns, particularly in areas such as privacy,  \nsurveillance, and decision-making. AI systems can   |  surveillance, and decision-making. AI systems can \nbe biased if not designed and trained with diverse  |  be biased if not designed and trained with diverse\ndata, leading to unfair outcomes. Additionally,     |  data, leading to unfair outcomes. Additionally,   \nthe use of AI in decision-making processes can      |  the use of AI in decision-making processes can    \nlead to ethical dilemmas, such as the use of AI in  |  lead to ethical dilemmas, such as the use of AI in\nmilitary or law enforcement contexts.  3. **Social  |  military or law enforcement contexts.  3. **Social\nImplications**: AI has the potential to enhance     |  Implications**: AI has the potential to enhance   \nsocial interactions and improve efficiency in       |  social interactions and improve efficiency in     \nvarious aspects of life. However, it also poses     |  various aspects of life. However, it also poses   \nchallenges, such as the potential for AI to         |  challenges, such as the potential for AI to       \nexacerbate social inequalities if not properly      |  exacerbate social inequalities if not properly    \nregulated. For example, AI-driven services could    |  regulated. For example, AI-driven services could  \nbe more accessible to those with higher incomes,    |  be more accessible to those with higher incomes,  \npotentially widening the digital divide.  4.        |  potentially widening the digital divide.  4.      \n**Environmental Impact**: AI can be used to         |  **Environmental Impact**: AI can be used to       \noptimize resource usage and reduce waste, but it    |  optimize resource usage and reduce waste, but it  \nalso has the potential to increase energy           |  also has the potential to increase energy         \nconsumption and carbon emissions if not designed    |  consumption and carbon emissions if not designed  \nwith sustainability in mind. The development of AI  |  with sustainability in mind. The development of AI\nsystems that are energy-efficient and               |  systems that are energy-efficient and             \nenvironmentally friendly will be crucial in         |  environmentally friendly will be crucial in       \naddressing these issues.  5. **Technological        |  addressing these issues.  5. **Technological      \nAdvancements**: AI is driving technological         |  Advancements**: AI is driving technological       \nadvancements in fields such as robotics, machine    |  advancements in fields such as robotics, machine  \nlearning, and data analytics. These advancements    |  learning, and data analytics. These advancements  \nare transforming industries and creating new        |  are transforming industries and creating new      \nopportunities for innovation and economic growth.   |  opportunities for innovation and economic growth. \nHowever, the rapid pace of AI development also      |  However, the rapid pace of AI development also    \npresents challenges, such as the need for           |  presents challenges, such as the need for         \ncontinuous innovation and the potential for AI to   |  continuous innovation and the potential for AI to \noutpace human understanding and control.  6.        |  outpace human understanding and control.  6.      \n**Global Governance**: As AI becomes more           |  **Cultural and Psychological Implications**: AI is\nintegrated into global systems, there is a need     |  increasingly integrated into our daily lives, from\nfor global governance frameworks to address issues  |  personal assistants to virtual reality            \nsuch as AI ethics, international law, and the       |  experiences. This integration raises questions    \nregulation of AI technologies. This will require    |  about the nature of human identity and the role of\ncollaboration between governments, international    |  AI in shaping our perceptions of reality. The     \norganizations, and private sector entities to       |  psychological impact of AI on individuals,        \nensure that AI is developed and used in a           |  particularly in terms of privacy and autonomy, is \nresponsible and ethical manner.  In conclusion,     |  also a significant concern.  7. **Global          \nthe implications of AI are multifaceted and far-    |  Governance**: As AI becomes more integrated into  \nreaching, affecting economic, ethical, social,      |  global systems, there is a need for global        \nenvironmental, technological, and global            |  governance frameworks to address issues such as AI\ngovernance aspects. Addressing these implications   |  ethics, data security, and international          \nwill be crucial for ensuring that the benefits of   |  cooperation. The global community must work       \nAI are realized while minimizing its potential      |  together to ensure that AI is developed and used  \ndrawbacks.                                          |  in a responsible and ethical manner.  In          \n                                                    |  conclusion, the implications of AI are vast and   \n                                                    |  multifaceted, encompassing economic, ethical,     \n                                                    |  social, environmental, technological, cultural,   \n                                                    |  and governance dimensions. Addressing these       \n                                                    |  implications will be crucial for the responsible  \n                                                    |  and beneficial development of AI in the           \n                                                    |  future.<|endoftext|>                              \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T03:13:48.138761Z",
          "iopub.execute_input": "2024-11-23T03:13:48.139476Z",
          "iopub.status.idle": "2024-11-23T03:15:24.601750Z",
          "shell.execute_reply.started": "2024-11-23T03:13:48.139442Z",
          "shell.execute_reply": "2024-11-23T03:15:24.600840Z"
        },
        "outputId": "49ce93b9-99a5-4f0b-c6e3-d21cc1c40106"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Think of   |  completes the request.  ### Instruction: Think of \nan example of a moral dilemma and explain why it    |  an example of a moral dilemma and explain why it  \nis difficult to make a decision.  ### Input:   ###  |  is difficult to make a decision.  ### Input:   ###\nResponse: The moral dilemma I would like to         |  Response: The moral dilemma I would like to       \nconsider is the following: A company has            |  consider is the following: A company has          \ndiscovered a way to increase its profits by         |  discovered a way to increase its profits by       \ncutting corners on safety regulations. The CEO is   |  cutting corners on safety regulations. The CEO is \nfaced with the decision of either continuing with   |  faced with the decision of either continuing with \nthe plan or stopping it altogether.   This dilemma  |  the plan or stopping it altogether.   This dilemma\nis difficult to make a decision about because the   |  is difficult to make a decision on because the    \nconsequences of each option are far-reaching and    |  consequences of both options are significant. If  \npotentially devastating. If the company continues   |  the company continues with the plan, it will      \nwith the plan, it could lead to increased profits,  |  increase profits but at the cost of endangering   \nbut at the cost of endangering the health and       |  the safety of its employees. On the other hand, if\nsafety of its employees and customers. On the       |  the company stops the plan, it will lose out on   \nother hand, if the company stops the plan, it       |  the opportunity to increase profits, but it will  \ncould lead to financial losses and damage to its    |  also prevent harm to its employees.   The decision\nreputation, but it would also prevent the           |  is further complicated by the fact that the CEO is\npotential harm caused by the continued violation    |  not entirely sure whether the safety regulations  \nof safety regulations.   In this case, the          |  are necessary or not. They may be necessary, but  \ndecision is not just about the immediate financial  |  they may also be outdated or ineffective.         \ngain or loss, but also about the long-term          |  Therefore, the CEO is left with the difficult task\nconsequences of the actions taken. It is a          |  of weighing the potential benefits and risks of   \ndifficult decision because the potential outcomes   |  each option.   In conclusion, the moral dilemma of\nare so severe and the consequences of each option   |  the company's decision-making process highlights  \nare so far-reaching. Therefore, it is difficult to  |  the importance of considering the long-term       \nmake a decision because the options are not just    |  consequences of one's actions and the need for a  \nabout the immediate consequences, but also about    |  balanced approach to decision-making. It also     \nthe long-term consequences of the actions taken.    |  highlights the importance of seeking advice from  \nIn conclusion, the moral dilemma of the company's   |  experts or stakeholders when faced with a         \ndecision to continue or stop the plan is difficult  |  difficult decision.<|endoftext|>                  \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. The decision is not just about the     |                                                    \nimmediate financial gain or loss, but also about    |                                                    \nthe long-term consequences of the actions taken.    |                                                    \nTherefore, it is a difficult decision because the   |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   The moral      |                                                    \ndilemma of the company's decision to continue or    |                                                    \nstop the plan is difficult to make a decision       |                                                    \nabout because the consequences of each option are   |                                                    \nfar-reaching and potentially devastating. The       |                                                    \ndecision is not just about the immediate financial  |                                                    \ngain or loss, but also about the long-term          |                                                    \nconsequences of the actions taken. Therefore, it    |                                                    \nis a difficult decision because the options are     |                                                    \nnot just about the immediate consequences, but      |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken.   The moral dilemma of the           |                                                    \ncompany's decision to continue or stop the plan is  |                                                    \ndifficult to make a decision about because the      |                                                    \nconsequences of each option are far-reaching and    |                                                    \npotentially devastating. The decision is not just   |                                                    \nabout the immediate financial gain or loss, but     |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken. Therefore, it is a difficult         |                                                    \ndecision because the options are not just about     |                                                    \nthe immediate consequences, but also about the      |                                                    \nlong-term consequences of the actions taken.   The  |                                                    \nmoral dilemma of the company's decision to          |                                                    \ncontinue or stop the plan is difficult to make a    |                                                    \ndecision about because the consequences of each     |                                                    \noption are far-reaching and potentially             |                                                    \ndevastating. The decision is not just about the     |                                                    \nimmediate financial gain or loss, but also about    |                                                    \nthe long-term consequences of the actions taken.    |                                                    \nTherefore, it is a difficult decision because the   |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   The moral      |                                                    \ndilemma of the company's decision to continue or    |                                                    \nstop the plan is difficult to make a decision       |                                                    \nabout because the consequences of each option are   |                                                    \nfar-reaching and potentially devastating. The       |                                                    \ndecision is not just about the immediate financial  |                                                    \ngain or loss, but also about the long-term          |                                                    \nconsequences of the actions taken. Therefore, it    |                                                    \nis a difficult decision because the options are     |                                                    \nnot just about the immediate consequences, but      |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken.   The moral dilemma of the           |                                                    \ncompany's decision to continue or stop the plan is  |                                                    \ndifficult to make a decision about because the      |                                                    \nconsequences of each option are far-reaching and    |                                                    \npotentially devastating. The decision is not just   |                                                    \nabout the immediate financial gain or loss, but     |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken. Therefore, it is a difficult         |                                                    \ndecision because the options are not just about     |                                                    \nthe immediate consequences, but also about the      |                                                    \nlong-term consequences of the actions taken.   The  |                                                    \nmoral dilemma of the company's decision to          |                                                    \ncontinue or stop the plan is difficult to make a    |                                                    \ndecision about because the consequences of each     |                                                    \noption are far-reaching and potentially             |                                                    \ndevastating. The decision is not just about the     |                                                    \nimmediate financial gain or loss, but also about    |                                                    \nthe long-term consequences of the actions taken.    |                                                    \nTherefore, it is a difficult decision because the   |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   The moral      |                                                    \ndilemma of the company's decision to continue or    |                                                    \nstop the plan is difficult to make a decision       |                                                    \nabout because the consequences of each option are   |                                                    \nfar-reaching and potentially devastating. The       |                                                    \ndecision is not just about the immediate financial  |                                                    \ngain or loss, but also about the long-term          |                                                    \nconsequences of the actions taken. Therefore, it    |                                                    \nis a difficult decision because the options are     |                                                    \nnot just about the immediate consequences, but      |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken.   The moral dilemma of the           |                                                    \ncompany's decision to continue or stop the plan is  |                                                    \ndifficult to make a decision about because the      |                                                    \nconsequences of each option are far-reaching and    |                                                    \npotentially devastating. The decision is not just   |                                                    \nabout the immediate financial gain or loss, but     |                                                    \nalso about the long-term consequences of the        |                                                    \nactions taken. Therefore, it is a difficult         |                                                    \ndecision because the options are not just           |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T03:15:55.786085Z",
          "iopub.execute_input": "2024-11-23T03:15:55.786445Z",
          "iopub.status.idle": "2024-11-23T03:16:18.852342Z",
          "shell.execute_reply.started": "2024-11-23T03:15:55.786413Z",
          "shell.execute_reply": "2024-11-23T03:16:18.851276Z"
        },
        "outputId": "28f98ab6-b622-4a2d-d0d5-acc673fab1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: List two   |  completes the request.  ### Instruction: List two \nproblems caused by climate change  ### Input:       |  problems caused by climate change  ### Input:     \n### Response: Climate change is a significant       |  ### Response: 1. **Increased Frequency of Extreme \nglobal issue that has far-reaching consequences.    |  Weather Events**: Climate change is causing more  \nTwo problems caused by climate change are rising    |  frequent and intense extreme weather events such  \nsea levels and extreme weather events. Rising sea   |  as hurricanes, heatwaves, and droughts. These     \nlevels can lead to flooding in coastal areas,       |  events can lead to significant economic and social\nwhile extreme weather events such as hurricanes,    |  impacts, including damage to infrastructure, loss \ndroughts, and heatwaves can cause significant       |  of life, and disruption of daily life.  2.        \ndamage to infrastructure and disrupt daily life.    |  **Disruption of Ecosystems and Biodiversity**:    \nThese problems highlight the urgent need for        |  Changes in temperature and precipitation patterns \naction to mitigate the effects of climate change.   |  due to climate change are leading to shifts in the\n                                                    |  distribution and abundance of species. This can   \n                                                    |  result in the loss of biodiversity, which can have\n                                                    |  cascading effects on ecosystems, including changes\n                                                    |  in food chains and the ability of ecosystems to   \n                                                    |  provide services such as pollination and water    \n                                                    |  purification. Additionally, the loss of certain   \n                                                    |  species can lead to a decrease in the resilience  \n                                                    |  of ecosystems, making them more vulnerable to     \n                                                    |  other disturbances.<|endoftext|>                  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T03:36:20.669139Z",
          "iopub.execute_input": "2024-11-23T03:36:20.669939Z",
          "iopub.status.idle": "2024-11-23T03:36:23.740091Z",
          "shell.execute_reply.started": "2024-11-23T03:36:20.669902Z",
          "shell.execute_reply": "2024-11-23T03:36:23.738983Z"
        },
        "outputId": "6adf0097-a434-4d03-9829-5cea77015521"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Provide a  |  completes the request.  ### Instruction: Provide a\nsuitable title  ### Input: This is a report on the  |  suitable title  ### Input: This is a report on the\npotential benefits of implementing renewable        |  potential benefits of implementing renewable      \nenergy  ### Response: \"Potential Benefits of        |  energy  ### Response: Title: \"Revolutionizing     \nImplementing Renewable Energy: A Comprehensive      |  Energy: The Potential Benefits of Implementing    \nReport\"                                             |  Renewable Energy\"<|endoftext|>                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loc = randint(0, len(dataset))\n",
        "prompt = dataset[loc]['instruction']\n",
        "inputs = dataset[loc]['input']\n",
        "pre_text = pre_assistant(prompt, inputs)\n",
        "post_text = post_assistant(prompt, inputs)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-23T03:46:09.694838Z",
          "iopub.execute_input": "2024-11-23T03:46:09.695200Z",
          "iopub.status.idle": "2024-11-23T03:47:22.589977Z",
          "shell.execute_reply.started": "2024-11-23T03:46:09.695169Z",
          "shell.execute_reply": "2024-11-23T03:47:22.589003Z"
        },
        "outputId": "bba782c7-b40c-4f88-ec24-9ca1738d0dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe 3 main components of a simple robotic system    |  the 3 main components of a simple robotic system  \nin a conversational manner as if you were talking   |  in a conversational manner as if you were talking \nto a friend.  ### Input:   ### Response: Sure,      |  to a friend.  ### Input:   ### Response: Sure,    \nlet's dive into the basics of a simple robotic      |  let's dive into the basics of a simple robotic    \nsystem. Imagine you're building a little robot      |  system. Imagine you're building a little robot    \nthat can do some basic tasks. Here's how you can    |  that can do some basic tasks. Here's how you can  \nthink about the three main components:  1. **The    |  think about the three main components:  1. **The  \nBrain**: This is the central part of your robot,    |  Brain**: This is the central part of your robot,  \nkind of like the brain of a human. It's where all   |  kind of like the brain of a human. It's where all \nthe instructions are stored and processed. In a     |  the instructions are stored and processed. In a   \nrobotic system, this is often called the            |  robotic system, this is often called the          \n\"controller\" or \"brain.\" It's where you write the   |  \"controller\" or \"brain controller.\" It's where you\ncode that tells the robot what to do. Think of it   |  write the code that tells the robot what to do.   \nas the \"command center\" of your robot.  2. **The    |  Think of it as the \"command center\" of your robot.\nBody**: This is the physical part of your robot,    |  2. **The Body**: This is the physical part of your\nlike the arms, legs, and wheels. It's where the     |  robot, like the body of a human. It's where all   \nrobot's movements are controlled. In a robotic      |  the parts are put together to make the robot work.\nsystem, this is often called the \"actuator\" or      |  In a robotic system, this is often called the     \n\"mechanism.\" It's where the robot's movements are   |  \"mechanical system\" or \"mechanical body.\" It's    \nmade possible. Think of it as the \"body\" of your    |  where you put the motors, sensors, and other parts\nrobot.  3. **The Senses**: This is the part of      |  that make the robot move and sense its            \nyour robot that helps it \"see\" and \"hear.\" It's     |  environment. Think of it as the \"body\" of your    \nlike the eyes and ears of your robot. In a robotic  |  robot.  3. **The Senses**: This is the part of    \nsystem, this is often called the \"sensor\" or        |  your robot that helps it \"see\" and \"hear\" its     \n\"detector.\" It's where the robot gets information   |  environment. It's like the eyes and ears of a     \nabout its environment. Think of it as the \"senses\"  |  human. In a robotic system, this is often called  \nof your robot.  So, in summary, a simple robotic    |  the \"sensing system\" or \"sensing body.\" It's where\nsystem is like a little robot that can do some      |  you put the sensors that help the robot \"see\" and \nbasic tasks. It has a brain (controller) that       |  \"hear\" its surroundings. Think of it as the       \ntells it what to do, a body (actuator) that makes   |  \"senses\" of your robot.  So, in summary, a simple \nit do those things, and a set of senses (sensor)    |  robotic system is like a little robot that can do \nthat help it understand its environment. It's like  |  some basic tasks. It has a brain that tells it    \na little robot that can move and see, but it's      |  what to do, a body that makes it move, and senses \nstill a very basic system. But with more complex    |  that help it \"see\" and \"hear\" its environment.    \nsystems, you can add more components like a memory  |  It's like a little robot that can do some basic   \n(storage) and a power supply (battery) to make      |  tasks, just like a human!<|endoftext|>            \nyour robot even more powerful and capable. But      |                                                    \nthat's a whole other topic! 😊  Does that help       |                                                    \nexplain it? Let me know if you have any more        |                                                    \nquestions! 🤖✨  [End of Response]                    |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}