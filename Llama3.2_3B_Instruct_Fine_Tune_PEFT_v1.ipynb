{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM_Fine_Tune/blob/main/Llama3.2_3B_Instruct_Fine_Tune_PEFT_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:11:19.775579Z",
          "iopub.execute_input": "2024-11-16T09:11:19.775999Z",
          "iopub.status.idle": "2024-11-16T09:12:07.235248Z",
          "shell.execute_reply.started": "2024-11-16T09:11:19.775949Z",
          "shell.execute_reply": "2024-11-16T09:12:07.233924Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "from random import randint\n",
        "from itertools import zip_longest\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "trusted": true,
        "outputId": "248c8f10-5eae-49a5-ba03-c6c30698404f",
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:07.237357Z",
          "iopub.execute_input": "2024-11-16T09:12:07.237699Z",
          "iopub.status.idle": "2024-11-16T09:12:15.890178Z",
          "shell.execute_reply.started": "2024-11-16T09:12:07.237664Z",
          "shell.execute_reply": "2024-11-16T09:12:15.889188Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "GPU is available!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "trusted": true,
        "outputId": "f7789872-8053-4e26-a665-0c4f94689529",
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:15.891423Z",
          "iopub.execute_input": "2024-11-16T09:12:15.891720Z",
          "iopub.status.idle": "2024-11-16T09:12:15.899457Z",
          "shell.execute_reply.started": "2024-11-16T09:12:15.891688Z",
          "shell.execute_reply": "2024-11-16T09:12:15.898423Z"
        }
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'unsloth/Llama-3.2-3B-Instruct'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:15.902092Z",
          "iopub.execute_input": "2024-11-16T09:12:15.902434Z",
          "iopub.status.idle": "2024-11-16T09:12:15.909233Z",
          "shell.execute_reply.started": "2024-11-16T09:12:15.902400Z",
          "shell.execute_reply": "2024-11-16T09:12:15.908244Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name, base = True):\n",
        "    if base == True:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype = torch.float16,\n",
        "            trust_remote_code = True\n",
        "        ).to(device)\n",
        "\n",
        "        return model\n",
        "\n",
        "    else:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit = True,\n",
        "            bnb_4bit_quant_type = 'nf4',\n",
        "            bnb_4bit_compute_dtype = torch.float16,\n",
        "            bnb_4bit_use_double_quant = True,\n",
        "        )\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config = bnb_config,\n",
        "            trust_remote_code = True\n",
        "        ).to(device)\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:15.910289Z",
          "iopub.execute_input": "2024-11-16T09:12:15.911453Z",
          "iopub.status.idle": "2024-11-16T09:12:15.919410Z",
          "shell.execute_reply.started": "2024-11-16T09:12:15.911408Z",
          "shell.execute_reply": "2024-11-16T09:12:15.918465Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:15.920453Z",
          "iopub.execute_input": "2024-11-16T09:12:15.920714Z",
          "iopub.status.idle": "2024-11-16T09:12:23.741825Z",
          "shell.execute_reply.started": "2024-11-16T09:12:15.920685Z",
          "shell.execute_reply": "2024-11-16T09:12:23.740750Z"
        },
        "outputId": "1dc5629d-2a75-4f91-c1c6-6c88ce7efe6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:23.743142Z",
          "iopub.execute_input": "2024-11-16T09:12:23.743541Z",
          "iopub.status.idle": "2024-11-16T09:12:23.754577Z",
          "shell.execute_reply.started": "2024-11-16T09:12:23.743503Z",
          "shell.execute_reply": "2024-11-16T09:12:23.753634Z"
        },
        "outputId": "bc690c6b-7942-489e-d044-74f8cff63988"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:23.755981Z",
          "iopub.execute_input": "2024-11-16T09:12:23.756390Z",
          "iopub.status.idle": "2024-11-16T09:12:24.443353Z",
          "shell.execute_reply.started": "2024-11-16T09:12:23.756346Z",
          "shell.execute_reply": "2024-11-16T09:12:24.442277Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'mlabonne/FineTome-100k'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:24.444614Z",
          "iopub.execute_input": "2024-11-16T09:12:24.444962Z",
          "iopub.status.idle": "2024-11-16T09:12:24.449244Z",
          "shell.execute_reply.started": "2024-11-16T09:12:24.444916Z",
          "shell.execute_reply": "2024-11-16T09:12:24.448238Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 1024"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:24.452887Z",
          "iopub.execute_input": "2024-11-16T09:12:24.453235Z",
          "iopub.status.idle": "2024-11-16T09:12:24.459842Z",
          "shell.execute_reply.started": "2024-11-16T09:12:24.453197Z",
          "shell.execute_reply": "2024-11-16T09:12:24.458781Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:24.460956Z",
          "iopub.execute_input": "2024-11-16T09:12:24.461308Z",
          "iopub.status.idle": "2024-11-16T09:12:27.993313Z",
          "shell.execute_reply.started": "2024-11-16T09:12:24.461276Z",
          "shell.execute_reply": "2024-11-16T09:12:27.992345Z"
        },
        "outputId": "23632afe-8600-44cf-b669-5b264e6d7d61"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.select(range(10000))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:27.994505Z",
          "iopub.execute_input": "2024-11-16T09:12:27.994834Z",
          "iopub.status.idle": "2024-11-16T09:12:28.002272Z",
          "shell.execute_reply.started": "2024-11-16T09:12:27.994797Z",
          "shell.execute_reply": "2024-11-16T09:12:28.001540Z"
        },
        "id": "iEaSHbIbdyLO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.003454Z",
          "iopub.execute_input": "2024-11-16T09:12:28.003812Z",
          "iopub.status.idle": "2024-11-16T09:12:28.035213Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.003778Z",
          "shell.execute_reply": "2024-11-16T09:12:28.034323Z"
        },
        "outputId": "47f27d1f-b9e7-472d-a509-125dfb7543b0"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.036287Z",
          "iopub.execute_input": "2024-11-16T09:12:28.036583Z",
          "iopub.status.idle": "2024-11-16T09:12:28.043478Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.036553Z",
          "shell.execute_reply": "2024-11-16T09:12:28.042422Z"
        },
        "outputId": "0b8f8f90-2242-4a6e-8c74-d59b1e869299"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.044755Z",
          "iopub.execute_input": "2024-11-16T09:12:28.045101Z",
          "iopub.status.idle": "2024-11-16T09:12:28.051368Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.045067Z",
          "shell.execute_reply": "2024-11-16T09:12:28.050277Z"
        },
        "outputId": "78526191-fa3e-40b1-adee-31d258b6eea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['conversations', 'source', 'score']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_conversations(example):\n",
        "  role_map = {\n",
        "    'human' : 'user',\n",
        "    'gpt' : 'assistant'\n",
        "  }\n",
        "\n",
        "  transformed_conversations = [\n",
        "    {\n",
        "      'role' : role_map.get(turn['from'], turn['from']),\n",
        "      'content' : turn['value']\n",
        "    }\n",
        "    for turn in example['conversations']\n",
        "  ]\n",
        "  return {'conversations': transformed_conversations}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.052478Z",
          "iopub.execute_input": "2024-11-16T09:12:28.052815Z",
          "iopub.status.idle": "2024-11-16T09:12:28.059928Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.052781Z",
          "shell.execute_reply": "2024-11-16T09:12:28.058957Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.061505Z",
          "iopub.execute_input": "2024-11-16T09:12:28.061840Z",
          "iopub.status.idle": "2024-11-16T09:12:28.075366Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.061805Z",
          "shell.execute_reply": "2024-11-16T09:12:28.074450Z"
        },
        "outputId": "9f956e12-ce6d-4bee-e94a-2b32cfa8c46f"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['conversations'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['conversations'])"
      ],
      "metadata": {
        "id": "cZya4tPEWUc9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.076549Z",
          "iopub.execute_input": "2024-11-16T09:12:28.076942Z",
          "iopub.status.idle": "2024-11-16T09:12:28.085240Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.076897Z",
          "shell.execute_reply": "2024-11-16T09:12:28.084068Z"
        },
        "outputId": "3f9b3119-5297-454f-8266-adbd2cbc9490"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def format_conversation(example):\n",
        "  for entry in example['conversations']:\n",
        "    role = entry['role']\n",
        "    content = entry['content']\n",
        "\n",
        "    if role == 'user':\n",
        "      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "    elif role == 'assistant':\n",
        "      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "\n",
        "  return {'prompt': formatted_text}"
      ],
      "metadata": {
        "id": "3bmXGueQWWzt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.086428Z",
          "iopub.execute_input": "2024-11-16T09:12:28.086758Z",
          "iopub.status.idle": "2024-11-16T09:12:28.094708Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.086710Z",
          "shell.execute_reply": "2024-11-16T09:12:28.093813Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = formatted_dataset.map(\n",
        "  format_conversation,\n",
        "  remove_columns = list(formatted_dataset.features.keys())\n",
        ")\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "Z6sSaCr5eaL7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.096078Z",
          "iopub.execute_input": "2024-11-16T09:12:28.096934Z",
          "iopub.status.idle": "2024-11-16T09:12:28.109737Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.096877Z",
          "shell.execute_reply": "2024-11-16T09:12:28.108825Z"
        },
        "outputId": "ff2cefb6-a944-4dcd-b308-9b536bebcc5c"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.111020Z",
          "iopub.execute_input": "2024-11-16T09:12:28.111396Z",
          "iopub.status.idle": "2024-11-16T09:12:28.116865Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.111354Z",
          "shell.execute_reply": "2024-11-16T09:12:28.115949Z"
        },
        "outputId": "9ea9fabb-8989-40f2-898e-d474318cc3e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.118198Z",
          "iopub.execute_input": "2024-11-16T09:12:28.118568Z",
          "iopub.status.idle": "2024-11-16T09:12:28.126044Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.118527Z",
          "shell.execute_reply": "2024-11-16T09:12:28.125338Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.127057Z",
          "iopub.execute_input": "2024-11-16T09:12:28.127981Z",
          "iopub.status.idle": "2024-11-16T09:12:28.348953Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.127935Z",
          "shell.execute_reply": "2024-11-16T09:12:28.347839Z"
        },
        "outputId": "1b295cb2-1b88-44ab-d54f-92e7ce6e30f3"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.350394Z",
          "iopub.execute_input": "2024-11-16T09:12:28.350777Z",
          "iopub.status.idle": "2024-11-16T09:12:28.358428Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.350742Z",
          "shell.execute_reply": "2024-11-16T09:12:28.357528Z"
        },
        "outputId": "92658366-2cac-418e-d8cb-385b68f331d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.359492Z",
          "iopub.execute_input": "2024-11-16T09:12:28.359779Z",
          "iopub.status.idle": "2024-11-16T09:12:28.376032Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.359742Z",
          "shell.execute_reply": "2024-11-16T09:12:28.375129Z"
        },
        "outputId": "1e5881ae-ae3c-41db-a9f0-02b4437f9898"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_dataset['train']\n",
        "test_dataset = tokenized_dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.377302Z",
          "iopub.execute_input": "2024-11-16T09:12:28.378041Z",
          "iopub.status.idle": "2024-11-16T09:12:28.384473Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.378005Z",
          "shell.execute_reply": "2024-11-16T09:12:28.383613Z"
        },
        "outputId": "efc6bdf8-9526-4d41-ca63-38179501f0cf"
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.385834Z",
          "iopub.execute_input": "2024-11-16T09:12:28.386560Z",
          "iopub.status.idle": "2024-11-16T09:12:28.414591Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.386489Z",
          "shell.execute_reply": "2024-11-16T09:12:28.413694Z"
        },
        "outputId": "085b9b43-acbe-43f1-eabc-27e3ba12eb07"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n\n                                           input_ids  \\\n0  [128004, 128004, 128004, 128004, 128004, 12800...   \n1  [128004, 128004, 128004, 128004, 128004, 12800...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128004, 128004, 128004, 128004, 128004, 12800...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.420444Z",
          "iopub.execute_input": "2024-11-16T09:12:28.420733Z",
          "iopub.status.idle": "2024-11-16T09:12:28.426924Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.420703Z",
          "shell.execute_reply": "2024-11-16T09:12:28.426083Z"
        },
        "outputId": "e1a63b7f-9555-46c0-da13-dadd7375b887"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|start_header_id|>user<|end_header_id|>\n\nHow do you graph the inequality #x > -4#?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo graph the inequality #x > -4#, follow these steps:\n\n1. Start by plotting the boundary line: Draw a vertical line at #x = -4# on the X-axis. This line divides the X-axis into two halves.\n\n2. Identify the direction of the inequality: Since the inequality is #x > -4#, it indicates that we are looking for all values of #x# that are greater than -4.\n\n3. Shade the appropriate region: Shade the entire region to the right of the line at #x = -4#. This shaded area represents all the points whose X-coordinate is greater than -4.\n\n4. Include a dashed line: Since the inequality is \"greater than\" (#>,# not \"##\"), draw the line at #x = -4# as a dashed line, indicating that the points on the line itself are not included in the solution.\n\nThe graph consists of the entire half-plane to the right of the dashed vertical line at #x = -4#, excluding the line itself.\n<|eot_id|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "id": "HR79ppIiE78f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.428344Z",
          "iopub.execute_input": "2024-11-16T09:12:28.429124Z",
          "iopub.status.idle": "2024-11-16T09:12:28.437165Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.429089Z",
          "shell.execute_reply": "2024-11-16T09:12:28.436246Z"
        },
        "outputId": "0efd115f-e5ad-4155-b966-d77d65b0972c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128004, 128000, 128006, 882, 128007, 271, 4438, 656, 499, 4876, 279, 32305, 674, 87, 871, 482, 19, 2, 5380, 128009, 128006, 78191, 128007, 271, 1271, 4876, 279, 32305, 674, 87, 871, 482, 19, 61878, 1833, 1521, 7504, 1473, 16, 13, 5256, 555, 45002, 279, 19254, 1584, 25, 12261, 264, 12414, 1584, 520, 674, 87, 284, 482, 19, 2, 389, 279, 1630, 36421, 13, 1115, 1584, 65928, 279, 1630, 36421, 1139, 1403, 75212, 382, 17, 13, 65647, 279, 5216, 315, 279, 32305, 25, 8876, 279, 32305, 374, 674, 87, 871, 482, 19, 61878, 433, 15151, 430, 584, 527, 3411, 369, 682, 2819, 315, 674, 87, 2, 430, 527, 7191, 1109, 482, 19, 382, 18, 13, 80918, 279, 8475, 5654, 25, 80918, 279, 4553, 5654, 311, 279, 1314, 315, 279, 1584, 520, 674, 87, 284, 482, 19, 88946, 1115, 92866, 3158, 11105, 682, 279, 3585, 6832, 1630, 81797, 374, 7191, 1109, 482, 19, 382, 19, 13, 30834, 264, 67822, 1584, 25, 8876, 279, 32305, 374, 330, 66335, 1109, 1, 30183, 8226, 2, 539, 5993, 120156, 2, 4063, 4128, 279, 1584, 520, 674, 87, 284, 482, 19, 2, 439, 264, 67822, 1584, 11, 19392, 430, 279, 3585, 389, 279, 1584, 5196, 527, 539, 5343, 304, 279, 6425, 382, 791, 4876, 17610, 315, 279, 4553, 4376, 90649, 311, 279, 1314, 315, 279, 67822, 12414, 1584, 520, 674, 87, 284, 482, 19, 61878, 44878, 279, 1584, 5196, 627, 128009]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "id": "xGmCvvZTE82D",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.438364Z",
          "iopub.execute_input": "2024-11-16T09:12:28.438734Z",
          "iopub.status.idle": "2024-11-16T09:12:28.448139Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.438691Z",
          "shell.execute_reply": "2024-11-16T09:12:28.447142Z"
        },
        "outputId": "68b494c0-a7ed-4b76-85af-e5c640b0e143"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.449345Z",
          "iopub.execute_input": "2024-11-16T09:12:28.449636Z",
          "iopub.status.idle": "2024-11-16T09:12:28.456241Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.449604Z",
          "shell.execute_reply": "2024-11-16T09:12:28.455336Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.457363Z",
          "iopub.execute_input": "2024-11-16T09:12:28.457663Z",
          "iopub.status.idle": "2024-11-16T09:12:28.466296Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.457631Z",
          "shell.execute_reply": "2024-11-16T09:12:28.465430Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.467534Z",
          "iopub.execute_input": "2024-11-16T09:12:28.468187Z",
          "iopub.status.idle": "2024-11-16T09:12:28.478237Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.468143Z",
          "shell.execute_reply": "2024-11-16T09:12:28.477346Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.479287Z",
          "iopub.execute_input": "2024-11-16T09:12:28.479654Z",
          "iopub.status.idle": "2024-11-16T09:12:28.487252Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.479611Z",
          "shell.execute_reply": "2024-11-16T09:12:28.486419Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:28.488329Z",
          "iopub.execute_input": "2024-11-16T09:12:28.488646Z",
          "iopub.status.idle": "2024-11-16T09:12:29.843775Z",
          "shell.execute_reply.started": "2024-11-16T09:12:28.488615Z",
          "shell.execute_reply": "2024-11-16T09:12:29.842747Z"
        },
        "outputId": "00527b85-372c-47d5-e736-97b2f13797ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 97,255,424 || all params: 3,310,005,248 || trainable%: 2.9382\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:29.845126Z",
          "iopub.execute_input": "2024-11-16T09:12:29.845562Z",
          "iopub.status.idle": "2024-11-16T09:12:29.868536Z",
          "shell.execute_reply.started": "2024-11-16T09:12:29.845515Z",
          "shell.execute_reply": "2024-11-16T09:12:29.867441Z"
        },
        "outputId": "2b13f13f-ef3a-49ce-d602-97fa8c1c5aaf"
      },
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:29.869738Z",
          "iopub.execute_input": "2024-11-16T09:12:29.870130Z",
          "iopub.status.idle": "2024-11-16T09:12:29.893501Z",
          "shell.execute_reply.started": "2024-11-16T09:12:29.870087Z",
          "shell.execute_reply": "2024-11-16T09:12:29.892444Z"
        },
        "outputId": "f58af747-6a29-4ed0-be0f-71fbcf218835"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1900719104\nTrainable parameters : 97255424\nTrainable percentage: 5.12%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:29.895027Z",
          "iopub.execute_input": "2024-11-16T09:12:29.895362Z",
          "iopub.status.idle": "2024-11-16T09:12:29.901300Z",
          "shell.execute_reply.started": "2024-11-16T09:12:29.895326Z",
          "shell.execute_reply": "2024-11-16T09:12:29.900331Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 1\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = True,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:29.902484Z",
          "iopub.execute_input": "2024-11-16T09:12:29.903380Z",
          "iopub.status.idle": "2024-11-16T09:12:29.942009Z",
          "shell.execute_reply.started": "2024-11-16T09:12:29.903340Z",
          "shell.execute_reply": "2024-11-16T09:12:29.940955Z"
        },
        "outputId": "5bb7d840-1ec0-4103-841a-ad8f18d80f4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov16_09-12-29_13d0209803f8,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(200)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:29.943255Z",
          "iopub.execute_input": "2024-11-16T09:12:29.943641Z",
          "iopub.status.idle": "2024-11-16T09:12:31.911238Z",
          "shell.execute_reply.started": "2024-11-16T09:12:29.943607Z",
          "shell.execute_reply": "2024-11-16T09:12:31.910189Z"
        },
        "outputId": "8452cf81-7baa-46f8-a7d5-3fdc04acdd26"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n",
          "output_type": "stream"
        },
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<trl.trainer.sft_trainer.SFTTrainer at 0x7a417024bee0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T09:12:31.912632Z",
          "iopub.execute_input": "2024-11-16T09:12:31.912946Z",
          "iopub.status.idle": "2024-11-16T10:31:20.036779Z",
          "shell.execute_reply.started": "2024-11-16T09:12:31.912912Z",
          "shell.execute_reply": "2024-11-16T10:31:20.035774Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:31:20.038136Z",
          "iopub.execute_input": "2024-11-16T10:31:20.038457Z",
          "iopub.status.idle": "2024-11-16T10:34:59.878231Z",
          "shell.execute_reply.started": "2024-11-16T10:31:20.038422Z",
          "shell.execute_reply": "2024-11-16T10:34:59.877300Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:34:59.879483Z",
          "iopub.execute_input": "2024-11-16T10:34:59.879797Z",
          "iopub.status.idle": "2024-11-16T10:35:02.992852Z",
          "shell.execute_reply.started": "2024-11-16T10:34:59.879763Z",
          "shell.execute_reply": "2024-11-16T10:35:02.991740Z"
        },
        "outputId": "cdd88691-fced-4083-f799-3a7c1055c177"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:02.995820Z",
          "iopub.execute_input": "2024-11-16T10:35:02.996733Z",
          "iopub.status.idle": "2024-11-16T10:35:03.173733Z",
          "shell.execute_reply.started": "2024-11-16T10:35:02.996695Z",
          "shell.execute_reply": "2024-11-16T10:35:03.172748Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_path = save_path + '/LoRA'\n",
        "peft_path"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:03.175591Z",
          "iopub.execute_input": "2024-11-16T10:35:03.176020Z",
          "iopub.status.idle": "2024-11-16T10:35:03.283527Z",
          "shell.execute_reply.started": "2024-11-16T10:35:03.175976Z",
          "shell.execute_reply": "2024-11-16T10:35:03.282726Z"
        },
        "id": "dyn9XiLIdyLc",
        "outputId": "eab53891-b46f-4d3d-f46c-b4ae9e66f1fb"
      },
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'./model/LoRA'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, peft_path)"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:03.284575Z",
          "iopub.execute_input": "2024-11-16T10:35:03.284920Z",
          "iopub.status.idle": "2024-11-16T10:35:04.925267Z",
          "shell.execute_reply.started": "2024-11-16T10:35:03.284869Z",
          "shell.execute_reply": "2024-11-16T10:35:04.924458Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Reload & Recheck Base Model"
      ],
      "metadata": {
        "id": "--OTxz-7dyLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(model_name, base = False)\n",
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:04.926450Z",
          "iopub.execute_input": "2024-11-16T10:35:04.926829Z",
          "iopub.status.idle": "2024-11-16T10:35:11.802777Z",
          "shell.execute_reply.started": "2024-11-16T10:35:04.926784Z",
          "shell.execute_reply": "2024-11-16T10:35:11.801913Z"
        },
        "id": "btW2UJOpdyLc",
        "outputId": "763ae7ae-159b-46d8-edbb-77ef60f10846"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"unsloth/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ]\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/Llama-3.2-3B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/bc836a93eabc97432d7be9faedddf045ca7ad8fc/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n",
          "output_type": "stream"
        },
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.804078Z",
          "iopub.execute_input": "2024-11-16T10:35:11.804477Z",
          "iopub.status.idle": "2024-11-16T10:35:11.816550Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.804432Z",
          "shell.execute_reply": "2024-11-16T10:35:11.815439Z"
        },
        "id": "9GWu9tKbdyLc",
        "outputId": "41f051d2-d4bf-4823-e405-55322e83ef0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.817762Z",
          "iopub.execute_input": "2024-11-16T10:35:11.818378Z",
          "iopub.status.idle": "2024-11-16T10:35:11.845353Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.818334Z",
          "shell.execute_reply": "2024-11-16T10:35:11.844482Z"
        },
        "id": "v-Eq2uWadyLd",
        "outputId": "8d9b641a-3f60-4a1b-e19d-7f37525283e1"
      },
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 3072)\n        (layers): ModuleList(\n          (0-27): 28 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.846751Z",
          "iopub.execute_input": "2024-11-16T10:35:11.847061Z",
          "iopub.status.idle": "2024-11-16T10:35:11.878301Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.847029Z",
          "shell.execute_reply": "2024-11-16T10:35:11.877412Z"
        },
        "id": "bOZxERPYdyLd",
        "outputId": "3aa75847-29a7-44f3-a418-e9a11469d9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total parameters : 1997974528\nTrainable parameters : 0\nTrainable percentage: 0.00%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Pre Test & Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.879330Z",
          "iopub.execute_input": "2024-11-16T10:35:11.879631Z",
          "iopub.status.idle": "2024-11-16T10:35:11.886855Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.879599Z",
          "shell.execute_reply": "2024-11-16T10:35:11.885924Z"
        },
        "id": "BHmJvmLvdyLd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.887980Z",
          "iopub.execute_input": "2024-11-16T10:35:11.888309Z",
          "iopub.status.idle": "2024-11-16T10:35:11.899742Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.888256Z",
          "shell.execute_reply": "2024-11-16T10:35:11.898985Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_side_by_side(pre_text, post_text, width = 50):\n",
        "  pre_wrapped = textwrap.wrap(pre_text, width)\n",
        "  post_wrapped = textwrap.wrap(post_text, width)\n",
        "\n",
        "  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n",
        "  print(\n",
        "    str(sum(p.numel() for p in model.parameters())).center(width),\n",
        "    '|',\n",
        "    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n",
        "  )\n",
        "  print('=' * width, '|', '=' * width)\n",
        "\n",
        "  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n",
        "    print(pre.ljust(width), ' | ', post.ljust(width))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:35:11.900857Z",
          "iopub.execute_input": "2024-11-16T10:35:11.901223Z",
          "iopub.status.idle": "2024-11-16T10:35:11.911384Z",
          "shell.execute_reply.started": "2024-11-16T10:35:11.901191Z",
          "shell.execute_reply": "2024-11-16T10:35:11.910582Z"
        },
        "id": "dbH5wS7IdyLd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:48:37.600001Z",
          "iopub.execute_input": "2024-11-16T10:48:37.600327Z",
          "iopub.status.idle": "2024-11-16T10:50:24.552234Z",
          "shell.execute_reply.started": "2024-11-16T10:48:37.600291Z",
          "shell.execute_reply": "2024-11-16T10:50:24.551238Z"
        },
        "outputId": "83950e5c-9e0b-4d4e-d045-40ca7495ce49"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n<|begin_of_text|><|start_header_id|>system<|end_he  |  <|begin_of_text|><|start_header_id|>system<|end_he\nader_id|>  Cutting Knowledge Date: December 2023    |  ader_id|>  Cutting Knowledge Date: December 2023  \nToday Date: 16 Nov 2024  <|eot_id|><|start_header_  |  Today Date: 16 Nov 2024  <|eot_id|><|start_header_\nid|>human<|end_header_id|>  How can students learn  |  id|>human<|end_header_id|>  How can students learn\nabout the real-life applications of chemistry in    |  about the real-life applications of chemistry in  \neveryday life despite limited exposure to           |  everyday life despite limited exposure to         \nchemistry beyond the classroom?<|eot_id|><|start_h  |  chemistry beyond the classroom?<|eot_id|><|start_h\neader_id|>assistant<|end_header_id|>  Students can  |  eader_id|>assistant<|end_header_id|>  Students can\nlearn about the real-life applications of           |  learn about the real-life applications of         \nchemistry in everyday life despite limited          |  chemistry in everyday life despite limited        \nexposure to chemistry beyond the classroom by:  1.  |  exposure to chemistry beyond the classroom by:  1.\n**Exploring online resources**: Websites like       |  **Exploring online resources**: Websites like     \nChemistry.com, SciShow, and Crash Course Chemistry  |  Chemistry.com, SciShow, and Crash Course Chemistry\noffer engaging videos, articles, and interactive    |  offer engaging videos, articles, and interactive  \nsimulations that demonstrate chemistry's relevance  |  simulations that demonstrate chemistry's relevance\nto everyday life. 2. **Real-world examples**:       |  to everyday life. 2. **Real-world examples**:     \nEncourage students to find examples of chemistry    |  Encourage students to find examples of chemistry  \nin action in their daily lives, such as:         *  |  in action in their daily lives, such as:         *\nHow soap works (emulsification and surfactants)     |  How soap works (emulsification and surfactants)   \n* How batteries work (electrochemistry)         *   |  * How batteries work (electrochemistry)         * \nHow food is preserved (preservatives and            |  How food is preserved (preservatives and          \nsterilization)         * How medicines work         |  sterilization)         * How medicines work       \n(pharmaceutical chemistry) 3. **Case studies**:     |  (pharmaceutical chemistry) 3. **Case studies**:   \nUse real-life case studies to illustrate            |  Use real-life case studies to illustrate          \nchemistry's impact on various industries, such as:  |  chemistry's impact on various industries, such as:\n* The development of new materials (e.g., Kevlar,   |  * The development of new materials (e.g., Kevlar, \nnanotechnology)         * The production of clean   |  nanotechnology)         * The production of clean \nenergy (e.g., solar cells, fuel cells)         *    |  energy (e.g., solar cells, fuel cells)         *  \nThe creation of new medical treatments (e.g., gene  |  The creation of new medical treatments (e.g., gene\nediting, targeted therapies) 4. **Hands-on          |  editing, targeted therapies) 4. **Hands-on        \nactivities**: Engage students in hands-on           |  activities**: Engage students in hands-on         \nactivities that demonstrate chemistry's             |  activities that demonstrate chemistry's           \napplications, such as:         * Building a         |  applications, such as:         * Building a       \nvolcano (geology and chemical reactions)         *  |  volcano (geology and chemical reactions)         *\nCreating a homemade battery (electrochemistry)      |  Creating a homemade battery (electrochemistry)    \n* Making slime (polymers and non-Newtonian fluids)  |  * Making slime (polymers and non-Newtonian fluids)\n5. **Guest speakers**: Invite professionals from    |  5. **Guest speakers**: Invite professionals from  \nvarious fields to share their experiences and       |  various fields to share their experiences and     \nillustrate how chemistry is used in their work,     |  illustrate how chemistry is used in their work,   \nsuch as:         * Chemists working in              |  such as:         * Chemists working in            \npharmaceuticals or materials science         *      |  pharmaceuticals or materials science         *    \nEngineers developing new technologies         *     |  Engineers developing new technologies         *   \nScientists studying environmental issues 6.         |  Scientists studying environmental issues 6.       \n**Project-based learning**: Assign projects that    |  **Project-based learning**: Assign projects that  \nrequire students to research and present on a       |  require students to research and present on a     \nspecific chemistry-related topic, such as:          |  specific chemistry-related topic, such as:        \n* Developing a new product or material         *    |  * Developing a new product or material         *  \nInvestigating the environmental impact of a         |  Investigating the environmental impact of a       \nparticular industry         * Creating a            |  particular industry         * Creating a          \nchemistry-based game or simulation 7.               |  chemistry-based game or simulation 7.             \n**Collaboration with other subjects**: Encourage    |  **Collaboration with other subjects**: Encourage  \ninterdisciplinary learning by connecting chemistry  |  interdisciplinary learning by connecting chemistry\nto other subjects, such as:         * Biology:      |  to other subjects, such as:         * Biology:    \nexploring the chemistry of biological systems       |  exploring the chemistry behind biological         \n* Physics: understanding the chemistry behind       |  processes (e.g., photosynthesis, metabolism)      \nphysical phenomena         * Math: using            |  * Physics: understanding the chemistry behind     \nmathematical models to describe chemical reactions  |  physical phenomena (e.g., light, sound)         * \n8. **Online simulations and games**: Utilize        |  Math: using mathematical models to describe       \nonline simulations and games that teach chemistry   |  chemical reactions and processes 8. **Real-world  \nconcepts in an engaging and interactive way, such   |  applications in everyday life**: Encourage        \nas:         * PhET Interactive Simulations          |  students to think about how chemistry is used in  \n(University of Colorado Boulder)         *          |  their daily lives, such as:         * How their   \nChemistry Lab Simulator (University of California,  |  favorite foods are prepared and preserved         \nBerkeley)         * Chemistry Games (National       |  * How their favorite products (e.g., toothpaste,  \nInstitute of Standards and Technology) 9. **Field   |  shampoo) work         * How their community uses  \ntrips**: Organize field trips to visit chemistry-   |  chemistry to address environmental issues  By     \nrelated facilities, such as:         * Chemical     |  incorporating these strategies, students can      \nplants or manufacturing facilities         *        |  develop a deeper understanding of chemistry's     \nResearch institutions or universities         *     |  relevance to everyday life, even without extensive\nScience museums or centers 10. **Encourage          |  exposure to chemistry beyond the                  \ncuriosity**: Foster a culture of curiosity and      |  classroom.<|eot_id|>                              \nexploration, encouraging students to ask questions  |                                                    \nand seek out answers about the chemistry behind     |                                                    \neveryday phenomena.  By incorporating these         |                                                    \nstrategies, students can develop a deeper           |                                                    \nunderstanding of chemistry's relevance to everyday  |                                                    \nlife, even without extensive exposure to chemistry  |                                                    \nbeyond the classroom.<|eot_id|>                     |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:36:21.530450Z",
          "iopub.execute_input": "2024-11-16T10:36:21.530777Z",
          "iopub.status.idle": "2024-11-16T10:37:22.581493Z",
          "shell.execute_reply.started": "2024-11-16T10:36:21.530742Z",
          "shell.execute_reply": "2024-11-16T10:37:22.580514Z"
        },
        "outputId": "922eae78-8c28-426c-8a84-2448e44f2e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n<|begin_of_text|><|start_header_id|>system<|end_he  |  <|begin_of_text|><|start_header_id|>system<|end_he\nader_id|>  Cutting Knowledge Date: December 2023    |  ader_id|>  Cutting Knowledge Date: December 2023  \nToday Date: 16 Nov 2024  <|eot_id|><|start_header_  |  Today Date: 16 Nov 2024  <|eot_id|><|start_header_\nid|>human<|end_header_id|>  What is the function    |  id|>human<|end_header_id|>  What is the function  \nof the three tiny bones in the middle ear and how   |  of the three tiny bones in the middle ear and how \ndo they contribute to the process of hearing?<|eot  |  do they contribute to the process of hearing?<|eot\n_id|><|start_header_id|>assistant<|end_header_id|>  |  _id|><|start_header_id|>assistant<|end_header_id|>\nThe three tiny bones in the middle ear are called   |  The three tiny bones in the middle ear are called \nossicles (plural for ossicle). They are:  1.        |  ossicles (plural for ossicle). They are:  1.      \nMalleus (hammer) 2. Incus (anvil) 3. Stapes         |  Malleus (hammer) 2. Incus (anvil) 3. Stapes       \n(stirrup)  Their primary function is to transmit    |  (stirrup)  Their primary function is to transmit  \nsound vibrations from the eardrum to the inner      |  sound vibrations from the eardrum to the inner    \near, where they are converted into electrical       |  ear, where they are converted into electrical     \nsignals that are interpreted by the brain.  Here's  |  signals that are interpreted by the brain.  Here's\nhow they contribute to the process of hearing:  1.  |  how they contribute to the process of hearing:  1.\n**Sound waves reach the eardrum**: When sound       |  **Sound waves reach the eardrum**: When sound     \nwaves enter the ear, they cause the eardrum to      |  waves enter the ear, they cause the eardrum to    \nvibrate. 2. **Vibrations are transmitted to the     |  vibrate. 2. **Vibrations are transmitted to the   \nossicles**: The vibrations from the eardrum are     |  ossicles**: The vibrations from the eardrum are   \ntransmitted to the malleus, which is attached to    |  transmitted to the malleus, which is attached to  \nthe eardrum. 3. **Ossicles amplify the              |  the eardrum. 3. **Ossicles amplify the            \nvibrations**: The malleus, incus, and stapes work   |  vibrations**: The malleus, incus, and stapes work \ntogether to amplify the vibrations, making them     |  together to amplify the vibrations, creating a    \nstronger and more efficient. 4. **Stapes transmits  |  more intense signal. 4. **Stapes transmits the    \nvibrations to the inner ear**: The stapes, the      |  signal to the inner ear**: The stapes, the        \nsmallest bone in the human body, transmits the      |  smallest bone in the human body, transmits the    \namplified vibrations to the oval window of the      |  amplified vibrations to the oval window of the    \ncochlea, a spiral-shaped structure in the inner     |  cochlea, a spiral-shaped structure in the inner   \near. 5. **Vibrations are converted into electrical  |  ear. 5. **Cochlea converts vibrations into        \nsignals**: The vibrations are converted into        |  electrical signals**: The vibrations are converted\nelectrical signals by the hair cells in the         |  into electrical signals by the hair cells in the  \ncochlea, which are specialized sensory cells. 6.    |  cochlea. 6. **Signals are transmitted to the      \n**Signals are interpreted by the brain**: The       |  brain**: The electrical signals are transmitted to\nelectrical signals are transmitted to the brain,    |  the brain, where they are interpreted as sound.   \nwhere they are interpreted as sound.  In summary,   |  In summary, the ossicles play a crucial role in   \nthe ossicles play a crucial role in amplifying and  |  amplifying and transmitting sound vibrations from \ntransmitting sound vibrations from the eardrum to   |  the eardrum to the inner ear, allowing us to      \nthe inner ear, allowing us to perceive and          |  perceive and interpret sound.<|eot_id|>           \ninterpret sound.<|eot_id|>                          |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:37:22.582833Z",
          "iopub.execute_input": "2024-11-16T10:37:22.583187Z",
          "iopub.status.idle": "2024-11-16T10:38:13.283621Z",
          "shell.execute_reply.started": "2024-11-16T10:37:22.583150Z",
          "shell.execute_reply": "2024-11-16T10:38:13.282673Z"
        },
        "outputId": "1f9c51be-53ee-4fb3-d863-f359e824d7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n<|begin_of_text|><|start_header_id|>system<|end_he  |  <|begin_of_text|><|start_header_id|>system<|end_he\nader_id|>  Cutting Knowledge Date: December 2023    |  ader_id|>  Cutting Knowledge Date: December 2023  \nToday Date: 16 Nov 2024  <|eot_id|><|start_header_  |  Today Date: 16 Nov 2024  <|eot_id|><|start_header_\nid|>human<|end_header_id|>  Solve the following     |  id|>human<|end_header_id|>  Solve the following   \nmath problem step-by-step. Simplify your answer as  |  math problem step-by-step. Simplify your answer as\nmuch as possible. Present your final answer as      |  much as possible. Present your final answer as    \n\\boxed{Your Answer}. if the height of a cone is     |  \\boxed{Your Answer}. if the height of a cone is   \nincreased by 160 % then its volume is increased by  |  increased by 160 % then its volume is increased by\n?<|eot_id|><|start_header_id|>assistant<|end_heade  |  ?<|eot_id|><|start_header_id|>assistant<|end_heade\nr_id|>  To solve this problem, we need to           |  r_id|>  To solve this problem, we need to         \nunderstand how the volume of a cone is affected by  |  understand how the volume of a cone is affected by\nchanges in its height.  The formula for the volume  |  changes in its height.  The formula for the volume\nof a cone is:  V = (1/3)rh  where V is the        |  of a cone is:  V = (1/3)rh  where V is the      \nvolume,  is a constant, r is the radius, and h is  |  volume,  is a constant, r is the radius, and h is\nthe height.  Let's assume the original height of    |  the height.  If the height of the cone is         \nthe cone is h, and its original volume is V. If     |  increased by 160%, the new height (h') is:  h' = h\nthe height is increased by 160%, the new height     |  + (160/100)h h' = h + 1.6h h' = 2.6h  Now, we need\nis:  h' = h + (160/100)h = 3.6h  Now, we need to    |  to find the new volume (V') in terms of the       \nfind the new volume, V'. We can plug in the new     |  original volume (V).  V' = (1/3)rh' =           \nheight into the volume formula:  V' =               |  (1/3)r(2.6h) = 2.6(1/3)rh = 2.6V  So, the     \n(1/3)r(3.6h) = (1/3)rh * 3.6 = 3.6V  So, the    |  volume of the cone is increased by a factor of    \nvolume of the cone is increased by a factor of      |  2.6.  To find the percentage increase in volume,  \n3.6.  To express this as a percentage increase, we  |  we can calculate:  Percentage increase = ((V' - V)\ncan calculate:  Percentage increase = ((3.6 - 1) /  |  / V)  100 = ((2.6V - V) / V)  100 = (1.6V / V) \n1) * 100% = (2.6 / 1) * 100% = 260%  Therefore,     |  100 = 160%  Therefore, the volume of the cone is  \nthe volume of the cone is increased by              |  increased by 160%.<|eot_id|>                      \n260%.<|eot_id|>                                     |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:38:13.284943Z",
          "iopub.execute_input": "2024-11-16T10:38:13.285299Z",
          "iopub.status.idle": "2024-11-16T10:39:46.696739Z",
          "shell.execute_reply.started": "2024-11-16T10:38:13.285264Z",
          "shell.execute_reply": "2024-11-16T10:39:46.695634Z"
        },
        "outputId": "7a80495b-ccc9-4bf7-c31b-6e672410405c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n<|begin_of_text|><|start_header_id|>system<|end_he  |  <|begin_of_text|><|start_header_id|>system<|end_he\nader_id|>  Cutting Knowledge Date: December 2023    |  ader_id|>  Cutting Knowledge Date: December 2023  \nToday Date: 16 Nov 2024  <|eot_id|><|start_header_  |  Today Date: 16 Nov 2024  <|eot_id|><|start_header_\nid|>human<|end_header_id|>  What were the social    |  id|>human<|end_header_id|>  What were the social  \nand economic impacts of the Industrial Revolution   |  and economic impacts of the Industrial Revolution \nin 19th century England?<|eot_id|><|start_header_i  |  in 19th century England?<|eot_id|><|start_header_i\nd|>assistant<|end_header_id|>  The Industrial       |  d|>assistant<|end_header_id|>  The Industrial     \nRevolution in 19th century England had significant  |  Revolution in 19th century England had significant\nsocial and economic impacts, both positive and      |  social and economic impacts, both positive and    \nnegative. Some of the key effects include:  Social  |  negative. Some of the key effects include:  Social\nImpacts:  1. **Urbanization**: The Industrial       |  Impacts:  1. **Urbanization**: The Industrial     \nRevolution led to rapid urbanization, as people     |  Revolution led to rapid urbanization, as people   \nmoved from rural areas to cities in search of       |  moved from rural areas to cities in search of     \nwork. This resulted in the growth of cities like    |  work. This resulted in the growth of cities like  \nManchester, Birmingham, and Liverpool, which        |  Manchester, Birmingham, and Liverpool, which      \nbecame major industrial centers. 2. **Changes in    |  became major industrial centers. 2. **Changes in  \nfamily structure**: With the rise of                |  family structure**: With the rise of              \nindustrialization, traditional family structures    |  industrialization, traditional family structures  \nbegan to break down. Children as young as 6 or 7    |  began to break down. Children as young as 6 or 7  \nyears old worked in factories, and women took on    |  years old worked in factories, and women took on  \nnew roles in the workforce. 3. **Growth of a new    |  new roles in the workforce. 3. **Growth of a new  \nmiddle class**: The Industrial Revolution created   |  middle class**: The Industrial Revolution created \na new middle class of industrialists, managers,     |  a new middle class of industrialists, managers,   \nand professionals who accumulated wealth and        |  and professionals who accumulated wealth and      \ninfluence. 4. **Increased social inequality**: The  |  influence. 4. **Increased social inequality**: The\nIndustrial Revolution also created new social       |  Industrial Revolution also created new social     \ninequalities, as the wealthy industrialists and     |  inequalities, as the wealthy industrialists and   \nmanagers accumulated vast fortunes, while the       |  managers accumulated vast fortunes, while the     \nworking class struggled to make ends meet.          |  working class struggled to make ends meet.        \nEconomic Impacts:  1. **Growth of industry and      |  Economic Impacts:  1. **Growth of industry and    \ntrade**: The Industrial Revolution led to a         |  trade**: The Industrial Revolution led to a       \nsignificant increase in industrial production and   |  significant increase in industrial production and \ntrade, which helped to stimulate economic growth.   |  trade, which helped to stimulate economic growth. \n2. **Creation of new industries**: New industries   |  2. **Creation of new industries**: New industries \nemerged, such as textiles, coal mining, and iron    |  emerged, such as textiles, coal mining, and iron  \nproduction, which created new job opportunities     |  production, which created new job opportunities   \nand helped to drive economic growth. 3.             |  and helped to drive economic growth. 3.           \n**Increased productivity**: The Industrial          |  **Increased productivity**: The Industrial        \nRevolution introduced new technologies and          |  Revolution introduced new technologies and        \nmanufacturing techniques, which increased           |  manufacturing techniques, which increased         \nproductivity and helped to reduce costs. 4.         |  productivity and helped to reduce costs. 4.       \n**Growth of international trade**: The Industrial   |  **Growth of international trade**: The Industrial \nRevolution helped to stimulate international        |  Revolution helped to stimulate international      \ntrade, as British manufacturers exported goods to   |  trade, as British manufacturers exported goods to \nother countries and imported raw materials and      |  other countries and imported raw materials and    \nmachinery.  Negative Social and Economic Impacts:   |  goods from abroad.  Negative Social and Economic  \n1. **Exploitation of workers**: The Industrial      |  Impacts:  1. **Exploitation of workers**: The     \nRevolution led to the exploitation of workers, who  |  Industrial Revolution led to the exploitation of  \nwere often paid low wages and worked long hours in  |  workers, who were often paid low wages and worked \npoor conditions. 2. **Poor living conditions**:     |  long hours in poor conditions. 2. **Poor living   \nThe rapid growth of cities led to overcrowding,     |  conditions**: The rapid growth of cities led to   \npoverty, and poor living conditions, which          |  overcrowding, poverty, and poor living conditions,\ncontributed to the growth of slums and urban        |  which contributed to the growth of slums and urban\npoverty. 3. **Environmental degradation**: The      |  poverty. 3. **Health problems**: The Industrial   \nIndustrial Revolution led to significant            |  Revolution also led to the growth of health       \nenvironmental degradation, as factories and         |  problems, such as tuberculosis and respiratory    \nindustrial processes released pollutants into the   |  diseases, which were exacerbated by poor working  \nair and water. 4. **Increased poverty and           |  conditions and living conditions. 4.              \ninequality**: The Industrial Revolution also led    |  **Environmental degradation**: The Industrial     \nto increased poverty and inequality, as the         |  Revolution led to significant environmental       \nwealthy industrialists and managers accumulated     |  degradation, as the growth of industry and trade  \nvast fortunes, while the working class struggled    |  led to pollution, deforestation, and habitat      \nto make ends meet.  Overall, the Industrial         |  destruction.  Overall, the Industrial Revolution  \nRevolution had a profound impact on English         |  had a profound impact on English society and      \nsociety and economy, creating new opportunities     |  economy, creating new opportunities for growth and\nfor growth and development, but also leading to     |  development, but also exacerbating social and     \nsignificant social and economic                     |  economic inequalities.<|eot_id|>                  \nproblems.<|eot_id|>                                 |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\n",
        "pre_text = pre_assistant(prompt)\n",
        "post_text = post_assistant(prompt)\n",
        "print_side_by_side(pre_text, post_text)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-16T10:46:08.846918Z",
          "iopub.execute_input": "2024-11-16T10:46:08.847274Z",
          "iopub.status.idle": "2024-11-16T10:48:37.598177Z",
          "shell.execute_reply.started": "2024-11-16T10:46:08.847238Z",
          "shell.execute_reply": "2024-11-16T10:48:37.597137Z"
        },
        "outputId": "5893eae5-486e-41f0-aa02-6a2a248d5a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n<|begin_of_text|><|start_header_id|>system<|end_he  |  <|begin_of_text|><|start_header_id|>system<|end_he\nader_id|>  Cutting Knowledge Date: December 2023    |  ader_id|>  Cutting Knowledge Date: December 2023  \nToday Date: 16 Nov 2024  <|eot_id|><|start_header_  |  Today Date: 16 Nov 2024  <|eot_id|><|start_header_\nid|>human<|end_header_id|>  How do viral            |  id|>human<|end_header_id|>  How do viral          \ninfections affect vulnerable populations such as    |  infections affect vulnerable populations such as  \ninfants, elderly and immunocompromised              |  infants, elderly and immunocompromised            \nindividuals, and what are the most effective        |  individuals, and what are the most effective      \nstrategies for preventing and treating these infec  |  strategies for preventing and treating these infec\ntions?<|eot_id|><|start_header_id|>assistant<|end_  |  tions?<|eot_id|><|start_header_id|>assistant<|end_\nheader_id|>  Viral infections can have a            |  header_id|>  Viral infections can have a          \ndisproportionate impact on vulnerable populations,  |  disproportionate impact on vulnerable populations,\nincluding infants, elderly individuals, and those   |  including infants, elderly individuals, and those \nwith compromised immune systems. These populations  |  with compromised immune systems. These populations\nare more susceptible to severe illness,             |  are more susceptible to severe illness,           \ncomplications, and even death due to various        |  complications, and even death due to various      \nfactors, such as:  1. Weakened immune systems:      |  factors, such as:  1. Weakened immune systems:    \nInfants, elderly individuals, and                   |  Infants, elderly individuals, and                 \nimmunocompromised individuals have impaired immune  |  immunocompromised individuals have impaired immune\nsystems, making it harder for their bodies to       |  systems, making it harder for their bodies to     \nfight off viral infections. 2. Age-related          |  fight off viral infections. 2. Age-related        \ndecline: As people age, their immune systems        |  decline: As people age, their immune systems      \nnaturally decline, making them more vulnerable to   |  naturally decline, making them more vulnerable to \ninfections. 3. Co-morbidities: Many vulnerable      |  infections. 3. Co-morbidities: Many vulnerable    \nindividuals have underlying health conditions,      |  individuals have underlying health conditions,    \nsuch as chronic respiratory disease or              |  such as chronic respiratory disease or            \ncardiovascular disease, which can exacerbate the    |  cardiovascular disease, which can exacerbate the  \neffects of viral infections. 4. Reduced             |  effects of viral infections. 4. Reduced           \nvaccination coverage: Some vulnerable populations   |  vaccination coverage: Some vulnerable populations \nmay not receive recommended vaccinations, leaving   |  may not receive recommended vaccinations, leaving \nthem more susceptible to vaccine-preventable        |  them more susceptible to vaccine-preventable      \ndiseases.  **Infants (0-12 months):**  1.           |  diseases.  **Infants (0-12 months):**  1.         \nRespiratory syncytial virus (RSV): A common cause   |  Respiratory syncytial virus (RSV): A common cause \nof respiratory illness in infants, particularly     |  of respiratory illness in infants, particularly   \nthose under 6 months. 2. Influenza: Infants are at  |  those under 6 months. 2. Influenza: Infants are at\nhigh risk for severe illness and hospitalization    |  high risk for severe illness and hospitalization  \ndue to influenza. 3. Human metapneumovirus (HMPV):  |  due to influenza. 3. Human metapneumovirus (HMPV):\nA common cause of respiratory illness in infants,   |  A common cause of respiratory illness in infants, \noften leading to hospitalization.  **Elderly (65+   |  often leading to hospitalization.  **Elderly (65+ \nyears):**  1. Influenza: Elderly individuals are    |  years):**  1. Influenza: Elderly individuals are  \nat high risk for severe illness and                 |  at high risk for severe illness and               \nhospitalization due to influenza. 2. Pneumonia:     |  hospitalization due to influenza. 2. Pneumonia:   \nElderly individuals are more susceptible to         |  Elderly individuals are more susceptible to       \npneumonia, particularly those with chronic          |  pneumonia, particularly those with chronic        \nrespiratory disease. 3. Herpes zoster (shingles):   |  respiratory disease. 3. Herpes zoster (shingles): \nElderly individuals are more likely to develop      |  Elderly individuals are more likely to develop    \nshingles, which can lead to serious complications.  |  shingles, which can lead to serious complications.\n**Immunocompromised individuals:**  1. HIV/AIDS:    |  **Immunocompromised individuals:**  1. HIV/AIDS:  \nIndividuals with HIV/AIDS are more susceptible to   |  Individuals with HIV/AIDS are more susceptible to \nopportunistic infections, such as Pneumocystis      |  opportunistic infections, such as Pneumocystis    \njirovecii pneumonia (PCP) and cryptococcal          |  jirovecii pneumonia (PCP) and cryptococcal        \nmeningitis. 2. Cancer: Chemotherapy and             |  meningitis. 2. Cancer: Chemotherapy and           \nimmunosuppressive therapy can increase the risk of  |  immunosuppressive therapy can increase the risk of\nviral infections, such as cytomegalovirus (CMV)     |  viral infections, such as cytomegalovirus (CMV)   \nand herpes simplex virus (HSV). 3. Organ            |  and herpes simplex virus (HSV). 3. Organ          \ntransplantation: Recipients of organ transplants    |  transplantation: Recipients of organ transplants  \nare at risk for viral infections, such as CMV and   |  are at risk for viral infections, such as CMV and \nHSV.  **Effective strategies for preventing and     |  HSV.  **Effective strategies for preventing and   \ntreating viral infections:**  1. Vaccination:       |  treating viral infections:**  1. Vaccination:     \nEnsure that all individuals, particularly           |  Ensure that all individuals, particularly         \nvulnerable populations, receive recommended         |  vulnerable populations, receive recommended       \nvaccinations. 2. Influenza vaccination: Administer  |  vaccinations. 2. Influenza vaccination: Administer\nannual influenza vaccination to all individuals,    |  annual influenza vaccination to all individuals,  \nespecially those at high risk. 3. Antiviral         |  especially those at high risk. 3. Antiviral       \nmedications: Use antiviral medications, such as     |  medications: Use antiviral medications, such as   \noseltamivir (Tamiflu) and zanamivir (Relenza), to   |  oseltamivir (Tamiflu) and zanamivir (Relenza), to \ntreat influenza and other viral infections. 4.      |  treat influenza and other viral infections. 4.    \nAntibiotics: Use antibiotics to treat bacterial     |  Antibiotics: Use antibiotics to treat bacterial   \nco-infections, such as pneumonia, which can occur   |  co-infections, such as pneumonia, which can occur \nwith viral infections. 5. Isolation and             |  with viral infections. 5. Isolation and           \nquarantine: Implement isolation and quarantine      |  quarantine: Implement isolation and quarantine    \nmeasures to prevent the spread of viral             |  measures to prevent the spread of viral           \ninfections. 6. Personal protective equipment        |  infections. 6. Personal protective equipment      \n(PPE): Use PPE, such as masks and gloves, to        |  (PPE): Use PPE, such as masks and gloves, to      \nprevent transmission of viral infections. 7.        |  prevent transmission of viral infections. 7.      \nContact tracing: Identify and contact individuals   |  Contact tracing: Identify and contact individuals \nwho have been in close contact with someone with a  |  who have been in close contact with someone with a\nviral infection to prevent transmission. 8.         |  viral infection to prevent transmission. 8.       \nHealthcare provider guidance: Follow guidance from  |  Healthcare provider guidance: Follow guidance from\nhealthcare providers on testing, treatment, and     |  healthcare providers on testing, treatment, and   \nmanagement of viral infections.  **Additional       |  management of viral infections.  **Additional     \nmeasures for vulnerable populations:**  1.          |  strategies for vulnerable populations:**  1. Home \nInfants:         * Implement strict infection       |  visits: Conduct home visits to provide education, \ncontrol measures in healthcare settings.         *  |  vaccinations, and antiviral medications to        \nProvide RSV prophylaxis to high-risk infants.       |  vulnerable populations. 2. Community-based        \n* Administer influenza vaccination to all infants.  |  programs: Implement community-based programs to   \n2. Elderly:         * Implement strict infection    |  provide education, vaccinations, and antiviral    \ncontrol measures in healthcare settings.         *  |  medications to vulnerable populations. 3.         \nProvide influenza vaccination to all elderly        |  Telemedicine: Utilize telemedicine to provide     \nindividuals.         * Monitor for shingles and     |  remote consultations and monitoring for vulnerable\nprovide prompt treatment. 3. Immunocompromised      |  populations. 4. Social support: Provide social    \nindividuals:         * Implement strict infection   |  support and resources to vulnerable populations to\ncontrol measures in healthcare settings.         *  |  help them manage their care and reduce the risk of\nProvide prophylactic antiviral medications for      |  viral infections.  By implementing these          \nhigh-risk individuals.         * Monitor for        |  strategies, we can reduce the risk of viral       \nopportunistic infections and provide prompt         |  infections and improve outcomes for vulnerable    \ntreatment.  By implementing these strategies, we    |  populations.<|eot_id|>                            \ncan reduce the risk of severe illness and           |                                                    \ncomplications associated with viral infections in   |                                                    \nvulnerable populations.<|eot_id|>                   |                                                    \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}