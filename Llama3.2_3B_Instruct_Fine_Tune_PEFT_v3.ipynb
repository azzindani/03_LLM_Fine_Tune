{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"!pip install -q --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-15T03:26:48.063923Z","iopub.execute_input":"2024-12-15T03:26:48.064285Z","iopub.status.idle":"2024-12-15T03:27:44.352690Z","shell.execute_reply.started":"2024-12-15T03:26:48.064242Z","shell.execute_reply":"2024-12-15T03:27:44.351654Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.12.2 requires transformers<4.47.0, but you have transformers 4.47.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-12-15T03:27:44.355011Z","iopub.execute_input":"2024-12-15T03:27:44.355777Z","iopub.status.idle":"2024-12-15T03:27:51.829178Z","shell.execute_reply.started":"2024-12-15T03:27:44.355733Z","shell.execute_reply":"2024-12-15T03:27:51.828333Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-12-15T03:27:51.830502Z","iopub.execute_input":"2024-12-15T03:27:51.830895Z","iopub.status.idle":"2024-12-15T03:27:51.837411Z","shell.execute_reply.started":"2024-12-15T03:27:51.830854Z","shell.execute_reply":"2024-12-15T03:27:51.836577Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"model_name = 'unsloth/Llama-3.2-3B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-15T03:27:51.839881Z","iopub.execute_input":"2024-12-15T03:27:51.840152Z","iopub.status.idle":"2024-12-15T03:27:51.851723Z","shell.execute_reply.started":"2024-12-15T03:27:51.840126Z","shell.execute_reply":"2024-12-15T03:27:51.851026Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-12-15T03:27:51.852675Z","iopub.execute_input":"2024-12-15T03:27:51.852938Z","iopub.status.idle":"2024-12-15T03:27:51.863772Z","shell.execute_reply.started":"2024-12-15T03:27:51.852913Z","shell.execute_reply":"2024-12-15T03:27:51.862946Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:27:51.864858Z","iopub.execute_input":"2024-12-15T03:27:51.865533Z","iopub.status.idle":"2024-12-15T03:30:32.862770Z","shell.execute_reply.started":"2024-12-15T03:27:51.865493Z","shell.execute_reply":"2024-12-15T03:30:32.861147Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/928 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a301d5f77b124c0eb5f0193a35031c25"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d69a0daf9467462daba64369c0011bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be40341084964e67b7850b4ae11d98c9"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:32.864699Z","iopub.execute_input":"2024-12-15T03:30:32.866370Z","iopub.status.idle":"2024-12-15T03:30:32.884365Z","shell.execute_reply.started":"2024-12-15T03:30:32.866331Z","shell.execute_reply":"2024-12-15T03:30:32.883563Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:32.885362Z","iopub.execute_input":"2024-12-15T03:30:32.887203Z","iopub.status.idle":"2024-12-15T03:30:36.391559Z","shell.execute_reply.started":"2024-12-15T03:30:32.887162Z","shell.execute_reply":"2024-12-15T03:30:36.390856Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83222a8650274b3a90801ac7f20747a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c94971dc9a3a4b928d3852c7cc406f46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"198dee9e94cc469fac3bb1fc058dee1d"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"dataset_name = 'microsoft/orca-math-word-problems-200k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:36.392710Z","iopub.execute_input":"2024-12-15T03:30:36.393081Z","iopub.status.idle":"2024-12-15T03:30:36.397411Z","shell.execute_reply.started":"2024-12-15T03:30:36.393041Z","shell.execute_reply":"2024-12-15T03:30:36.396570Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 384","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:36.399916Z","iopub.execute_input":"2024-12-15T03:30:36.400153Z","iopub.status.idle":"2024-12-15T03:30:36.419846Z","shell.execute_reply.started":"2024-12-15T03:30:36.400129Z","shell.execute_reply":"2024-12-15T03:30:36.418990Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:36.420938Z","iopub.execute_input":"2024-12-15T03:30:36.421644Z","iopub.status.idle":"2024-12-15T03:30:38.534414Z","shell.execute_reply.started":"2024-12-15T03:30:36.421604Z","shell.execute_reply":"2024-12-15T03:30:38.533612Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answer'],\n    num_rows: 200035\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.535617Z","iopub.execute_input":"2024-12-15T03:30:38.536209Z","iopub.status.idle":"2024-12-15T03:30:38.542144Z","shell.execute_reply.started":"2024-12-15T03:30:38.536167Z","shell.execute_reply":"2024-12-15T03:30:38.541452Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.543013Z","iopub.execute_input":"2024-12-15T03:30:38.543230Z","iopub.status.idle":"2024-12-15T03:30:38.567747Z","shell.execute_reply.started":"2024-12-15T03:30:38.543208Z","shell.execute_reply":"2024-12-15T03:30:38.566955Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.568725Z","iopub.execute_input":"2024-12-15T03:30:38.568987Z","iopub.status.idle":"2024-12-15T03:30:38.574442Z","shell.execute_reply.started":"2024-12-15T03:30:38.568962Z","shell.execute_reply":"2024-12-15T03:30:38.573552Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.575648Z","iopub.execute_input":"2024-12-15T03:30:38.576371Z","iopub.status.idle":"2024-12-15T03:30:38.583901Z","shell.execute_reply.started":"2024-12-15T03:30:38.576335Z","shell.execute_reply":"2024-12-15T03:30:38.583037Z"}},"outputs":[{"name":"stdout","text":"['question', 'answer']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.584992Z","iopub.execute_input":"2024-12-15T03:30:38.585489Z","iopub.status.idle":"2024-12-15T03:30:38.594549Z","shell.execute_reply.started":"2024-12-15T03:30:38.585450Z","shell.execute_reply":"2024-12-15T03:30:38.593721Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  input = examples['question']\n  output = examples['answer']\n  \n  text = prompt_format.format(input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.595528Z","iopub.execute_input":"2024-12-15T03:30:38.595834Z","iopub.status.idle":"2024-12-15T03:30:38.603592Z","shell.execute_reply.started":"2024-12-15T03:30:38.595765Z","shell.execute_reply":"2024-12-15T03:30:38.602852Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.604536Z","iopub.execute_input":"2024-12-15T03:30:38.604789Z","iopub.status.idle":"2024-12-15T03:30:38.680194Z","shell.execute_reply.started":"2024-12-15T03:30:38.604765Z","shell.execute_reply":"2024-12-15T03:30:38.679477Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.681030Z","iopub.execute_input":"2024-12-15T03:30:38.681262Z","iopub.status.idle":"2024-12-15T03:30:38.685342Z","shell.execute_reply.started":"2024-12-15T03:30:38.681239Z","shell.execute_reply":"2024-12-15T03:30:38.684509Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|eot_id|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.686297Z","iopub.execute_input":"2024-12-15T03:30:38.686580Z","iopub.status.idle":"2024-12-15T03:30:38.695339Z","shell.execute_reply.started":"2024-12-15T03:30:38.686555Z","shell.execute_reply":"2024-12-15T03:30:38.694633Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:38.696338Z","iopub.execute_input":"2024-12-15T03:30:38.696607Z","iopub.status.idle":"2024-12-15T03:30:47.167848Z","shell.execute_reply.started":"2024-12-15T03:30:38.696582Z","shell.execute_reply":"2024-12-15T03:30:47.166930Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d2a927539934de5814e10ed85b928ba"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.168927Z","iopub.execute_input":"2024-12-15T03:30:47.169177Z","iopub.status.idle":"2024-12-15T03:30:47.174614Z","shell.execute_reply.started":"2024-12-15T03:30:47.169153Z","shell.execute_reply":"2024-12-15T03:30:47.173621Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|eot_id|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.175927Z","iopub.execute_input":"2024-12-15T03:30:47.176296Z","iopub.status.idle":"2024-12-15T03:30:47.233332Z","shell.execute_reply.started":"2024-12-15T03:30:47.176251Z","shell.execute_reply":"2024-12-15T03:30:47.232519Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.234307Z","iopub.execute_input":"2024-12-15T03:30:47.234536Z","iopub.status.idle":"2024-12-15T03:30:47.244143Z","shell.execute_reply.started":"2024-12-15T03:30:47.234513Z","shell.execute_reply":"2024-12-15T03:30:47.243135Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.245193Z","iopub.execute_input":"2024-12-15T03:30:47.245465Z","iopub.status.idle":"2024-12-15T03:30:47.268638Z","shell.execute_reply.started":"2024-12-15T03:30:47.245438Z","shell.execute_reply":"2024-12-15T03:30:47.267950Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [128000, 14711, 16225, 512, 3947, 374, 264, 14...   \n1  [128000, 14711, 16225, 512, 644, 264, 2466, 38...   \n2  [128004, 128004, 128004, 128004, 128004, 12800...   \n3  [128004, 128004, 128004, 128004, 128004, 12800...   \n4  [128000, 14711, 16225, 512, 3947, 374, 264, 52...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 14...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[128000, 14711, 16225, 512, 644, 264, 2466, 38...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[128004, 128004, 128004, 128004, 128004, 12800...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[128000, 14711, 16225, 512, 3947, 374, 264, 52...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.269487Z","iopub.execute_input":"2024-12-15T03:30:47.269769Z","iopub.status.idle":"2024-12-15T03:30:47.274989Z","shell.execute_reply.started":"2024-12-15T03:30:47.269741Z","shell.execute_reply":"2024-12-15T03:30:47.274209Z"}},"outputs":[{"name":"stdout","text":"### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|eot_id|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.276154Z","iopub.execute_input":"2024-12-15T03:30:47.276497Z","iopub.status.idle":"2024-12-15T03:30:47.287237Z","shell.execute_reply.started":"2024-12-15T03:30:47.276469Z","shell.execute_reply":"2024-12-15T03:30:47.286422Z"}},"outputs":[{"name":"stdout","text":"[128000, 14711, 16225, 512, 3947, 374, 264, 1403, 49442, 5933, 1396, 6832, 22781, 2035, 374, 220, 18, 13, 6914, 362, 323, 426, 387, 279, 75862, 315, 420, 1396, 555, 220, 605, 323, 279, 27410, 315, 13096, 555, 220, 605, 11, 15947, 13, 1442, 426, 56016, 555, 220, 605, 5636, 362, 374, 220, 24, 2753, 1109, 362, 56016, 555, 220, 605, 5636, 426, 11, 1148, 374, 279, 1176, 1396, 5380, 14711, 22559, 512, 10267, 596, 79164, 279, 1403, 49442, 1396, 439, 18240, 58419, 1144, 705, 1405, 18240, 1630, 1144, 8, 374, 279, 16099, 304, 279, 22781, 2035, 323, 18240, 816, 1144, 8, 374, 279, 16099, 304, 279, 6305, 2035, 13, 8876, 279, 22781, 2035, 374, 220, 18, 11, 584, 617, 18240, 1630, 284, 220, 18, 1144, 3677, 11439, 311, 279, 3575, 11, 18240, 362, 1144, 8, 374, 279, 75862, 315, 279, 1396, 555, 220, 605, 11, 323, 18240, 426, 1144, 8, 374, 279, 27410, 315, 279, 13096, 555, 220, 605, 13, 15636, 11, 18240, 362, 284, 1630, 284, 220, 18, 1144, 8, 323, 18240, 426, 284, 816, 1144, 3677, 791, 3575, 5415, 430, 18240, 426, 1144, 15487, 220, 605, 489, 362, 1144, 8, 374, 220, 24, 2753, 1109, 18240, 362, 1144, 15487, 220, 605, 489, 426, 1144, 570, 1115, 649, 387, 5439, 439, 459, 24524, 1473, 79145, 426, 1144, 15487, 220, 605, 489, 362, 284, 362, 1144, 15487, 220, 605, 489, 426, 482, 220, 24, 1144, 2595, 3214, 3781, 10831, 18240, 362, 1144, 8, 323, 18240, 426, 1144, 8, 449, 18240, 220, 18, 1144, 8, 323, 18240, 816, 1144, 705, 15947, 11, 584, 636, 1473, 79145, 816, 1144, 15487, 220, 605, 489, 220, 18, 284, 220, 18, 1144, 15487, 220, 605, 489, 816, 482, 220, 24, 1144, 2595, 50, 6517, 7922, 279, 24524, 1473, 79145, 220, 605, 56, 489, 220, 18, 284, 220, 966, 489, 816, 482, 220, 24, 1144, 2595, 79145, 220, 605, 56, 489, 220, 18, 284, 816, 489, 220, 1691, 1144, 2595, 3214, 2193, 18240, 816, 1144, 8, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 489, 220, 18, 284, 220, 1691, 1144, 2595, 3214, 2193, 220, 18, 505, 2225, 11314, 1473, 79145, 220, 24, 56, 284, 220, 972, 1144, 2595, 12792, 579, 2225, 11314, 555, 220, 24, 1473, 79145, 816, 284, 220, 17, 1144, 2595, 4516, 279, 6305, 2035, 16099, 374]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.292784Z","iopub.execute_input":"2024-12-15T03:30:47.293080Z","iopub.status.idle":"2024-12-15T03:30:47.299934Z","shell.execute_reply.started":"2024-12-15T03:30:47.293054Z","shell.execute_reply":"2024-12-15T03:30:47.299006Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.301051Z","iopub.execute_input":"2024-12-15T03:30:47.301293Z","iopub.status.idle":"2024-12-15T03:30:47.312822Z","shell.execute_reply.started":"2024-12-15T03:30:47.301269Z","shell.execute_reply":"2024-12-15T03:30:47.312139Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.313789Z","iopub.execute_input":"2024-12-15T03:30:47.314142Z","iopub.status.idle":"2024-12-15T03:30:47.324645Z","shell.execute_reply.started":"2024-12-15T03:30:47.314115Z","shell.execute_reply":"2024-12-15T03:30:47.323762Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.325614Z","iopub.execute_input":"2024-12-15T03:30:47.325907Z","iopub.status.idle":"2024-12-15T03:30:47.336788Z","shell.execute_reply.started":"2024-12-15T03:30:47.325881Z","shell.execute_reply":"2024-12-15T03:30:47.335997Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n\n#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.337901Z","iopub.execute_input":"2024-12-15T03:30:47.338511Z","iopub.status.idle":"2024-12-15T03:30:47.346188Z","shell.execute_reply.started":"2024-12-15T03:30:47.338470Z","shell.execute_reply":"2024-12-15T03:30:47.345474Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:47.347082Z","iopub.execute_input":"2024-12-15T03:30:47.347330Z","iopub.status.idle":"2024-12-15T03:30:48.595666Z","shell.execute_reply.started":"2024-12-15T03:30:47.347305Z","shell.execute_reply":"2024-12-15T03:30:48.594742Z"}},"outputs":[{"name":"stdout","text":"trainable params: 97,255,424 || all params: 3,310,005,248 || trainable%: 2.9382\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:48.596919Z","iopub.execute_input":"2024-12-15T03:30:48.597306Z","iopub.status.idle":"2024-12-15T03:30:48.612099Z","shell.execute_reply.started":"2024-12-15T03:30:48.597264Z","shell.execute_reply":"2024-12-15T03:30:48.611135Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1900719104\nTrainable parameters : 97255424\nTrainable percentage: 5.12%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:48.613162Z","iopub.execute_input":"2024-12-15T03:30:48.613567Z","iopub.status.idle":"2024-12-15T03:30:48.622644Z","shell.execute_reply.started":"2024-12-15T03:30:48.613494Z","shell.execute_reply":"2024-12-15T03:30:48.621936Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:48.623639Z","iopub.execute_input":"2024-12-15T03:30:48.623924Z","iopub.status.idle":"2024-12-15T03:30:48.676345Z","shell.execute_reply.started":"2024-12-15T03:30:48.623894Z","shell.execute_reply":"2024-12-15T03:30:48.675143Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec15_03-30-48_38248fae1b86,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:48.677425Z","iopub.execute_input":"2024-12-15T03:30:48.677781Z","iopub.status.idle":"2024-12-15T03:30:50.511763Z","shell.execute_reply.started":"2024-12-15T03:30:48.677744Z","shell.execute_reply":"2024-12-15T03:30:50.511097Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7fb38c6d3e80>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T03:30:50.513029Z","iopub.execute_input":"2024-12-15T03:30:50.513395Z","iopub.status.idle":"2024-12-15T04:13:56.712843Z","shell.execute_reply.started":"2024-12-15T03:30:50.513355Z","shell.execute_reply":"2024-12-15T04:13:56.712019Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 97,255,424\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241215_033052-uccx8a6e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/uccx8a6e' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/uccx8a6e' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/uccx8a6e</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 42:54, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.975300</td>\n      <td>0.944131</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.916500</td>\n      <td>0.820465</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.793600</td>\n      <td>0.750923</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.769500</td>\n      <td>0.725149</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.731700</td>\n      <td>0.713067</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.698800</td>\n      <td>0.706175</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.690900</td>\n      <td>0.702059</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.716700</td>\n      <td>0.699980</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.697700</td>\n      <td>0.699060</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.705200</td>\n      <td>0.698960</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.7695897912979126, metrics={'train_runtime': 2585.7844, 'train_samples_per_second': 0.619, 'train_steps_per_second': 0.077, 'total_flos': 1.1108075175936e+16, 'train_loss': 0.7695897912979126, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:13:56.714092Z","iopub.execute_input":"2024-12-15T04:13:56.714753Z","iopub.status.idle":"2024-12-15T04:15:28.620461Z","shell.execute_reply.started":"2024-12-15T04:13:56.714709Z","shell.execute_reply":"2024-12-15T04:15:28.619556Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 01:30]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.6989598870277405, 'eval_runtime': 91.8936, 'eval_samples_per_second': 2.176, 'eval_steps_per_second': 0.544, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:15:28.621566Z","iopub.execute_input":"2024-12-15T04:15:28.621877Z","iopub.status.idle":"2024-12-15T04:15:31.191198Z","shell.execute_reply.started":"2024-12-15T04:15:28.621849Z","shell.execute_reply":"2024-12-15T04:15:31.190217Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/37107b20e598aa024ef99a16e83b39aca1eef916/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/37107b20e598aa024ef99a16e83b39aca1eef916/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:15:31.192866Z","iopub.execute_input":"2024-12-15T04:15:31.193303Z","iopub.status.idle":"2024-12-15T04:15:31.485896Z","shell.execute_reply.started":"2024-12-15T04:15:31.193250Z","shell.execute_reply":"2024-12-15T04:15:31.484823Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:15:31.487072Z","iopub.execute_input":"2024-12-15T04:15:31.487380Z","iopub.status.idle":"2024-12-15T04:15:31.497697Z","shell.execute_reply.started":"2024-12-15T04:15:31.487351Z","shell.execute_reply":"2024-12-15T04:15:31.496906Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:15:31.498885Z","iopub.execute_input":"2024-12-15T04:15:31.499197Z","iopub.status.idle":"2024-12-15T04:15:33.064609Z","shell.execute_reply.started":"2024-12-15T04:15:31.499157Z","shell.execute_reply":"2024-12-15T04:15:33.063638Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:15:33.065697Z","iopub.execute_input":"2024-12-15T04:15:33.065976Z","iopub.status.idle":"2024-12-15T04:16:04.786086Z","shell.execute_reply.started":"2024-12-15T04:15:33.065948Z","shell.execute_reply":"2024-12-15T04:16:04.785284Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/37107b20e598aa024ef99a16e83b39aca1eef916/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"unsloth/Llama-3.2-3B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"head_dim\": 128,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 24,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 32.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/37107b20e598aa024ef99a16e83b39aca1eef916/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ]\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/Llama-3.2-3B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--Llama-3.2-3B-Instruct/snapshots/37107b20e598aa024ef99a16e83b39aca1eef916/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 128000,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 3072)\n    (layers): ModuleList(\n      (0-27): 28 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.787285Z","iopub.execute_input":"2024-12-15T04:16:04.788062Z","iopub.status.idle":"2024-12-15T04:16:04.798977Z","shell.execute_reply.started":"2024-12-15T04:16:04.788017Z","shell.execute_reply":"2024-12-15T04:16:04.798184Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1803463680\nTrainable parameters : 394177536\nTrainable percentage: 21.86%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.799862Z","iopub.execute_input":"2024-12-15T04:16:04.800117Z","iopub.status.idle":"2024-12-15T04:16:04.821868Z","shell.execute_reply.started":"2024-12-15T04:16:04.800084Z","shell.execute_reply":"2024-12-15T04:16:04.821070Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 3072)\n        (layers): ModuleList(\n          (0-27): 28 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1024, bias=False)\n                  (default): Linear(in_features=64, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8192, bias=False)\n                  (default): Linear(in_features=64, out_features=8192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.822875Z","iopub.execute_input":"2024-12-15T04:16:04.823129Z","iopub.status.idle":"2024-12-15T04:16:04.846932Z","shell.execute_reply.started":"2024-12-15T04:16:04.823105Z","shell.execute_reply":"2024-12-15T04:16:04.846116Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1997974528\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.848005Z","iopub.execute_input":"2024-12-15T04:16:04.848814Z","iopub.status.idle":"2024-12-15T04:16:04.856648Z","shell.execute_reply.started":"2024-12-15T04:16:04.848754Z","shell.execute_reply":"2024-12-15T04:16:04.855968Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.857570Z","iopub.execute_input":"2024-12-15T04:16:04.857911Z","iopub.status.idle":"2024-12-15T04:16:04.866533Z","shell.execute_reply.started":"2024-12-15T04:16:04.857872Z","shell.execute_reply":"2024-12-15T04:16:04.865858Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:16:04.867296Z","iopub.execute_input":"2024-12-15T04:16:04.867524Z","iopub.status.idle":"2024-12-15T04:16:04.877468Z","shell.execute_reply.started":"2024-12-15T04:16:04.867500Z","shell.execute_reply":"2024-12-15T04:16:04.876670Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:42:10.337908Z","iopub.execute_input":"2024-12-15T04:42:10.338278Z","iopub.status.idle":"2024-12-15T04:43:03.368372Z","shell.execute_reply.started":"2024-12-15T04:42:10.338250Z","shell.execute_reply":"2024-12-15T04:43:03.367512Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n### Question: A cleaning company produces two       |  ### Question: A cleaning company produces two     \nsanitizer sprays. One spray kills 50% of germs,     |  sanitizer sprays. One spray kills 50% of germs,   \nand another spray kills 25% of germs. However, a    |  and another spray kills 25% of germs. However, a  \ncertain percentage of the germs they kill are the   |  certain percentage of the germs they kill are the \nsame ones. After using both sanitizer sprays        |  same ones. After using both sanitizer sprays      \ntogether, 30% of germs would be left. What          |  together, 30% of germs would be left. What        \npercentage of germs do both sprays kill in common?  |  percentage of germs do both sprays kill in common?\n### Answer: ## Step 1:  To solve this problem, we   |  ### Answer: ## Step 1:  To solve this problem, we \nfirst need to understand the relationship between   |  need to understand that the percentage of germs   \nthe percentage of germs killed by each spray and    |  killed by both sprays together is the sum of the  \nthe overall percentage of germs left after using    |  percentages of germs killed by each spray minus   \nboth sprays together. ## Step 2:  Let's denote the  |  the percentage of germs killed in common. ## Step \npercentage of germs killed by the first spray as    |  2:  Let's denote the percentage of germs killed in\n$x$ and the percentage of germs killed by the       |  common as x. This means that the first spray kills\nsecond spray as $y$. We are given that the first    |  50% - x germs, and the second spray kills 25% - x \nspray kills 50% of germs, so $x = 50$. The second   |  germs. ## Step 3:  We know that after using both  \nspray kills 25% of germs, so $y = 25$. ## Step 3:   |  sprays together, 30% of germs would be left. This \nWe are also told that a certain percentage of the   |  means that the total percentage of germs killed by\ngerms they kill are the same ones. This means that  |  both sprays is 100% - 30% = 70%. ## Step 4:  We   \nthe overlap between the two sprays is the same      |  can set up an equation to represent the situation:\npercentage of germs killed by each spray. ## Step   |  (50% - x) + (25% - x) = 70%. ## Step 5:           \n4:  After using both sprays together, 30% of germs  |  Simplifying the equation, we get 75% - 2x = 70%.  \nwould be left. This can be represented as $100\\% -  |  ## Step 6:  Subtracting 75% from both sides of the\n(x + y - 2 \\cdot \\text{overlap}) = 30\\%$, where     |  equation, we get -2x = -5%. ## Step 7:  Dividing  \n$\\text{overlap}$ is the percentage of germs killed  |  both sides of the equation by -2, we get x = 2.5%.\nin common by both sprays. ## Step 5:  Substituting  |  ## Step 8:  Therefore, the percentage of germs    \nthe given values for $x$ and $y$, we get $100\\% -   |  that both sprays kill in common is 2.5%.  The     \n(50\\% + 25\\% - 2 \\cdot \\text{overlap}) = 30\\%$. ##  |  final answer is: $\\boxed{2.5}$                    \nStep 6:  Simplifying this equation, we have $100\\%  |                                                    \n- 75\\% + 2 \\cdot \\text{overlap} = 30\\%$, which      |                                                    \nfurther simplifies to $25\\% + 2 \\cdot               |                                                    \n\\text{overlap} = 30\\%$. ## Step 7:  Solving for     |                                                    \n$\\text{overlap}$, we get $2 \\cdot \\text{overlap} =  |                                                    \n30\\% - 25\\% = 5\\%$, and therefore $\\text{overlap}   |                                                    \n= \\frac{5\\%}{2} = 2.5\\%$. ## Step 8:  This means    |                                                    \nthat both sprays kill 2.5% of the germs in common.  |                                                    \nThe final answer is: $\\boxed{2.5}$                  |                                                    \n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T05:04:55.853982Z","iopub.execute_input":"2024-12-15T05:04:55.854344Z","iopub.status.idle":"2024-12-15T05:06:01.569816Z","shell.execute_reply.started":"2024-12-15T05:04:55.854312Z","shell.execute_reply":"2024-12-15T05:06:01.568918Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n### Question: Joy fosters dogs. The mom foster dog  |  ### Question: Joy fosters dogs. The mom foster dog\neats 1.5 cups of food, three times a day. The       |  eats 1.5 cups of food, three times a day. The     \npuppies each eat 1/2 cup of food, twice a day.      |  puppies each eat 1/2 cup of food, twice a day.    \nThere are a certain number of puppies. Joy will     |  There are a certain number of puppies. Joy will   \nneed 57 cups of food for the next 6 days. How many  |  need 57 cups of food for the next 6 days. How many\npuppies are there? ### Answer: ## Step 1:           |  puppies are there? ### Answer: ## Step 1:         \nCalculate the total amount of food the mom foster   |  Calculate the total amount of food the mom foster \ndog eats in a day. The mom foster dog eats 1.5      |  dog eats in a day. The mom foster dog eats 1.5    \ncups of food, three times a day. So, the total      |  cups of food, three times a day. So, the total    \namount of food the mom foster dog eats in a day is  |  amount of food the mom foster dog eats in a day is\n1.5 * 3 = 4.5 cups.  ## Step 2: Calculate the       |  1.5 * 3 = 4.5 cups.  ## Step 2: Calculate the     \ntotal amount of food the mom foster dog eats in 6   |  total amount of food the mom foster dog eats in 6 \ndays. Since the mom foster dog eats 4.5 cups of     |  days. Since the mom foster dog eats 4.5 cups of   \nfood per day, the total amount of food the mom      |  food per day, the total amount of food the mom    \nfoster dog eats in 6 days is 4.5 * 6 = 27 cups.     |  foster dog eats in 6 days is 4.5 * 6 = 27 cups.   \n## Step 3: Calculate the total amount of food the   |  ## Step 3: Calculate the total amount of food the \npuppies eat in a day. Each puppy eats 1/2 cup of    |  puppies eat in a day. Each puppy eats 1/2 cup of  \nfood, twice a day. So, the total amount of food     |  food, twice a day. So, the total amount of food   \neach puppy eats in a day is 1/2 * 2 = 1 cup.  ##    |  each puppy eats in a day is 1/2 * 2 = 1 cup.  ##  \nStep 4: Calculate the total amount of food the      |  Step 4: Calculate the total amount of food the    \npuppies eat in 6 days. Since there are a certain    |  puppies eat in 6 days. Since there are a certain  \nnumber of puppies, let's call the number of         |  number of puppies, let's call the number of       \npuppies 'x'. The total amount of food the puppies   |  puppies 'x'. The total amount of food the puppies \neat in a day is 1 * x = x cups. The total amount    |  eat in a day is 1 * x = x cups. The total amount  \nof food the puppies eat in 6 days is x * 6 = 6x     |  of food the puppies eat in 6 days is x * 6 = 6x   \ncups.  ## Step 5: Calculate the total amount of     |  cups.  ## Step 5: Calculate the total amount of   \nfood Joy needs for the next 6 days. Joy needs 57    |  food Joy needs for the next 6 days. Joy needs 57  \ncups of food for the next 6 days. The total amount  |  cups of food for the next 6 days. The total amount\nof food Joy needs for the next 6 days is the sum    |  of food Joy needs for the next 6 days is the sum  \nof the food the mom foster dog eats in 6 days and   |  of the food the mom foster dog eats in 6 days and \nthe food the puppies eat in 6 days. So, the         |  the food the puppies eat in 6 days. So, the       \nequation is 27 + 6x = 57.  ## Step 6: Solve the     |  equation is 27 + 6x = 57.  ## Step 6: Solve the   \nequation for x. To solve the equation 27 + 6x =     |  equation for x. To solve the equation 27 + 6x =   \n57, we need to isolate x. Subtracting 27 from both  |  57, we need to isolate x. Subtract 27 from both   \nsides of the equation gives 6x = 30. Dividing both  |  sides of the equation: 6x = 57 - 27. 6x = 30.     \nsides of the equation by 6 gives x = 5.  The final  |  Divide both sides of the equation by 6: x = 30 /  \nanswer is: $\\boxed{5}$                              |  6. x = 5.  The final answer is: $\\boxed{5}$       \n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T05:28:56.325810Z","iopub.execute_input":"2024-12-15T05:28:56.326706Z","iopub.status.idle":"2024-12-15T05:29:56.136151Z","shell.execute_reply.started":"2024-12-15T05:28:56.326668Z","shell.execute_reply":"2024-12-15T05:29:56.135197Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n### Question: Nine weights of the same weight       |  ### Question: Nine weights of the same weight     \nweigh a total of 4.5 kilograms (kg). Two of these   |  weigh a total of 4.5 kilograms (kg). Two of these \nweights and several pencil cases that weigh 850     |  weights and several pencil cases that weigh 850   \ngrams (g) each were placed on one side of a pan     |  grams (g) each were placed on one side of a pan   \nbalance scale, and five dictionaries that weigh     |  balance scale, and five dictionaries that weigh   \n1050 grams (g) each were placed on the other side,  |  1050 grams (g) each were placed on the other side,\nand they were level. How many pencil cases are      |  and they were level. How many pencil cases are    \nthere? ### Answer: ## Step 1: Calculate the total   |  there? ### Answer: ## Step 1: Calculate the total \nweight of the weights First, we need to calculate   |  weight of the weights First, we need to calculate \nthe total weight of the nine weights. Since they    |  the total weight of the nine weights. Since they  \nweigh a total of 4.5 kilograms, we can convert      |  weigh a total of 4.5 kilograms, we can convert    \nthis to grams for consistency. 1 kilogram = 1000    |  this to grams for consistency. 1 kilogram = 1000  \ngrams, so 4.5 kilograms = 4.5 * 1000 = 4500 grams.  |  grams, so 4.5 kilograms = 4.5 * 1000 = 4500 grams.\n## Step 2: Calculate the combined weight of the     |  ## Step 2: Calculate the total weight of the      \ntwo weights Since the weights are of the same       |  weights on one side Since two of the weights were \nweight, we can find the combined weight of two of   |  placed on one side of the balance scale, we need  \nthese weights by dividing the total weight of the   |  to calculate their combined weight. Each weight is\nnine weights by 9. So, the combined weight of two   |  4500 grams / 9 = 500 grams. So, two weights weigh \nweights is 4500 / 9 = 500 grams.  ## Step 3:        |  2 * 500 = 1000 grams.  ## Step 3: Calculate the   \nCalculate the combined weight of the dictionaries   |  total weight of the weights on the other side The \nWe are given that five dictionaries weigh 1050      |  total weight of the weights on the other side of  \ngrams each. So, the combined weight of the          |  the balance scale is the weight of the two weights\ndictionaries is 5 * 1050 = 5250 grams.  ## Step 4:  |  plus the weight of the pencil cases. Let's denote \nCalculate the total weight on the other side of     |  the number of pencil cases as x. The total weight \nthe scale We know that the two weights and the      |  of the pencil cases is 850x grams.  ## Step 4:    \npencil cases were level, so the total weight on     |  Calculate the total weight of the dictionaries The\nthe other side of the scale is equal to the         |  total weight of the five dictionaries is 5 * 1050 \ncombined weight of the two weights plus the weight  |  = 5250 grams.  ## Step 5: Set up the equation     \nof the pencil cases. Let's denote the number of     |  Since the two sides of the balance scale are      \npencil cases as 'x'. The total weight on the other  |  level, the total weight on one side is equal to   \nside is then 500 + 850x.  ## Step 5: Calculate the  |  the total weight on the other side. We can set up \ntotal weight on the first side of the scale We are  |  the equation: 1000 + 850x = 5250.  ## Step 6:     \ngiven that the total weight on the first side of    |  Solve the equation Now, we need to solve the      \nthe scale is 4500 grams.  ## Step 6: Set up the     |  equation for x. Subtract 1000 from both sides:    \nequation Since the two sides of the scale are       |  850x = 4250. Divide both sides by 850: x = 4250 / \nlevel, we can set up the equation: 500 + 850x =     |  850 = 5.  The final answer is: $\\boxed{5}$        \n4500.  ## Step 7: Solve the equation Now, we can    |                                                    \nsolve the equation for 'x'. Subtract 500 from both  |                                                    \nsides: 850x = 4000. Then, divide both sides by      |                                                    \n850: x = 4000 / 850 = 4.70588 (round to 4.71).  ##  |                                                    \nStep 8: Round down to the nearest whole number      |                                                    \nSince we can't have a fraction of a pencil case,    |                                                    \nwe round down to the nearest whole number.  The     |                                                    \nfinal answer is: $\\boxed{4}$                        |                                                    \n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T05:48:44.186443Z","iopub.execute_input":"2024-12-15T05:48:44.187386Z","iopub.status.idle":"2024-12-15T05:51:13.243272Z","shell.execute_reply.started":"2024-12-15T05:48:44.187348Z","shell.execute_reply":"2024-12-15T05:51:13.242237Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n### Question: Which of the four numbers among 5,    |  ### Question: Which of the four numbers among 5,  \n8, 3, 2 is the smallest? ### Answer: The smallest   |  8, 3, 2 is the smallest? ### Answer: The smallest \nnumber is 2.  ### Explanation: To determine the     |  number is 2.  ### Explanation: To determine the   \nsmallest number among the given options, we need    |  smallest number among the given options, we need  \nto compare them. The numbers are 5, 8, 3, and 2.    |  to compare them. The numbers are 5, 8, 3, and 2.  \nWe can see that 2 is less than 3, 3 is less than    |  We can see that 2 is less than 3, 3 is less than  \n5, and 5 is greater than 8. Therefore, 2 is the     |  5, and 5 is greater than 8. Therefore, 2 is the   \nsmallest number among the given options.   ###      |  smallest number among the given options.   ###    \nCode: ```python # Define the numbers numbers = [5,  |  Code: ```python # Define the numbers numbers = [5,\n8, 3, 2]  # Find the smallest number                |  8, 3, 2]  # Find the smallest number              \nsmallest_number = min(numbers)  # Print the         |  smallest_number = min(numbers)  # Print the       \nsmallest number print(\"The smallest number is:\",    |  smallest number print(\"The smallest number is:\",  \nsmallest_number) ```  ### Output: ``` The smallest  |  smallest_number) ```  ### Output: ``` The smallest\nnumber is: 2 ```  ### Alternative Solution: We can  |  number is: 2 ```  ### Alternative Solution: We can\nalso use a for loop to compare the numbers and      |  also use a for loop to compare the numbers and    \nfind the smallest one. ```python # Define the       |  find the smallest one. ```python # Define the     \nnumbers numbers = [5, 8, 3, 2]  # Initialize the    |  numbers numbers = [5, 8, 3, 2]  # Initialize the  \nsmallest number smallest_number = numbers[0]  #     |  smallest number smallest_number = numbers[0]  #   \nIterate over the numbers for num in numbers:     #  |  Iterate over the numbers for num in numbers:     #\nUpdate the smallest number if necessary     if num  |  Update the smallest number if necessary     if num\n< smallest_number:         smallest_number = num    |  < smallest_number:         smallest_number = num  \n# Print the smallest number print(\"The smallest     |  # Print the smallest number print(\"The smallest   \nnumber is:\", smallest_number) ```  Both of these    |  number is:\", smallest_number) ```  Both of these  \nsolutions will output `The smallest number is: 2`.  |  solutions will output `The smallest number is: 2`.\n### Time Complexity: The time complexity of both    |  ### Time Complexity: The time complexity of both  \nsolutions is O(n), where n is the number of         |  solutions is O(n), where n is the number of       \nelements in the list. This is because we are        |  elements in the list. This is because we are      \niterating over the list once to find the smallest   |  iterating over the list once to find the smallest \nnumber.   ### Space Complexity: The space           |  number.   ### Space Complexity: The space         \ncomplexity of both solutions is O(1), because we    |  complexity of both solutions is O(1), because we  \nare only using a constant amount of space to store  |  are only using a constant amount of space to store\nthe smallest number and the list of numbers.   ###  |  the smallest number and the list of numbers.   ###\nAdvice: When comparing numbers, it's generally      |  Advice: When comparing numbers, it's generally    \nmore efficient to use the built-in `min` function,  |  more efficient to use the built-in `min` function,\nas it is implemented in C and is highly optimized.  |  as it is implemented in C and is highly optimized.\nHowever, if you need to implement your own          |  However, if you need to implement your own        \nsolution, the for loop approach is a good           |  solution, the for loop approach is a good         \nalternative.   ### Example Use Cases: This code     |  alternative.   ### Example Use Cases: This code   \ncan be used in a variety of situations, such as:    |  can be used in a variety of situations, such as:  \n* Finding the smallest number in a list of exam     |  * Finding the smallest number in a list of exam   \nscores * Determining the smallest price among a     |  scores * Determining the smallest price among a   \nlist of products * Identifying the smallest value   |  list of products * Identifying the smallest value \nin a dataset  Note: This code assumes that the      |  in a dataset  Note: This code assumes that the    \ninput list contains at least one element. If the    |  input list contains at least one element. If the  \nlist is empty, the `min` function will raise a      |  list is empty, the `min` function will raise a    \n`ValueError`. You may want to add error checking    |  `ValueError`. You may want to add error checking  \nto handle this case.   ### Error Handling: To       |  to handle this case.   ### Error Handling: To     \nhandle the case where the input list is empty, you  |  handle the case where the input list is empty, you\ncan add a check before finding the smallest         |  can add a check before finding the smallest       \nnumber: ```python # Define the numbers numbers =    |  number: ```python # Define the numbers numbers =  \n[5, 8, 3, 2]  # Check if the list is empty if not   |  [5, 8, 3, 2]  # Check if the list is empty if not \nnumbers:     print(\"The list is empty.\") else:      |  numbers:     print(\"The list is empty.\") else:    \n# Find the smallest number     smallest_number =    |  # Find the smallest number     smallest_number =  \nmin(numbers)     # Print the smallest number        |  min(numbers)     # Print the smallest number      \nprint(\"The smallest number is:\", smallest_number)   |  print(\"The smallest number is:\", smallest_number) \n```  This code will print \"The list is empty.\" if   |  ```  This code will print \"The list is empty.\" if \nthe input list is empty, instead of raising a       |  the input list is empty, instead of raising a     \n`ValueError`.   ### Best Practices: * Always check  |  `ValueError`.   ### Best Practices: * Always check\nthe input to ensure it is valid * Use the built-in  |  the input to ensure it is valid * Use the built-in\n`min` function when possible * Handle edge cases,   |  `min` function whenever possible * Keep your code \nsuch as an empty list * Use clear and descriptive   |  concise and readable * Use meaningful variable    \nvariable names * Use comments to explain the code   |  names * Add comments to explain your code * Test  \n* Test the code thoroughly to ensure it works as    |  your code thoroughly before using it in production\nexpected  By following these best practices, you    |  * Handle errors and edge cases * Follow standard  \ncan write efficient and effective code that is      |  professional guidelines for coding style and      \neasy to understand and maintain.   ### Conclusion:  |  documentation  Note: This is not an exhaustive    \nIn this question, we were asked to find the         |  list of best practices, but it covers some of the \nsmallest number among four given options. We used   |  most important ones.   ### Commit Message: `Added \nthe built-in `min` function to find the smallest    |  code to find the smallest number in a list`  Note:\nnumber, which is the most efficient approach. We    |  This is a good commit message because it is       \nalso provided an alternative solution using a for   |  concise, descriptive, and follows standard        \nloop, which is a good alternative when the built-   |  professional guidelines.   ### API Documentation: \nin function is not available.   We discussed the    |  `find_smallest_number(numbers)`  * Description:   \ntime and space complexity of both solutions, and    |  Finds the smallest number in a list of numbers. * \nprovided advice on how to compare numbers           |  Parameters:         + `numbers`: A list of        \nefficiently. We also provided example use cases     |  numbers. * Returns: The smallest number in the    \nand error handling to make the code more robust.    |  list. * Raises: `ValueError` if the input list is \nBy following the best practices outlined above,     |  empty.  Note: This is a good API documentation    \nyou can write efficient and effective code that is  |  because it is concise, descriptive, and follows   \neasy to understand and maintain.   ### Final        |  standard professional guidelines.   ### Testing:  \nAnswer: The final answer is 2.   ### Final Answer   |  ```python import unittest  class                  \nExplanation: The final answer is 2 because it is    |  TestFindSmallestNumber(unittest.TestCase):     def\nthe smallest number among the given options.   ###  |  test_empty_list(self):                            \nFinal Answer Code: ```python # Define the numbers   |  self.assertEqual(find_smallest_number([]), None)  \nnumbers = [5, 8, 3, 2]  # Find the smallest number  |  def test_single_element_list(self):               \nsmallest_number = min(numbers)  # Print the         |  self.assertEqual(find_smallest_number([5]), 5)    \nsmallest number print(\"The smallest number is:\",    |  def test_multiple_element_list(self):             \nsmallest_number) ```  This code will output `The    |  self.assertEqual(find_smallest_number([5, 8, 3,   \nsmallest number is: 2`.   ### Final Answer Time     |  2]), 2)  if __name__ == '__main__':               \nComplexity: The time complexity of this code is     |  unittest.main() ```  This test suite covers the   \nO(n), where n is the number of elements in the      |  cases where the input list is empty, contains a   \nlist.   ### Final Answer Space Complexity: The      |  single element, and contains multiple elements. It\nspace complexity of this code is O(1), because we   |  ensures that the `find_smallest_number` function  \nare only using a constant amount of space to store  |  behaves correctly in these cases.   Note: This is \n                                                    |  not an exhaustive list of test cases, but it      \n                                                    |  covers some of                                    \n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T04:17:45.453530Z","iopub.execute_input":"2024-12-15T04:17:45.453817Z","iopub.status.idle":"2024-12-15T04:20:15.682087Z","shell.execute_reply.started":"2024-12-15T04:17:45.453769Z","shell.execute_reply":"2024-12-15T04:20:15.681202Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1803463680                     |                     1997974528                    \n================================================== | ==================================================\n### Question: What is the surface area of a cuboid  |  ### Question: What is the surface area of a cuboid\nthat is 8 centimeters (cm) wide, 5 centimeters      |  that is 8 centimeters (cm) wide, 5 centimeters    \n(cm) long, and 10 centimeters (cm) height? ###      |  (cm) long, and 10 centimeters (cm) height? ###    \nAnswer: To find the surface area of a cuboid, we    |  Answer: To find the surface area of a cuboid, we  \nneed to find the area of each face and add them     |  need to find the area of each face and add them   \ntogether. The formula for the surface area of a     |  together. The formula for the surface area of a   \ncuboid is 2lw + 2lh + 2wh, where l is the length,   |  cuboid is 2lw + 2lh + 2wh, where l is the length, \nw is the width, and h is the height.  ```python #   |  w is the width, and h is the height.  ```python # \nDefine the dimensions of the cuboid length = 5  #   |  Define the dimensions of the cuboid length = 5  # \ncm width = 8   # cm height = 10  # cm  # Calculate  |  cm width = 8   # cm height = 10  # cm  # Calculate\nthe surface area surface_area = 2 * (length *       |  the surface area surface_area = 2 * (length *     \nwidth) + 2 * (length * height) + 2 * (width *       |  width) + 2 * (length * height) + 2 * (width *     \nheight)  # Print the surface area print(\"The        |  height)  # Print the surface area print(\"The      \nsurface area of the cuboid is\", surface_area,       |  surface area of the cuboid is\", surface_area,     \n\"square centimeters.\") ```  ### Explanation: This   |  \"square centimeters.\") ```  ### Explanation: This \ncode calculates the surface area of a cuboid given  |  code calculates the surface area of a cuboid given\nits dimensions. It uses the formula for the         |  its dimensions. It uses the formula for the       \nsurface area of a cuboid, which is 2lw + 2lh +      |  surface area of a cuboid, which is 2lw + 2lh +    \n2wh, where l is the length, w is the width, and h   |  2wh, where l is the length, w is the width, and h \nis the height. The code defines the dimensions of   |  is the height. The code defines the dimensions of \nthe cuboid, calculates the surface area using the   |  the cuboid, calculates the surface area using the \nformula, and prints the result.   ### Example Use   |  formula, and prints the result.   ### Example Use \nCase: This code can be used in a variety of         |  Case: This code can be used in a variety of       \napplications, such as calculating the surface area  |  applications, such as calculating the surface area\nof a cuboid in a 3D modeling program or in a        |  of a cuboid in a 3D modeling program or in a      \nphysics simulation. For example, if you are         |  physics simulation. For example, if you are       \ndesigning a box to hold a certain amount of         |  designing a box to hold a certain amount of       \nmaterial, you can use this code to calculate the    |  material, you can use this code to calculate the  \nsurface area of the box and determine how much      |  surface area of the box and determine how much    \nmaterial you will need to cover it.   ### Note:     |  material you will need to cover it.   ### Note:   \nThis code assumes that the dimensions of the        |  This code assumes that the dimensions of the      \ncuboid are given in centimeters. If the dimensions  |  cuboid are given in centimeters. If the dimensions\nare given in a different unit, you will need to     |  are given in a different unit, you will need to   \nconvert them to centimeters before calculating the  |  convert them to centimeters before calculating the\nsurface area.   ### Output: The surface area of     |  surface area.   ### Output: The surface area of   \nthe cuboid is 240 square centimeters.   ### Time    |  the cuboid is 240 square centimeters.   ### Time  \nComplexity: The time complexity of this code is     |  Complexity: The time complexity of this code is   \nO(1), meaning that it runs in constant time         |  O(1), meaning it takes constant time to run,      \nregardless of the size of the input. This is        |  regardless of the size of the input. This is      \nbecause the code only performs a fixed number of    |  because the code only performs a fixed number of  \noperations, regardless of the dimensions of the     |  operations, regardless of the dimensions of the   \ncuboid.   ### Space Complexity: The space           |  cuboid.   ### Space Complexity: The space         \ncomplexity of this code is O(1), meaning that it    |  complexity of this code is O(1), meaning it uses a\nuses a constant amount of space regardless of the   |  constant amount of space to store the input and   \nsize of the input. This is because the code only    |  output. This is because the code only uses a fixed\nuses a fixed number of variables to store the       |  amount of space to store the dimensions of the    \ndimensions of the cuboid and the surface area.      |  cuboid and the surface area, regardless of the    \n### Advice: When working with 3D geometry, it's     |  size of the input.   ### Advice: When working with\noften helpful to break down the problem into        |  3D geometry, it's often useful to have a function \nsmaller, more manageable pieces. In this case, we   |  that can calculate the surface area of a cuboid.  \ncan calculate the surface area of the cuboid by     |  This code provides a simple and efficient way to  \ncalculating the area of each face and adding them   |  do so. Just remember to define the dimensions of  \ntogether. This can make the problem easier to       |  the cuboid before using the function, and the     \nunderstand and solve.   ### Tips: * Make sure to    |  function will return the surface area of the      \ndefine the dimensions of the cuboid clearly and     |  cuboid.   ### Tips: - Make sure to define the     \naccurately. * Use the correct formula for the       |  dimensions of the cuboid before using the         \nsurface area of a cuboid. * Check your              |  function. - The function assumes that the         \ncalculations to ensure that they are correct. *     |  dimensions are given in centimeters. If the       \nConsider using a calculator or computer program to  |  dimensions are given in a different unit, you will\nsimplify the calculation of the surface area.       |  need to convert them to centimeters before        \n### Variations: * To calculate the surface area of  |  calculating the surface area. - The function uses \na cuboid with different dimensions, simply change   |  a simple and efficient formula to calculate the   \nthe values of the length, width, and height         |  surface area. This makes it easy to use and       \nvariables. * To calculate the surface area of a     |  understand, even for those without a strong       \ndifferent shape, such as a sphere or a cylinder,    |  background in 3D geometry.   ### Related          \nyou will need to use a different formula.   ###     |  Functions: - `volume()`: calculates the volume of \nConclusion: This code provides a simple and         |  a cuboid - `diagonal()`: calculates the diagonal  \nefficient way to calculate the surface area of a    |  of a cuboid - `perimeter()`: calculates the       \ncuboid given its dimensions. By following the       |  perimeter of a cuboid  ### Related Classes: -     \nsteps outlined in the code, you can easily          |  `Cuboid()`: a class that represents a cuboid and  \ncalculate the surface area of a cuboid and apply    |  provides methods for calculating its surface area,\nit to a variety of real-world problems.   ###       |  volume, and diagonal.   ### Related Modules: -    \nFuture Work: * Consider adding more error checking  |  `math`: provides mathematical functions and       \nto the code to ensure that the dimensions of the    |  constants, such as the square root and pi.   ###  \ncuboid are valid. * Consider adding more            |  Related Documentation: - `numpy`: provides support\nfunctionality to the code, such as calculating the  |  for large, multi-dimensional arrays and matrices, \nvolume of the cuboid or determining its surface     |  along with a large collection of high-level       \narea in a different unit.   ### References: *       |  mathematical functions to operate on these arrays.\nWikipedia: Cuboid * MathWorld: Surface Area of a    |  ### Related Libraries: - `matplotlib`: a plotting \nCuboid * Khan Academy: Surface Area of a Cuboid     |  library for creating static, animated, and        \n### Acknowledgments: This code was written by       |  interactive visualizations in python.   ###       \n[Your Name] and is based on the Wikipedia article   |  Related Frameworks: - `pygame`: a set of Python   \non cuboids. The code was reviewed and tested by     |  modules designed for writing video games.   ###   \n[Reviewer's Name].   ### License: This code is      |  Related APIs: - `numpy`: provides support for     \nlicensed under the [License Name] license.   ###    |  large, multi-dimensional arrays and matrices,     \nDisclaimer: This code is provided \"as is\" without   |  along with a large collection of high-level       \nany warranties or guarantees. The author disclaims  |  mathematical functions to operate on these arrays.\nany liability for any damages or losses resulting   |  ### Related Books: - `3D Geometry` by Mark Allen  \nfrom the use of this code.   ### Copyright: This    |  Hopkins - `Python for Data Analysis` by Wes       \ncode is copyrighted by [Your Name] and may not be   |  McKinney - `3D Graphics with Python` by Mark Allen\nreproduced or distributed without permission.       |  Hopkins  ### Related Online Courses: - `3D        \n### Credits: This code was written by [Your Name]   |  Geometry` by Mark Allen Hopkins on Udemy - `Python\nand was reviewed and tested by [Reviewer's Name].   |  for Data Analysis` by Wes McKinney on Coursera -  \n### Updates: This code has been updated to include  |  `3D Graphics with Python` by Mark Allen Hopkins on\nmore error checking and to improve its              |  Udemy  ### Related YouTube Channels: -            \nperformance.   ### Changes: * Added more error      |  `3Blue1Brown` by Grant Sanderson - `Python for    \nchecking to the code. * Improved the performance    |  Data Analysis` by Wes McKinney - `3D Graphics with\nof the code. * Added more documentation to the      |  Python` by                                        \ncode.   ### Notes: * This code                      |                                                    \n","output_type":"stream"}],"execution_count":55}]}